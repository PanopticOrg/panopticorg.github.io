{"config":{"lang":["en","fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Qu'est ce que Panoptic ?","text":"<p>Panoptic est un logiciel d\u00e9di\u00e9 \u00e0 la recherche permettant d'explorer et d'annoter de larges corpus d'images. </p> <p></p> <p>Cet outil int\u00e8gre ainsi de nombreuses fonctions avec l\u2019objectif d\u2019aider les chercheur\u00b7euses pour travailler au sein d\u2019une importante masse de donn\u00e9es : regroupement d\u2019images, recherche de similarit\u00e9s visuelles, annotations fines ou par lots, import de donn\u00e9es associ\u00e9es aux images, gestion de corpus pluris\u00e9miotiques, etc. </p>"},{"location":"#synthese-des-fonctionnalites-disponibles","title":"Synth\u00e8se des fonctionnalit\u00e9s disponibles","text":"<p>Panoptic permet de:</p> <ul> <li>Explorer l\u2019ensemble des \u00e9l\u00e9ments d\u2019un corpus d\u2019images import\u00e9 par les chercheur\u00b7euses.</li> <li>Regrouper des images ensemble en fonction de leur similarit\u00e9.</li> <li>Trouver des images similaires \u00e0 une image particuli\u00e8re ou \u00e0 des groupes d\u2019images.</li> <li>Annoter des images en fonction de diff\u00e9rentes propri\u00e9t\u00e9s : date, url, tag(s), valeur num\u00e9rique, vrai/faux</li> <li>Grouper, trier et filtrer des images en fonction de leurs propri\u00e9t\u00e9s (import\u00e9es ou annot\u00e9es dans l\u2019interface).</li> <li>Importer, g\u00e9rer et exporter des propri\u00e9t\u00e9s associ\u00e9es aux images.</li> </ul>"},{"location":"concepts/","title":"Glossaire","text":"<p>Cette page est un aper\u00e7u de tous les concepts utilis\u00e9s dans Panoptic. Elle peut \u00eatre une bonne r\u00e9f\u00e9rence pour comprendre rapidement un terme ou obtenir une vue d'ensemble du logiciel. Pour plus d\u2019informations sur un concept sp\u00e9cifique, consultez la page d\u00e9di\u00e9e.</p>"},{"location":"concepts/#projet","title":"Projet","text":"<p>Les projets dans Panoptic sont un moyen de stocker votre travail. Vous pouvez, par exemple, cr\u00e9er diff\u00e9rents projets sur un m\u00eame corpus si vous souhaitez r\u00e9aliser diff\u00e9rentes annotations, importer diff\u00e9rentes donn\u00e9es en lien avec les images, ou encore m\u00e9langer plusieurs corpus d'images dans un m\u00eame projet.</p> <p>Par exemple, il peut \u00eatre int\u00e9ressant de travailler sur un ensemble de photographies historiques pour faire des annotations et explorer les th\u00e8mes r\u00e9currents, mais il pourrait \u00e9galement \u00eatre pertinent de m\u00e9langer ce corpus avec un corpus collect\u00e9 sur Internet afin de voir si certaines de ces images historiques peuvent \u00eatre retrouv\u00e9es sur des sites web et, si oui, dans quel contexte elles apparaissent.</p>"},{"location":"concepts/#donnees","title":"Donn\u00e9es","text":"<p>Lors de la cr\u00e9ation d'un projet, vous devez s\u00e9lectionner un dossier dans lequel les donn\u00e9es du projet seront stock\u00e9es. Chaque projet stocke ses donn\u00e9es s\u00e9par\u00e9ment dans une base de donn\u00e9es SQLite (voir le sch\u00e9ma d\u00e9taill\u00e9).</p>"},{"location":"concepts/#parametres","title":"Param\u00e8tres","text":"<p>Un projet peut \u00eatre configur\u00e9 avec des param\u00e8tres permettant de d\u00e9finir les valeurs par d\u00e9faut de chaque plugin au niveau du projet. Il est \u00e9galement possible, par exemple, de stocker une copie des images directement dans la base de donn\u00e9es, ce qui facilite le partage d\u2019un projet Panoptic en envoyant un seul fichier.</p>"},{"location":"concepts/#images-et-instances","title":"Images et Instances","text":"<p>L\u2019un des concepts les plus complexes \u00e0 comprendre dans Panoptic est la diff\u00e9rence entre images et instances. Pour comprendre la n\u00e9cessit\u00e9 de cette distinction, prenons l\u2019exemple d\u2019une image trouv\u00e9e sur Twitter, mais post\u00e9e par deux utilisateurs diff\u00e9rents, \u00e0 des moments diff\u00e9rents, et avec des messages tr\u00e8s distincts. Techniquement, c\u2019est la m\u00eame image, mais comme les contextes dans lesquels elle appara\u00eet sont tr\u00e8s diff\u00e9rents, on pourrait consid\u00e9rer qu'elle n'est pas s\u00e9mantiquement identique.</p> <p>Ainsi, si nous souhaitons observer les images dans Panoptic avec leurs contextes stock\u00e9s sous forme de propri\u00e9t\u00e9s, une m\u00eame image peut appara\u00eetre plusieurs fois si elle a \u00e9t\u00e9 trouv\u00e9e plusieurs fois dans le corpus avec des propri\u00e9t\u00e9s diff\u00e9rentes.</p> <p>En r\u00e9sum\u00e9 :</p> <ul> <li>Une image correspond uniquement \u00e0 un ensemble de pixels.</li> <li>Une instance d'image repr\u00e9sente l'occurrence de cet ensemble de pixels dans un contexte sp\u00e9cifique.</li> </ul> <p>Par cons\u00e9quent, une image peut avoir plusieurs instances, mais une instance ne peut \u00eatre li\u00e9e qu'\u00e0 une seule image.</p>"},{"location":"concepts/#proprietes","title":"Propri\u00e9t\u00e9s","text":"<p>Les propri\u00e9t\u00e9s sont utilis\u00e9es dans Panoptic pour ajouter des donn\u00e9es suppl\u00e9mentaires qui ne sont pas des images. Elles peuvent \u00eatre import\u00e9es ou ajout\u00e9es manuellement afin de cr\u00e9er des annotations sur les images.</p>"},{"location":"concepts/#types-de-proprietes","title":"Types de propri\u00e9t\u00e9s","text":"<p>Les propri\u00e9t\u00e9s peuvent \u00eatre de diff\u00e9rents types selon le type d'annotation \u00e0 ajouter. Chaque type poss\u00e8de un comportement sp\u00e9cifique. Par exemple, les propri\u00e9t\u00e9s de type date permettent de regrouper dynamiquement les images par ann\u00e9e, mois, semaine, etc.</p> Type de propri\u00e9t\u00e9 Description Tag Contient un seul tag MultiTags Contient plusieurs tags URL Lien web cliquable Date Une date Couleur Une couleur parmi 12 disponibles dans Panoptic Checkbox Case \u00e0 cocher simple Nombre Nombre entier ou flottant Texte Donn\u00e9e textuelle"},{"location":"concepts/#image-instance","title":"Image / Instance","text":"<p>Lorsqu'elles sont cr\u00e9\u00e9es ou import\u00e9es, les propri\u00e9t\u00e9s peuvent \u00eatre li\u00e9es aux images ou aux instances :</p> <ul> <li>Une propri\u00e9t\u00e9 d'image est partag\u00e9e par toutes les instances de cette image et est souvent utilis\u00e9e pour d\u00e9crire des caract\u00e9ristiques visuelles.</li> <li>Une propri\u00e9t\u00e9 d'instance est li\u00e9e \u00e0 une seule occurrence sp\u00e9cifique d'une image.</li> </ul> <p>Par exemple, pour une m\u00eame image post\u00e9e deux fois sur Twitter, les auteurs, la date de publication et le commentaire associ\u00e9 au post doivent \u00eatre des propri\u00e9t\u00e9s d'instance et non des propri\u00e9t\u00e9s d\u2019image.</p>"},{"location":"concepts/#tags","title":"Tags","text":"<p>Les types de propri\u00e9t\u00e9 les plus couramment utilis\u00e9s dans Panoptic sont \"tag\" et \"multi_tags\" car ils sont faciles \u00e0 cr\u00e9er et \u00e0 manipuler, avec une autocompl\u00e9tion facilitant l'annotation des images. Cependant, lorsqu\u2019il y a un grand nombre de tags, leur organisation peut devenir complexe. Dans Panoptic, les tags peuvent \u00eatre hi\u00e9rarchiques et avoir plusieurs parents.</p> <p>C'est pourquoi un module d\u00e9di\u00e9 \u00e0 la gestion des tags a \u00e9t\u00e9 cr\u00e9\u00e9, souvent appel\u00e9 \"tags modal\", permettant de r\u00e9organiser ou renommer les tags visuellement.</p>"},{"location":"concepts/#importation","title":"Importation","text":"<p>Les propri\u00e9t\u00e9s peuvent \u00eatre import\u00e9es via le module d'importation en utilisant un fichier CSV.</p>"},{"location":"concepts/#exportation","title":"Exportation","text":"<p>Les propri\u00e9t\u00e9s peuvent \u00eatre export\u00e9es via le module d'exportation vers un fichier CSV. Une s\u00e9lection d'images peut \u00e9galement \u00eatre export\u00e9e avec le fichier CSV.</p>"},{"location":"concepts/#filtres-tri-et-groupes","title":"Filtres, Tri et Groupes","text":"<p>Panoptic permet de cr\u00e9er des vues dynamiques des images en utilisant des filtres, des tris et des regroupements.</p>"},{"location":"concepts/#filtres","title":"Filtres","text":"<p>Les filtres permettent d'afficher uniquement les images correspondant aux crit\u00e8res d\u00e9finis. Plusieurs filtres peuvent \u00eatre combin\u00e9s \u00e0 l'aide des op\u00e9rateurs ET ou OU.</p>"},{"location":"concepts/#tri","title":"Tri","text":"<p>Le tri permet de modifier l\u2019ordre d\u2019affichage des images. Il peut \u00eatre croissant ou d\u00e9croissant et appliqu\u00e9 sur plusieurs propri\u00e9t\u00e9s, par exemple : \"trier par date croissante, puis par description textuelle d\u00e9croissante\".</p>"},{"location":"concepts/#groupes","title":"Groupes","text":"<p>Les groupes permettent de regrouper les images en fonction d'une propri\u00e9t\u00e9 s\u00e9lectionn\u00e9e. Des sous-groupes peuvent \u00eatre cr\u00e9\u00e9s en s\u00e9lectionnant une autre propri\u00e9t\u00e9. Les groupes peuvent \u00eatre tri\u00e9s par valeur de propri\u00e9t\u00e9 ou par nombre d'\u00e9l\u00e9ments.</p>"},{"location":"concepts/#recherche","title":"Recherche","text":"<p>Une recherche en texte int\u00e9gral est possible sur toutes les propri\u00e9t\u00e9s textuelles via la barre de recherche.</p>"},{"location":"concepts/#vues","title":"Vues","text":"<p>Lors de l'affichage des images, plusieurs modes de pr\u00e9sentation sont disponibles :</p> <ul> <li>Vue en grille : affichage par d\u00e9faut centr\u00e9 sur les images.</li> <li>Vue en tableau : permet de visualiser plus de propri\u00e9t\u00e9s et/ou des propri\u00e9t\u00e9s longues.</li> <li>Vue en graphe : affiche un graphe lorsqu'un regroupement est fait sur une valeur num\u00e9rique ou une date.</li> </ul>"},{"location":"concepts/#onglets","title":"Onglets","text":"<p>Un des objectifs principaux de Panoptic est de permettre plusieurs fa\u00e7ons d'explorer un corpus d'images simultan\u00e9ment. Pour cela, les onglets sont utilis\u00e9s comme espaces de travail distincts, chacun pouvant avoir ses propres filtres, tris, groupes, vues et propri\u00e9t\u00e9s affich\u00e9es.</p>"},{"location":"concepts/#vecteurs","title":"Vecteurs","text":"<p>Pour permettre l'utilisation d'algorithmes d'apprentissage automatique, les images sont transform\u00e9es en vecteurs (ou embeddings) lors de leur importation dans Panoptic. Un vecteur est une liste de nombres repr\u00e9sentant des caract\u00e9ristiques de l\u2019image.</p> <p>Ces caract\u00e9ristiques ne sont pas forc\u00e9ment interpr\u00e9tables directement, mais elles permettent de comparer les images entre elles. Par exemple, deux images de chats auront des vecteurs plus proches que ceux d'un chien.</p>"},{"location":"concepts/#clusters","title":"Clusters","text":"<p>Une fois les vecteurs calcul\u00e9s, les images peuvent \u00eatre regroup\u00e9es automatiquement en clusters. Contrairement aux groupes cr\u00e9\u00e9s avec des propri\u00e9t\u00e9s, les clusters sont param\u00e9trables, peuvent \u00eatre g\u00e9n\u00e9r\u00e9s avec diff\u00e9rents algorithmes, et ne sont pas d\u00e9terministes (un m\u00eame clustering peut produire des r\u00e9sultats l\u00e9g\u00e8rement diff\u00e9rents selon les ex\u00e9cutions).</p>"},{"location":"concepts/#similarite","title":"Similarit\u00e9","text":"<p>Une fois les vecteurs calcul\u00e9s, la similarit\u00e9 entre images peut \u00eatre mesur\u00e9e. Diff\u00e9rents algorithmes peuvent \u00eatre utilis\u00e9s. Panoptic utilise par d\u00e9faut la similarit\u00e9 cosinus, dont les valeurs sont comprises entre 0 et 1.</p>"},{"location":"concepts/#executer","title":"Ex\u00e9cuter","text":"<p>Les calculs qui ne sont pas list\u00e9s ci-dessus peuvent \u00eatre lanc\u00e9s avec le bouton \"Ex\u00e9cuter\", qui regroupe toutes les actions fournies par les plugins. Exemples :</p> <ul> <li>D\u00e9tecter les couleurs principales des images et les enregistrer en tant que propri\u00e9t\u00e9.</li> <li>Ex\u00e9cuter l'OCR sur les images.</li> <li>Identifier les sujets principaux des textes associ\u00e9s aux images.</li> <li>Extraire des objets des images.</li> </ul>"},{"location":"concepts/#plugins","title":"Plugins","text":"<p>Les plugins permettent d'ajouter de nouvelles fonctionnalit\u00e9s \u00e0 Panoptic. Chaque projet peut activer uniquement les plugins n\u00e9cessaires, ce qui optimise la l\u00e9g\u00e8ret\u00e9 du logiciel. M\u00eame les fonctionnalit\u00e9s de deep learning de Panoptic sont int\u00e9gr\u00e9es sous forme de plugin.</p> <p>Les plugins peuvent ajouter de nouvelles possibilit\u00e9s pour :</p> <ul> <li>Cr\u00e9er des clusters.</li> <li>Calculer des similarit\u00e9s.</li> <li>Ajouter des actions sp\u00e9cifiques via le bouton \"Ex\u00e9cuter\".</li> </ul>"},{"location":"faq/","title":"Questions fr\u00e9quentes","text":""},{"location":"faq/#est-ce-que-panoptic-cree-les-corpus-dimage-automatiquement","title":"Est ce que panoptic cr\u00e9\u00e9 les corpus d'image automatiquement ?","text":"<p>Non panoptic est un outil d'analyse de corpus d\u00e9j\u00e0 existant. Pour \u00eatre utilis\u00e9 il faut pr\u00e9alablement avoir t\u00e9l\u00e9charg\u00e9 son corpus d'images localement. </p>"},{"location":"faq/#mon-corpus-est-en-iiif-puis-je-limporter-dans-panoptic","title":"Mon corpus est en IIIF, puis-je l'importer dans panoptic ?","text":"<p>Pour le moment non, mais nous y travaillons.</p>"},{"location":"faq/#je-narrive-pas-a-importer-mes-donnees-additionnelles-dans-panoptic","title":"Je n'arrive pas \u00e0 importer mes donn\u00e9es additionnelles dans panoptic","text":"<p>Assurez vous d'avoir bien respect\u00e9 le tutoriel</p> <p>La plupart des erreurs viennent couramment de:</p> <ul> <li>la premi\u00e8re colonne doit imp\u00e9rativement se nommer path et contenir un chemin vers l'image</li> <li>la colonne path doit seulement s'appeler path et rien d'autre</li> <li>il ne doit pas y avoir en m\u00eame temps de colonne path et de colonne id</li> <li>chaque colonne autre que path doit avoir entre crochets un type de propri\u00e9t\u00e9 de renseign\u00e9</li> </ul>"},{"location":"faq/#puis-je-utiliser-une-carte-graphique-avec-panoptic","title":"Puis-je utiliser une carte graphique avec panoptic ?","text":"<p>Oui c'est possible, lors de l'installation si vous avez une carte graphique NVidia il vous sera propos\u00e9 d'installer les librairies compatibles GPU.  Il est \u00e0 noter que cela n'augmentera que le calcul des vecteurs d'images qui n'a lieu qu'une fois. </p>"},{"location":"faq/#si-mes-images-ont-deja-ete-importees-puis-je-les-partager-sans-avoir-a-refaire-le-calcul","title":"Si mes images ont d\u00e9j\u00e0 \u00e9t\u00e9 import\u00e9es, puis-je les partager sans avoir \u00e0 refaire le calcul ?","text":"<p>Le calcul des images peut \u00eatre long, aussi si plusieurs personnes ont vocation \u00e0 travailler sur un m\u00eame projet, l'import peut \u00eatre fait sur un ordinateur ayant de bonnes capacit\u00e9s de calcul, puis le fichier .db peut \u00eatre partag\u00e9, celui ci se trouve dans le dossier que vous avez choisi au moment de la cr\u00e9ation du projet. </p>"},{"location":"faq/#puis-je-annoter-a-plusieurs-en-ligne-sur-panoptic","title":"Puis-je annoter \u00e0 plusieurs en ligne sur panoptic ?","text":"<p>Non, panoptic est un outil fait pour \u00eatre utilis\u00e9 localement, nous avons pour but plus tard de le rendre collaboratif mais cela va demander encore beaucoup de d\u00e9veloppements. </p>"},{"location":"faq/#ou-est-ce-que-panoptic-stocke-les-donnees","title":"O\u00f9 est ce que Panoptic stocke les donn\u00e9es ?","text":"<p>Lorsque vous cr\u00e9ez un projet, vous choisissez un dossier dans lequel le cr\u00e9er, ce dossier contiendra toute la base de donn\u00e9e sqlite (le fichier panoptic.db) ainsi que les \u00e9ventuelles donn\u00e9es des plugins. C'est ce fichier .db que vous pouvez utiliser pour partager un projet \u00e0 quelqu'un d'autre ou pour sauvegarder un projet ailleurs que sur votre ordinateur (pour faire un backup).</p>"},{"location":"resources/","title":"Ressources Utiles","text":""},{"location":"resources/#outils-open-source-complementaires-en-analyse-dimages","title":"Outils open source compl\u00e9mentaires en analyse d'images","text":"<ul> <li>Pimmi : un outil en ligne de commande du m\u00e9dialab de Science-Po pour faire de la recherche de similarit\u00e9s (image enti\u00e8re et fragments d'images) en ligne de commande. Permet de traiter un tr\u00e8s grand nombre d'images. Se base sur la technique du SIFT. </li> <li>Aikon: un outil plut\u00f4t ax\u00e9 serveur d\u00e9velopp\u00e9 par l'\u00e9cole des Ponts. Permet d'extraire des r\u00e9gions dans des documents (plut\u00f4t li\u00e9s aux humanit\u00e9s) et de faire de la recherche de similarit\u00e9 au sein de ces r\u00e9gions extraites. </li> <li>Tropy: un explorateur d'images pens\u00e9 pour la recherche, permet d'annoter finement des corpus d'images.</li> <li>Arkindex: outil d\u00e9velopp\u00e9 par l'entreprise TEKLIA et offrant de nombreuses fonctionnalit\u00e9s de traitement d'image, OCR, HTR, extraction de r\u00e9gions etc. il existe de plus un partenariat avec huma-num pour avoir acc\u00e8s \u00e0 une instance d'Arkindex d\u00f4t\u00e9e de serveurs de calculs.</li> <li>Collection Space Navigator: un simple outil permettant d'explorer des corpus d'images sous forme visualisation spatiale. On ne peut pas choisir en ligne son propre corpus mais le code est opensource et r\u00e9utilisable si n\u00e9cessaire.</li> <li>Voxel 51: un outil \u00e0 mi chemin entre panoptic et arkindex permettant d'appliquer de nombreux algorithmes de vision par ordinateur \u00e0 des datasets d'images, n\u00e9cessite tout de m\u00eame un niveau technique en python, il est conseill\u00e9 aux personnes ayant envie d'analyser un peu plus en d\u00e9tail les r\u00e9sultats produits par les algoritumes.</li> <li>eScriptorium: un outil permettant de faire de l'HTR et d'entrainer des mod\u00e8les.</li> <li>DistantViewing Lab: ensemble de d\u00e9mos en ligne d'algorithmes pour travailler avec des images, vid\u00e9os ou du texte. </li> </ul>"},{"location":"resources/#publications-utilisant-panoptic","title":"Publications utilisant Panoptic","text":"<ul> <li>Panoptic, un outil d'exploration par similarit\u00e9 de vastes corpus d'images</li> <li>Fantin Le Ber. IA et patrimoine, un changement dans la continuit\u00e9 : l\u2019exemple du projet Highvision. Sciences de l\u2019Homme et Soci\u00e9t\u00e9. 2025.</li> <li>Pierre Husson. Indexation iconographique et intelligence artificielle : exp\u00e9rimentations autour du R\u00e9pertoire des tableaux italiens dans les collections publiques fran\u00e7aises (RETIF). Sciences de l\u2019Homme et Soci\u00e9t\u00e9. 2025. \uffff</li> <li>Panoptic pr\u00e9sent\u00e9 au FOSDEM 2025</li> </ul>"},{"location":"resources/#litterature-complementaire-sur-lanalyse-dimages","title":"Litt\u00e9rature compl\u00e9mentaire sur l'analyse d'images","text":"<ul> <li>Distant Viewing: ensemble de r\u00e9flexions th\u00e9oriques et m\u00e9thodologiques sur comment travailler de fa\u00e7on automatique avec des images.</li> <li>Consortium PictorIA: consortium travaillant sur la fa\u00e7on dont l'IA peut s'appliquer aux humanit\u00e9s num\u00e9riques.</li> </ul>"},{"location":"advanced/astuces/","title":"Astuces et raccourcis","text":"<p>Cette section vise \u00e0 recenser quelques raccourcis claviers et astuces d'utilisation permettant de faciliter l'usage de panoptic. </p>"},{"location":"advanced/astuces/#raccourcis","title":"Raccourcis","text":"<p>Note</p> <p>A noter que sur mac, CTRL est remplac\u00e9 par Commande</p> <ul> <li>ctrl + z: annuler, </li> <li>ctrl + alt + z: r\u00e9tablir, </li> <li>ctrl maintenu au survol d'une image: affichage d'un agrandissement d'une image, </li> <li>s\u00e9lection en maintenant shift: s\u00e9lectionne toutes les images entre la premi\u00e8re et la derni\u00e8re image s\u00e9lectionn\u00e9e,</li> <li>s\u00e9lection en maintenant ctrl: s\u00e9lectionne une image sans annuler la s\u00e9lection en cours</li> <li>tab lorsque l'est en train d'annoter une image: passe \u00e0 l'annotation de la m\u00eame propri\u00e9t\u00e9 sur l'image d'apr\u00e8s, </li> <li>entr\u00e9e permet de valider la plupart des actions (annotation, clusters, executer etc.)</li> </ul>"},{"location":"advanced/astuces/#astuces","title":"Astuces","text":"<ul> <li>lorsque l'on effectue une recherche de similarit\u00e9 par texte, si l'on entre une url d'image \u00e0 la place du texte, panoptic va t\u00e9l\u00e9charger cette image et faire une recherche de similarit\u00e9 par image sur cette image externe.</li> </ul>"},{"location":"advanced/import/","title":"Import des images et similarit\u00e9","text":"<p>Tous les outils de similarit\u00e9 de panoptic se reposent sur une premi\u00e8re \u00e9tape ayant lieu lors de l'import des images: la vectorisation.</p> <p>Ce processus consiste \u00e0 utiliser un mod\u00e8le de Deep Learning, en l'occurence le mod\u00e8le open source OpenAI - CLIP pour transformer les images en embedding (ou plongement en fran\u00e7ais). </p> <p>Ces embeddings vont permettre de comparer facilement les images entre elles, non seulement en fonction de leur ressemblance visuelle, mais \u00e9galement en fonction de ce qu'elles repr\u00e9sentent. </p>"},{"location":"advanced/import/#exemple-illustre","title":"Exemple illustr\u00e9","text":"<p>Concr\u00e8tement les embeddings sont des listes de chiffres, le nombre de chiffres pourra varier en fonction du mod\u00e8le utilis\u00e9 mais par exemple pour CLIP les images sont transform\u00e9s en listes de 512 chiffres. Ces derniers repr\u00e9sentent des caract\u00e9ristiques visuelles et / ou s\u00e9mantiques des images, mais sont durs \u00e0 interpr\u00e9ter si l'on regarder uniquement les chiffres.</p> <p>Voici un exemple fictif et extr\u00eamement simplifi\u00e9 d'embeddings de seulement 3 chiffres que l'on pourrait obtenir pour les images suivantes:</p> <p></p> <p>Les deux vecteurs de chats sont a priori plus proches en valeur. On pourrait alors chercher \u00e0 interpr\u00eater ce que repr\u00e9sente chaque valeur pour le mod\u00e8le, (par exemple le type de museau, la posture, le type d\u2019oreille), mais c\u2019est un champ de recherche \u00e0 part, et ici nous nous contentons d\u2019utiliser le mod\u00e8le en partant du principe qu\u2019il a \u00e9t\u00e9 pr\u00e9alablement bien entrain\u00e9 et saura convertir nos images en vecteurs de telle sorte qu\u2019il puisse bien identifier les images.</p> <p>Une fois que le mod\u00e8le a transform\u00e9 nos images en vecteurs, on peut se permettre de cr\u00e9er des groupes d\u2019images en fonction de ces caract\u00e9ristiques (qui ne sont, rappelons le, pas des caract\u00e9ristiques purement visuelles comme on a pu le voir dans les premi\u00e8res m\u00e9thodes, mais bien des caract\u00e9ristiques de ce qui est repr\u00e9sent\u00e9.) </p> <p>Ces groupes peuvent \u00eatre repr\u00e9sent\u00e9s sur un graphique, ce qui implique toutefois de ne garder que deux points par image. Il existe des m\u00e9thodes statistiques permettant de calculer ces deux points et ce quel que soit la taille du vecteur d\u2019entr\u00e9e mais ici par souci de simplicit\u00e9 nous nous contenterons de ne conserver que les points correspondant aux museaux et aux oreilles puisqu\u2019ils sont a priori les plus significatifs.</p> <p>On obtient donc le graphique suivant:</p> <p></p> <p>Ce qui nous permet de constater qu\u2019effectivement on peut visuellement regrouper nos images en groupes, les chats ensemble et le chien \u00e0 part.</p>"},{"location":"advanced/instances/","title":"Instances","text":"<p>L\u2019un des concepts les plus complexes \u00e0 comprendre dans Panoptic est la diff\u00e9rence entre images et instances. Pour comprendre la n\u00e9cessit\u00e9 de cette distinction, prenons l\u2019exemple d\u2019une image trouv\u00e9e sur Twitter, mais post\u00e9e par deux utilisateurs diff\u00e9rents, \u00e0 des moments diff\u00e9rents, et avec des messages tr\u00e8s distincts. Techniquement, c\u2019est la m\u00eame image, mais comme les contextes dans lesquels elle appara\u00eet sont tr\u00e8s diff\u00e9rents, on pourrait consid\u00e9rer qu'elle n'est pas s\u00e9mantiquement identique.</p> <p>Ainsi, si nous souhaitons observer les images dans Panoptic avec leurs contextes stock\u00e9s sous forme de propri\u00e9t\u00e9s, une m\u00eame image peut appara\u00eetre plusieurs fois si elle a \u00e9t\u00e9 trouv\u00e9e plusieurs fois dans le corpus avec des propri\u00e9t\u00e9s diff\u00e9rentes.</p> <p></p> <p>En r\u00e9sum\u00e9</p> <p>Une image correspond uniquement \u00e0 un ensemble de pixels.</p> <p>Une instance d'image repr\u00e9sente l'occurrence de cet ensemble de pixels dans un contexte sp\u00e9cifique.</p> <p>Par cons\u00e9quent, une image peut avoir plusieurs instances, mais une instance ne peut \u00eatre li\u00e9e qu'\u00e0 une seule image.</p>"},{"location":"advanced/instances/#proprietes-dinstances","title":"Propri\u00e9t\u00e9s d'instances","text":"<p>Du fait de la diff\u00e9rence que nous venons d'observer, il existe deux types d'annotations que l'on va pouvoir produire dans panoptic:</p> <ul> <li>Les annotations servant \u00e0 d\u00e9crire toutes les instances d'une m\u00eame image, dans l'exemple ci dessus, cela serait d'annoter l'image en disant que c'est un chat, pour cela on utilise donc les propri\u00e9t\u00e9s d'images qui vont automatiquement \u00eatre appliqu\u00e9es \u00e0 toutes les instances.</li> <li>Les annotations servant \u00e0 d\u00e9crire une instance en particulier, dans l'exemple ci dessus, cela serait d'annoter en disant que l'instance 1 est \"pro-chats\" alors que l'instance 2 est \"anti-chats\". On utilise pour cela des propri\u00e9t\u00e9s d'instances. </li> </ul>"},{"location":"advanced/models/","title":"Choisir son mod\u00e8le","text":"<p>Pour des usages plus avanc\u00e9s, il est possible de comparer des mod\u00e8les de vectorisation d'images entre eux. Celui utilis\u00e9 de base par le plugin de similarit\u00e9 de panoptic est le mod\u00e8le CLIP d'OpenAI (quand ils \u00e9taient encore Open).  Mais il existe d'autres mod\u00e8les qui proposeront une repr\u00e9sentation vectorielle diff\u00e9rente et qui peuvent \u00eatre plus ou moins efficace en fonction des jeux de donn\u00e9es. Certains d'entre eux sont directement int\u00e9gr\u00e9s au plugin de similarit\u00e9:</p> <ul> <li>Mobilenet: mod\u00e8le aux performances moyennes mais \u00e9tant beaucoup plus l\u00e9ger en terme de calcul, bien dans le cas d'utilisation sur une machine ayant peu de puissance de calcul cpu, ne permet pas de similarit\u00e9 texte / image.</li> <li>CLIP: mod\u00e8le par d\u00e9faut de panoptic, bonnes performances et tourne relativement vite sur la plupart des machines, permet de faire de la similarit\u00e9 texte / image</li> <li>SIGLIP: mod\u00e8le plus lourd que CLIP, mais obtenant de meilleures performances en similarit\u00e9 texte / image, les vecteurs seront beaucoup plus long \u00e0 calculer sur une machine moyenne.</li> <li>DINOSv2: mod\u00e8le plus lourd que CLIP, cens\u00e9 avoir de meilleures performances sur la similarit\u00e9 visuelle, ne permet pas de faire de la similarit\u00e9 texte / image</li> </ul>"},{"location":"advanced/models/#creer-de-nouveaux-vecteurs","title":"Cr\u00e9er de nouveaux vecteurs","text":"<p>Afin de pouvoir tester ces diff\u00e9rents mod\u00e8les, il faut g\u00e9n\u00e9rer les vecteurs associ\u00e9s \u00e0 ce mod\u00e8le, on se rend donc dans les param\u00e8tres du projet:</p> <p></p> <ul> <li>Puis on se rend dans Vecteurs &gt; Cr\u00e9er de nouveaux vecteurs.</li> <li>On choisit le nom du mod\u00e8le que l'on souhaite utiliser, dans l'exemple ci-dessous SIGLIP</li> <li>On confirme en appuyant sur Cr\u00e9er et le calcul devrait se lancer en quelques secondes</li> </ul> <p></p> <p>Note</p> <p>Il est possible d'\u00e9galement cocher l'option \"greyscale\" avant d'appuyer sur \"Cr\u00e9er\" si l'on souhaite ignorer la couleur des images, cela peut \u00eatre utile par exemple dans un corpus poss\u00e9dant des images en noir et blanc et d'autres en couleurs si jamais on ne souhaitait pas que la couleur soit un crit\u00e8re d\u00e9terminant par rapport \u00e0 ce qui est repr\u00e9sent\u00e9 \u00e0 l'image.</p> <p>Note</p> <p>Dans le cas o\u00f9 pour une raison quelconque le calcul des vecteurs venait \u00e0 \u00eatre interrompu il est possible de le relancer en appuyant sur le bouton suivant: </p>"},{"location":"advanced/models/#utiliser-les-vecteurs","title":"Utiliser les vecteurs","text":"<p>Une fois g\u00e9n\u00e9r\u00e9, les nouveaux vecteurs ne sont pas utilis\u00e9s par d\u00e9faut, comme les autres vecteurs (CLIP par exemple) restent disponibles il faut choisir lorsque l'on execute une action quels vecteurs l'on souhaite utiliser.</p> <p>Ainsi dans n'importe quelle action de similarit\u00e9 panoptic, clustering, similarit\u00e9 visuelle, similarit\u00e9 textuelle, recommandation de groupe, il est toujours possible de pr\u00e9ciser quels vecteurs utiliser: </p> <ul> <li>Lors de l'execution d'une fonction on appuie sur vec_type et on vient choisir les vecteurs que l'on vient de g\u00e9n\u00e9rer:</li> </ul> <p></p>"},{"location":"advanced/onglets/","title":"Les onglets","text":"<p>Comme abord\u00e9 bri\u00e8vement pr\u00e9c\u00e9demment, panoptic propose un syst\u00e8me d'onglets permettant de conserver diff\u00e9rents points de vue en parall\u00e8le sur le m\u00eame corpus. </p>"},{"location":"advanced/onglets/#exemple-de-cas-dusage","title":"Exemple de cas d'usage","text":"<p>L'objectif est de pouvoir cr\u00e9er des espace de travail d\u00e9di\u00e9s \u00e0 certains objets \u00e0 l'aide des filtres des tris et des groupes. Un exemple basique est l'utilisation d'un onglet \"poubelle\". On utilise un premier onglet d'exploration, dans lequel on annote les images avec une propri\u00e9t\u00e9 de type checkbox \"hors corpus\" tout en appliquant un filtre sur cette propri\u00e9t\u00e9. Toutes les images qui sont coch\u00e9es disparaissent alors instantan\u00e9ment du premier onglet gr\u00e2ce \u00e0 ce filtre et aparaissent dans un autre onglet qui a le filtre inverse (c'est \u00e0 dire ne laissant appara\u00eetre que les images qui ont la case \"hors corpus\" de coch\u00e9e). Cela permet de revenir de temps en temps se concentrer sur l'onglet \"poubelle\" afin de revisionner les images qui ont \u00e9t\u00e9 d\u00e9sign\u00e9es comme hors corpus et de v\u00e9rifier que l'on a pas fait d'erreur, sans pour autant devoir voir ces images l\u00e0 dans la vue principale.</p>"},{"location":"advanced/onglets/#les-vues","title":"Les vues","text":"<p>Si chaque onglet peut avoir ses propres filtres, tris et groupes, il est \u00e9galement possible de configurer l'affichage d\u00e9sir\u00e9 au niveau de l'onglet en choisissant la vue. </p>"},{"location":"advanced/onglets/#la-vue-grille","title":"La vue grille","text":"<p>La vue par d\u00e9faut, affiche une simple grille d'images.</p>"},{"location":"advanced/onglets/#la-vue-tableau","title":"La vue tableau","text":"<p>Une vue sous forme de tableau classique, elle permet de se concentrer plus sur les propri\u00e9t\u00e9s accompagnant les images, notamment les propri\u00e9t\u00e9s de type texte pouvant prendre de la place.</p>"},{"location":"advanced/onglets/#la-vue-graphe","title":"La vue graphe","text":"<p>Vue pour l'instant encore un peu exp\u00e9rimentale mais permettant d'afficher des graphiques montrant le nombre d'image contenues dans un groupage.  Exemple, si je groupe mes images par date et passe en vue graphe, je peux afficher le nombre d'images \u00e0 chaque date, ainsi qu'une pr\u00e9visualisation des images \u00e0 cette date en survolant un point: </p> <p></p> <p>Note</p> <p>Il est \u00e0 noter que tous les filtres et tris sont \u00e9galement appliqu\u00e9s en temps r\u00e9el dans cette vue, ce qui vous permet de modifier votre graphique \u00e0 la vol\u00e9e en fonction d'autres propri\u00e9t\u00e9s que vous auriez. Dans l'exemple ci dessus on n'affiche que le graphique entre certaines dates, et seules les images ayant \u00e9t\u00e9 tagg\u00e9es comme \"rimbaud\". De m\u00eame le groupage par date permet de changer la granularit\u00e9 du groupage en choisissant \u00e0 la minute, heure, jour, semaine, mois, ann\u00e9e. Ces changements sont \u00e9galement r\u00e9percut\u00e9s sur le graphe.</p> <p>Il est \u00e9galement possible de rajouter un nouveau de groupage permettant de fractionner le graphique en fonction d'une autre propri\u00e9t\u00e9, ici par exemple on rajoute un groupage apr\u00e8s la date pour grouper ensuite par type de source d'o\u00f9 proviennent les images \u00e0 chaque date. (On a \u00e9galement pass\u00e9 le type de graphique \u00e0 histogramme en cliquant sur le bouton \"Histogramme\").</p> <p></p>"},{"location":"advanced/projectimport/","title":"Partager un projet","text":"<p>Il est possible d'importer un projet d\u00e9j\u00e0 existant, ce qui permet de transf\u00e9rer un projet d'un ordinateur \u00e0 l'autre.  Il suffit pour cela de cliquer sur importer depuis le menu principal, et de naviguer jusqu'\u00e0 un dossier contenant le fichier .db du projet que l'on souhaite importer.</p> <p></p> <p>!!! info  Un avantage d'importer un projet c'est que cela permet de ne pas recalculer les vecteurs d'images, ces derniers sont d\u00e9j\u00e0 automatiquement stock\u00e9s dans le fichier .db  Un usage courant est donc de calculer les vecteurs sur un ordi puissant puis de partager le projet pour de l'exploration sur des projets moins puissants.</p>"},{"location":"advanced/projectimport/#integrer-les-images","title":"Int\u00e9grer les images","text":"<p>Il convient tout de m\u00eame de noter que de base seules les miniatures d'images sont int\u00e9gr\u00e9es dans un fichier .db, ainsi pour fonctionner correctement il faudra d'abord activer la sauvegarde des versions hd des images dans les param\u00e8tres du projet.</p>"},{"location":"advanced/projectparams/","title":"Param\u00e8tres de projet et de plugins","text":"<p>Il est possible de g\u00e9rer un certain nombre d'options dans les param\u00e8tres de projets.</p> <p>Pour y acc\u00e9der il faut cliquer sur la petite roue dent\u00e9e \u00e0 c\u00f4t\u00e9 du nom du projet ouvert dans l'interface:</p> <p></p> <p>Dedans pourront \u00eatre g\u00e9r\u00e9s:</p> <ul> <li>les formats d'image \u00e0 sauvegarder dans la base de donn\u00e9es, de base on ne garde que les miniatures et les versions de taille moyenne calcul\u00e9es lors de l'import, mais il est \u00e9galement possible de cocher \"Save large image\", faire ceci permet d'avoir un fichier de projet .db relativement autonome et sera facilement partageable \u00e0 d'autres personnes sans que ces derni\u00e8res n'aient besoin des images.</li> <li>les fonctions par d\u00e9faut \u00e0 executer pour chaque outil de similarit\u00e9</li> <li>le type de vecteurs par d\u00e9faut \u00e0 utiliser pour les outils de similarit\u00e9</li> <li>les param\u00e8tres relatifs \u00e0 chacun des plugins install\u00e9s</li> </ul>"},{"location":"advanced/projectparams/#activer-ou-desactiver-les-plugins-pour-un-projet","title":"Activer ou d\u00e9sactiver les plugins pour un projet","text":"<p>Lorsque l'on installe un plugin dans panoptic, il est automatiquement activ\u00e9 pour tous les projets. Mais en r\u00e9alit\u00e9 tous les projets n'auront pas forc\u00e9ment besoin de tous les plugins, ainsi un projet sans image contenant du texte n'aura pas besoin du plugin d'OCR.  Il est donc ainsi possible de d\u00e9sactiver les plugins non n\u00e9cessaires \u00e0 un projet, depuis la page d'accueil en cliquant sur les trois petits points \u00e0 c\u00f4t\u00e9 du nom du projet:</p> <p></p> <p>Il suffira ensuite de cocher ou d\u00e9cocher les plugin \u00e0 activer / d\u00e9sactiver.</p>"},{"location":"advanced/tags/","title":"Les tags","text":"<p>Les tags sont les types de propri\u00e9t\u00e9s les plus courants pour r\u00e9aliser des annotations. Il en existe deux types diff\u00e9rents: - les tags simples: ils permettent d'assigner un seul et unique tag \u00e0 une image - les multi tags: ils permettent d'assigner autant de tags que l'on souhaite \u00e0 une image</p>"},{"location":"advanced/tags/#tags-hierarchiques","title":"Tags hi\u00e9rarchiques","text":"<p>Dans certains cas il peut \u00eatre utile de vouloir cr\u00e9er simultan\u00e9ment plusieurs annotations, par exemple si je souhaite annoter mon image avec le terme \"Joconde\" et que plus tard je veux regrouper toutes mes images qui sont des tableaux, il peut \u00eatre utile de cr\u00e9er un tag tableau, et de lui ajouter comme \"enfant\" le tag Joconde. Une image tagg\u00e9e par \"joconde\" sera ainsi \u00e0 la fois tagg\u00e9e comme joconde et comme tableau.</p> <p>Il est possible de cr\u00e9er des liens de hi\u00e9rarchie entre tags en cliquant sur le bouton ci dessous: </p> <p></p> <p>Il suffit ensuite de choisir un tag existant ou d'en cr\u00e9er un nouveau dans le champ qui s'affiche pour ajouter un tag \"enfant\".</p> <p>## Multi \"parents\"</p> <p>Il est possible de cr\u00e9er des liens de hi\u00e9rarchie complexes. Un parent peut avoir plusieurs enfant, mais il est \u00e9galement possible qu'un enfant ait plusieurs parents. </p> <p>Cela permet d'assigner en une seule fois des cat\u00e9gories diff\u00e9rentes, si l'on reprend l'exemple pr\u00e9c\u00e9dent, \"joconde\" pourrait avoir \u00e9galement le tag \"femme\" en parent, assigner le tag \"joconde\" assignera alors \u00e9galement \"tableau\" et \"femme\".</p> <p>La gestion des tags peut devenir un peu complexe s'il y en a beaucoup et avec plusieurs liens de hi\u00e9rarchie, aussi il existe une fen\u00eatre d\u00e9di\u00e9e permettant de g\u00e9rer plus finement les tags et les images associ\u00e9es.</p>"},{"location":"advanced/tagsmodal/","title":"La fen\u00eatre de gestion des tags","text":"<p>La fen\u00eatre (ou modal) de gestion des tags permet de manipuler avec plus de facilit\u00e9 les tags afin de pouvoir: - les renommer - g\u00e9rer les liens de hi\u00e9rarchie - fusionner des tags si l'on estime cela n\u00e9cessaire</p> <p>Il existe deux vues possibles: - la vue liste, vue par d\u00e9faut qui permet d'afficher la liste des tags, de les trier par ordre alphab\u00e9tique ou par nombre d'images associ\u00e9e \u00e0 ces tags - la vue arbre, qui est plus visuelle et est particuli\u00e8rement utile lorsque l'on cherche \u00e0 comprendre l'organisation hi\u00e9rarchique des tags </p>"},{"location":"advanced/tagsmodal/#acces","title":"Acc\u00e8s","text":"<p>Pour ouvrir cette fen\u00eatre il suffit de cliquer sur le logo d'agrandissement \u00e0 c\u00f4t\u00e9 d'une propri\u00e9t\u00e9 de type tag ou multitags: </p>"},{"location":"advanced/tagsmodal/#trier-les-tags","title":"Trier les tags","text":"<p>Dans la vue liste, il est facile de filtrer les tags en cherchant dans le champ recherche, ou encore de les trier en prenant en compte soit leur nom soit le nombre d'images associ\u00e9es \u00e0 chaque tag. </p> <p>Il suffit pour cela d'utiliser les boutons de tri</p> <p></p>"},{"location":"advanced/tagsmodal/#selection-multiple","title":"S\u00e9lection multiple","text":"<p>Lorsque l'on clique sur un tag, ses images associ\u00e9es s'affiche \u00e0 droite. Mais il est \u00e9galement possible de s\u00e9lectionner plusieurs tags \u00e0 la fois, en maintenant la touche controle (ou shift pour s\u00e9lectionner une plage de tags), il est alors int\u00e9ressant de noter que les images associ\u00e9es \u00e0 tous les tags s\u00e9lectionn\u00e9s en m\u00eame temps, ce qui peut \u00eatre pratique pour comparer des tags.</p>"},{"location":"advanced/tagsmodal/#fusion","title":"Fusion","text":"<p>Lorsque plusieurs tags sont s\u00e9lectionn\u00e9s il est possible de les fusionner, le tag \"r\u00e9sultant de la fusion\" sera le premier tag s\u00e9lectionn\u00e9. Il est possible de fusionner autant de tags \u00e0 la fois que l'on souhaite. Tous les liens de parent\u00e9s seront \u00e9galement conserv\u00e9s.</p>"},{"location":"advanced/tagsmodal/#creer-des-liens-de-hierarchie","title":"Cr\u00e9er des liens de hi\u00e9rarchie","text":"<p>Comme \u00e9nonc\u00e9 sur la page pr\u00e9c\u00e9dente il est possible de cr\u00e9er des liens de hi\u00e9rarchie entre les tags. Cette op\u00e9ration est ici facilit\u00e9e dans la modale et ce particuli\u00e8rement dans la vue en arbre. </p> <p>Il suffit de cliquer sur un tag et de maintenir appuy\u00e9 pour tirer un lien jusqu'au tag que l'on souhaite ajouter comme enfant. Le lien se fait donc dans le sens \"parent -&gt; enfant\". </p> <p>Il est \u00e9galement possible de g\u00e9rer ces liens dans la vue liste, il suffit de prendre un tag et de le glisser d\u00e9poser dans la colonne souhait\u00e9e (parent ou enfant) d'un autre tag. </p>"},{"location":"install/install/","title":"Installation","text":"<p>Pr\u00e9requis mat\u00e9riels</p> <p>Panoptic a \u00e9t\u00e9 pens\u00e9 et con\u00e7u pour \u00eatre \u00e9xecut\u00e9 sur un ordinateur local. De nombreux efforts d'optimisations ont \u00e9t\u00e9 effectu\u00e9s pour que le logiciel puisse tourner sur le plus de machines possibles, n\u00e9anmoins plus le nombre d'images augmentera et plus une machine dot\u00e9e d'un bon processeur et d'au moins 16Go de RAM sera conseill\u00e9e pour une bonne exp\u00e9rience d'utilisation.</p>"},{"location":"install/install/#avec-des-fichiers-dinstallation-recommande","title":"Avec des fichiers d'installation (recommand\u00e9)","text":""},{"location":"install/install/#installation_1","title":"Installation","text":"<p>Cette installation \u00e0 base de script permet d'installer la bonne version de python, ainsi que toutes les d\u00e9pendances pour \u00eatre s\u00fbr d'\u00eatre compatible:</p> <p>Note</p> <p>Il vous sera demand\u00e9 au milieu de l'installation si vous souhaitez installer une version pour carte graphique. Cela permet d'acc\u00e9ler l'importation des images qui peut \u00eatre longue mais prendra plus de place sur votre disque. Il est important de noter que cela ne fonctionne qu'avec des cartes graphiques NVidia.</p> WindowsLinuxmacOS <p>Un executable est disponible sur ce lien et permet d'installer et de lancer Panoptic au sein d'un environnement virtuel. </p> <pre><code>wget https://raw.githubusercontent.com/CERES-Sorbonne/Panoptic/refs/heads/main/install/start_panoptic_linux.sh -O start_panoptic_linux.sh\nchmod +x start_panoptic_linux.sh\n./start_panoptic_linux.sh\n</code></pre> <pre><code>curl -O https://raw.githubusercontent.com/CERES-Sorbonne/Panoptic/refs/heads/main/install/start_panoptic_mac2.sh\nchmod +x start_panoptic_mac.sh\n./start_panoptic_mac.sh\n</code></pre>"},{"location":"install/install/#lancement","title":"Lancement","text":"Windows (cmd)LinuxmacOS <p>Il suffit de lancer panoptic.exe </p> <pre><code>./start_panoptic_linux.sh\n</code></pre> <p>D'autre part le script ajoute normalement \u00e9galement une icone permettant de lancer panoptic depuis un clic sur l'icone.</p> <pre><code>./start_panoptic_mac.sh\n</code></pre>"},{"location":"install/install/#avec-python","title":"Avec python","text":""},{"location":"install/install/#installation_2","title":"Installation","text":"<p>Si vous avez d\u00e9j\u00e0 python d'install\u00e9, avec une version sup\u00e9rieure ou \u00e9gale \u00e0 <code>3.10</code> vous pouvez simplement \u00e9xecuter dans un terminal: </p> Windows (cmd)LinuxmacOS <pre><code>pip install panoptic\n</code></pre> <pre><code>pip3 install panoptic\n</code></pre> <pre><code>pip3 install panoptic\n</code></pre> <p>Utilisateurs Mac OS</p> <p>Les outils xcode ont besoin d'\u00eatre install\u00e9s pr\u00e9alablement pour que panoptic puisse fonctionner convenablement sur MacOS. </p> <p>Ces derniers peuvent \u00eatre install\u00e9s via: <code>xcode-select --install</code></p> <p>D'autre part, de nombreuses d\u00e9pendances doivent avoir des versions pr\u00e9cises pour fonctionner sous mac. Il est ainsi recommand\u00e9 d'utiliser le script d'installation de panoptic fourni plus bas.</p> <p>Note</p> <p>Dans les trois cas il est possible de remplacer <code>panoptic</code> dans la commande par <code>panoptic[vision]</code> pour installer panoptic avec le module de similarit\u00e9 directement</p>"},{"location":"install/install/#lancement_1","title":"Lancement","text":"<p>Entrez la commande <code>panoptic</code> dans votre terminal</p>"},{"location":"install/install/#utilisation-dun-environnement-virtuel","title":"Utilisation d'un environnement virtuel","text":"<p>Les paquets python pouvant facilement entrer en conflits en fonction des versions il est conseill\u00e9 d'installer panoptic dans un environnement python d\u00e9di\u00e9. </p> Windows (cmd)LinuxmacOS <pre><code>python -m venv panoptic_env\npanoptic_env\\Scripts\\activate\npip install panoptic\n</code></pre> <pre><code>python3 -m venv panoptic_env\nsource panoptic_env/bin/activate\npip3 install panoptic\n</code></pre> <pre><code>python3 -m venv panoptic_env\nsource panoptic_env/bin/activate\npip3 install panoptic\n</code></pre>"},{"location":"install/install/#lancement_2","title":"Lancement","text":"Windows (cmd)LinuxmacOS <pre><code>panoptic_env\\Scripts\\activate\npanoptic\n</code></pre> <pre><code>source panoptic_env/bin/activate\npanoptic\n</code></pre> <pre><code>source panoptic_env/bin/activate\npanoptic\n</code></pre>"},{"location":"install/install/#installation-avec-docker","title":"Installation avec Docker","text":"<p>Si vous avez rencontr\u00e9 des probl\u00e8mes avec l'installation classique, ou que vous pr\u00e9f\u00e9rez utiliser Docker, une image est \u00e0 disposition. Il faut tout d'abord:</p>"},{"location":"install/install/#installer-docker","title":"Installer Docker","text":"<ul> <li>Sur MacOS</li> <li>Sur Windows</li> <li>Sur Linux</li> </ul>"},{"location":"install/install/#option-1-un-seul-dossier-pour-les-images-et-pour-les-donnees-panoptic","title":"Option 1: Un seul dossier pour les images et pour les donn\u00e9es panoptic:","text":"<p>Cela implique d'avoir cr\u00e9\u00e9 un dossier sp\u00e9cial appel\u00e9 \"images\", dans le dossier que vous indiquerez en entr\u00e9e de panoptic. Dans l'exemple suivant, il faudrait ainsi que dans le dossier: <code>/chemin/vers/le/dossier</code>, il existe un dossier <code>images</code> dont le chemin complet serait par cons\u00e9quent <code>/chemin/vers/le/dossier/images</code>.</p> <p>Il faut ensuite lancer la commande suivante (avec Docker de lanc\u00e9 au pr\u00e9alable)</p> <pre><code>docker run -it -p 8000:8000 -v /path/to/your/folder:/data --name panoptic ceressorbonne/panoptic\n</code></pre>"},{"location":"install/install/#option-2-un-dossier-pour-les-images-et-un-dossier-pour-les-donnees-panoptic","title":"Option 2: Un dossier pour les images, et un dossier pour les donn\u00e9es panoptic:","text":"<pre><code>docker run -it -p 8000:8000 \\\n-v /path/to/your/data:/data \\\n-v /path/to/your/images:/data/images \\\n--name panoptic \\\nceressorbonne/panoptic\n</code></pre>"},{"location":"install/install_dev/","title":"Installation (d\u00e9veloppement)","text":"<p>Si vous souhaitez contribuer \u00e0 panoptic en modifiant le code ou en d\u00e9veloppant des plugins vous aurez besoin de pouvoir faire tourner panoptic en mode d\u00e9veloppement.</p> <p>Commencez par cloner le repository avec: </p> <pre><code>git clone https://github.com/CERES-Sorbonne/Panoptic.git\n</code></pre>"},{"location":"install/install_dev/#developpement-backend-uniquement","title":"D\u00e9veloppement backend uniquement","text":"<p>Pour tester et modifier le fonctionnement backend, nous fournissons un front-end d\u00e9j\u00e0 build\u00e9 dans le dossier html du back:</p> <ul> <li>aller dans le dossier <code>panoptic-back</code></li> <li>pour installer les d\u00e9pendances: <pre><code>pip install -e .\n</code></pre></li> <li>lancer:  <pre><code>panoptic\n</code></pre></li> </ul>"},{"location":"install/install_dev/#developpement-front-et-back","title":"D\u00e9veloppement front et back","text":"<ol> <li>r\u00e9aliser tout d'abord les \u00e9tapes d'installation du backend</li> <li>aller dans le dossier <code>panoptic-front</code></li> <li>lancer <code>npm install</code></li> <li>lancer <code>npm run dev</code></li> <li>avant de lancer le backend la variable d'environnement <code>PANOPTIC_ENV</code> devra \u00eatre set \u00e0 <code>DEV</code> afin d'utiliser le frontend de d\u00e9veloppement.</li> </ol>"},{"location":"install/install_plugin/","title":"Installation (Fin)","text":"<p>Info</p> <p>Si vous avez install\u00e9 panoptic avec un script / un exe ou en utilisant panoptic[vision] cette \u00e9tape peut \u00eatre ignor\u00e9e</p> <p>Par soucis de flexibilit\u00e9, Panoptic est install\u00e9 sans les outils de similarit\u00e9. Dans la plupart des cas vous voudrez les installer pour utiliser les fonctionnalit\u00e9s de clustering et de similarit\u00e9 d'image.</p> <p>Il suffit pour ceci de cliquer sur le bouton \"Installer le Plugin de Similarit\u00e9\" sur la page d'accueil de panoptic une fois celui ci lanc\u00e9. Cela prendra quelques instants par les librairies peuvent \u00eatre un peu lourdes \u00e0 t\u00e9l\u00e9charger (plusieurs centaines de Mo).</p> <p></p> <p>Utilisation d'une carte graphique</p> <p>Si vous poss\u00e9dez une carte graphique (GPU), cela peut acc\u00e9l\u00e9rer le fonctionnement de panoptic lors de l'import des images. Toutefois, en fonction de la mani\u00e8re dont vous avez install\u00e9 panoptic et de votre syst\u00e8me d'exploitation vous n'aurez pas toujours les librairies GPU d'install\u00e9es par d\u00e9faut. Des informations d'installation des versions cuda de pytorch sont disponibles pour chaque OS sur ce lien.</p> <p>A noter que l'execution de panoptic ne sera pas impact\u00e9e si vous ne poss\u00e9dez pas de GPU, seul l'import des images (qui ne se produit qu'une fois) sera plus lent.</p>"},{"location":"method/clusters/","title":"Cr\u00e9er des clusters pour identifier des tendances","text":""},{"location":"method/clusters/#objectif","title":"Objectif","text":"<p>Utiliser les outils de clustering de panoptic afin d'identifier diff\u00e9rentes cat\u00e9gories d'images dans un corpus.</p>"},{"location":"method/clusters/#corpus","title":"Corpus","text":"<p>Prenons l'exemple d'un corpus de photos d'oeuvres de gr\u00e8ce antique: </p> <p></p> <p>Ce corpus semble n'\u00eatre pas facilement d\u00e9coupable en sous ensembles bien d\u00e9finis comme en t\u00e9moigne un aper\u00e7u dans la vue spatiale: </p> <p></p>"},{"location":"method/clusters/#clustering","title":"Clustering","text":"<p>Commencer par cr\u00e9er un clustering normal. Il peut \u00eatre int\u00e9ressant de tester de rentrer un nombre de clusters automatique (-1) si le nombre d'images n'est pas trop \u00e9lev\u00e9:</p> <p></p> <p>On voit que pour les premiers clusters les r\u00e9sultats sont assez coh\u00e9rents au niveau des types d'images regroup\u00e9es ensemble.  En revanche si l'on descend un peu et que l'on regarde les clusters avec un score plus \u00e9lev\u00e9 (donc avec une plus grande dispersion, c'est \u00e0 dire une plus grande vari\u00e9t\u00e9 d'images) on constate effectivement un ensemble m\u00e9ritant d'\u00eatre encore un peu s\u00e9par\u00e9.</p> <p></p>"},{"location":"method/clusters/#clustering-imbriques","title":"Clustering imbriqu\u00e9s","text":"<p>On peut venir ainsi reclusteriser les clusters que l'on consid\u00e8re comme trop larges, on peut parfois retenter -1, mais \u00e9galement demander parfois une s\u00e9paration en un nombre sp\u00e9cifique de clusters quand il appara\u00eet \u00e0 l'oeil nu que deux ensemble se d\u00e9gagent d'un m\u00eame cluster, comme par exemple le cluster entour\u00e9 dans l'image ci-dessous, qui contenait des statues d'athena sur socle jaune et des statues en noir et blanc et qu'on a donc divis\u00e9 par deux. </p> <p></p> <p>On peut ainsi continuer it\u00e9rativement et continuer \u00e0 d\u00e9couper nos clusters jusqu'\u00e0 obtenir un niveau de d\u00e9tail satisfaisant.</p> <p>On peut noter le cas int\u00e9ressant de l'exemple ci-dessous o\u00f9 l'on a tent\u00e9 de redemander un d\u00e9coupage -1 \u00e0 un groupe qui avait \u00e9t\u00e9 marqu\u00e9 ayant un score de 1000 (globalement le chiffre maximum retourn\u00e9 par le clustering et consid\u00e8re que le groupe est tr\u00e8s peu coh\u00e9rent), et cela a \u00e0 nouveau produit un groupe \u00e0 1000, c'est \u00e0 dire que l'algorithme n'a pas \u00e9t\u00e9 capable de d\u00e9couper de fa\u00e7on pertinente ce cluster l\u00e0. Dans ces cas l\u00e0 tout particuli\u00e8rement il devient n\u00e9cessaire de sp\u00e9cifier un nombre d\u00e9fini de clusters \u00e0 produire pour forcer un d\u00e9coupage:</p> <p></p>"},{"location":"method/clusters/#sauvegarder-les-clusters","title":"Sauvegarder les clusters","text":"<p>Une fois que l'on est satisfait on peut venir sauvegarder le r\u00e9sultat du cluster pour en faire une propri\u00e9t\u00e9 persist\u00e9e et par laquelle on va pouvoir venir manipuler les images. </p>"},{"location":"method/clusters/#demander-des-recommandations","title":"Demander des recommandations","text":"<p>Une fois que la propri\u00e9t\u00e9 est cr\u00e9\u00e9e on peut grouper les images par cette propri\u00e9t\u00e9 et venir demander des recommandations \u00e0 panoptic pour voir si certains pourraient \u00eatre compl\u00e9t\u00e9s.  Ici par exemple on observe un cluster assez large contenant des vases ou des assiettes, en m\u00e9tal ou en c\u00e9ramique, on peut alors soit demander des recommandations g\u00e9n\u00e9rale comme sur l'image ci-dessous, ce qui va nous proposer de nouvelles assiettes et vases, soit il est peut \u00eatre pertinent de red\u00e9couper ce groupe afin d'\u00eatre plus pr\u00e9cis dans son contenu. </p> <p></p>"},{"location":"method/clusters/#renommer-ses-clusters","title":"Renommer ses clusters","text":"<p>Une fois ce travail r\u00e9alis\u00e9, il est possible d'ouvrir la propri\u00e9t\u00e9 cr\u00e9\u00e9e \u00e0 l'\u00e9tape de sauvegarde des clusters dans la modale des tags afin de revenir sur les clusters un \u00e0 un pour les renommer et leur donner des noms pertinents en fonction de leur contenu, ou encore de venir fusionner certains tags au cas o\u00f9 on aurait trop d\u00e9coup\u00e9 certains ensembles au moment du clustering. (Pour ce faire on s\u00e9lectionne deux tags en maintenant la touche SHIFT).</p> <p></p>"},{"location":"method/duplicates/","title":"Identifier les doublons","text":"<p>Ceci est un placeholder pour la documentation sur l'identification des doublons.</p>"},{"location":"method/intro/","title":"Introduction","text":""},{"location":"method/intro/#methodologie","title":"M\u00e9thodologie","text":"<p>Cette section vise \u00e0 pr\u00e9senter quelques m\u00e9thodologies et pratiques que nous ou d'autres personnes utilisant panoptic ont pu d\u00e9velopper. Elles ne sont pas exhaustives, ni parfaites et vise simplement \u00e0 donner de grandes id\u00e9es sur des fa\u00e7ons d'utiliser l'outil. De plus, elles ne sont pas ind\u00e9pendantes les unes des autres et peuvent bien s\u00fbres \u00eatre combin\u00e9es pour s'adapter \u00e0 de nouveaux besoins. D'autre part, il est possible que ces fiches viennent \u00e0 \u00eatre modifi\u00e9es avec l'apparition de nouvelles fonctionnalit\u00e9s du fait du d\u00e9veloppement continu de l'outil.</p> <p>En r\u00e9sum\u00e9 rapide de celles qui seront pr\u00e9sent\u00e9es ici: - Utiliser des clusters pour identifier des tendances visuelles dans un corpus et les annoter - Trouver des doublons parfait ou tr\u00e8s proches dans un corpus - Nettoyer un corpus en filtrant le bruit  - Importer un th\u00e9saurus ou une liste de propri\u00e9t\u00e9s pour annoter les images avec</p>"},{"location":"method/noise/","title":"D\u00e9bruiter son corpus","text":"<p>Ceci est un placeholder pour la documentation sur le d\u00e9bruitage de corpus.</p>"},{"location":"method/thesaurus/","title":"Importer un th\u00e9saurus et cat\u00e9goriser les images automatiquement","text":""},{"location":"method/workspaces/","title":"G\u00e9rer ses espaces de travail","text":"<p>Ceci est un placeholder pour la documentation sur la gestion des espaces de travail.</p>"},{"location":"plugins/add/","title":"Installer un plugin","text":"<p>Installer un plugin est (normalement) relativement facile, il suffit d'avoir l'adresse d'un r\u00e9pertoire github (ou gitlab) sur lequel le code du plugin est stock\u00e9. Par exemple: https://github.com/PanopticOrg/PanopticOCR</p> <p>Dans panoptic il faut ensuite se rendre sur la page principale et cliquer sur le + :</p> <p></p> <p>On rentre ensuite l'url git, on clique dans le champ nom (qui devrait se remplir automatiquement \u00e0 partir de l'url) puis on clique sur Installer.</p> <p></p> <p>Le plugin devrait alors s'installer et une fois fini il devient disponible pour tous les projets.</p>"},{"location":"plugins/create/","title":"Cr\u00e9er ses propres plugins","text":"<p>Si les plugins d\u00e9j\u00e0 existant ne correspondent pas \u00e0 vos usages, n'h\u00e9sitez pas \u00e0 cr\u00e9er les votres, ils consistent en grande partie en du code python libre dans lesquels vous \u00e9crirez le comportement souhait\u00e9. Il suffit de respecter un format et de connaitre les quelques fonctions panoptic permettant de se raccorder aux actions de l'interface. </p> <p>Un guide d\u00e9taill\u00e9 avec exemple est disponible ici: </p> <p>https://github.com/CERES-Sorbonne/Panoptic/wiki/Plugin</p>"},{"location":"plugins/dev/","title":"Cr\u00e9er ses plugins","text":""},{"location":"plugins/dev/#apercu","title":"Aper\u00e7u","text":"<p>Panoptic impl\u00e9mente un syst\u00e8me de plugins qui vous permet de personnaliser votre fa\u00e7on de travailler avec vos donn\u00e9es d'images. L'interface peut s'adapter \u00e0 divers r\u00e9sultats d'action, ce qui en fait un outil pratique pour la visualisation et la manipulation de donn\u00e9es.</p>"},{"location":"plugins/dev/#comment-ca-marche","title":"Comment \u00e7a marche","text":"<p>Les plugins \u00e9tendent Panoptic en s'int\u00e9grant \u00e0 plusieurs niveaux :</p> <ul> <li>Actions de l'interface utilisateur \u2013 Enregistrez des actions personnalis\u00e9es qui apparaissent dans l'interface et op\u00e8rent sur les images s\u00e9lectionn\u00e9es.</li> <li>\u00c9v\u00e9nements syst\u00e8me \u2013 R\u00e9pondez \u00e0 des \u00e9v\u00e9nements tels que l'importation d'images ou la suppression de dossiers pour automatiser les mises \u00e0 jour de donn\u00e9es.</li> <li>Couche de donn\u00e9es \u2013 D\u00e9finissez des propri\u00e9t\u00e9s personnalis\u00e9es, stockez des vecteurs et g\u00e9rez des structures de donn\u00e9es dans la base de donn\u00e9es du projet.</li> </ul> <p>Les fonctionnalit\u00e9s d'apprentissage automatique de Panoptic \u2014 vecteurs CLIP, clustering FAISS, recherche par similarit\u00e9 et d\u00e9tection de doublons \u2014 sont impl\u00e9ment\u00e9es dans le plugin PanopticML : https://github.com/CERES-Sorbonne/PanopticML</p> <p>Il constitue un bon exemple pour comprendre comment d\u00e9velopper votre propre plugin.</p>"},{"location":"plugins/dev/#chargement-et-cycle-de-vie-des-plugins","title":"Chargement et cycle de vie des plugins","text":"<p>Les plugins sont charg\u00e9s au niveau du projet, ce qui signifie que chaque projet Panoptic peut avoir son propre ensemble de plugins actifs avec des configurations sp\u00e9cifiques au projet. Lorsqu'un projet s'ouvre, ses plugins sont initialis\u00e9s et restent actifs pendant toute la dur\u00e9e de vie du projet. Un plugin est identifi\u00e9 par un nom unique.</p>"},{"location":"plugins/dev/#composants-principaux","title":"Composants principaux","text":"<p>PluginProjectInterface : L'interface principale que les plugins utilisent pour interagir avec le projet Panoptic. Elle donne acc\u00e8s \u00e0 :</p> <ul> <li>Op\u00e9rations de base de donn\u00e9es (instances, propri\u00e9t\u00e9s, tags, vecteurs)</li> <li>Gestion des t\u00e2ches pour les op\u00e9rations de longue dur\u00e9e</li> <li>Syst\u00e8me d'\u00e9v\u00e9nements pour r\u00e9agir aux changements du projet</li> <li>D\u00e9clencheurs de mise \u00e0 jour de l'interface utilisateur</li> </ul> <p>APlugin : La classe de base dont tous les plugins doivent h\u00e9riter. Elle g\u00e8re :</p> <ul> <li>L'enregistrement des actions pour l'int\u00e9gration \u00e0 l'interface utilisateur</li> <li>La gestion des abonnements aux \u00e9v\u00e9nements</li> <li>L'acc\u00e8s aux ressources sp\u00e9cifiques du plugin</li> </ul>"},{"location":"plugins/dev/#ressources-des-plugins","title":"Ressources des plugins","text":"<p>Chaque plugin a acc\u00e8s \u00e0 :</p> <ul> <li>Dossier de donn\u00e9es : Un r\u00e9pertoire d\u00e9di\u00e9 pour stocker les donn\u00e9es sp\u00e9cifiques au plugin, les mod\u00e8les, les caches ou tout fichier persistant dont le plugin a besoin.</li> <li>Interface de projet : Acc\u00e8s complet aux donn\u00e9es et op\u00e9rations du projet via <code>PluginProjectInterface</code>.</li> <li>Chemin de base : Le r\u00e9pertoire racine du projet pour acc\u00e9der aux fichiers du projet.</li> </ul>"},{"location":"plugins/dev/#configuration-du-plugin","title":"Configuration du plugin","text":"<p>Avant qu'un plugin puisse interagir avec un projet Panoptic, il doit \u00eatre correctement initialis\u00e9 et enregistr\u00e9. Cette section explique comment d\u00e9finir la classe du plugin, configurer ses param\u00e8tres et enregistrer des actions ou des \u00e9v\u00e9nements afin qu'il s'int\u00e8gre de mani\u00e8re transparente dans l'environnement Panoptic.</p>"},{"location":"plugins/dev/#classe-de-base","title":"Classe de base","text":"<p>Chaque plugin h\u00e9rite de <code>APlugin</code> et est instanci\u00e9 avec trois param\u00e8tres :</p> <pre><code>class MonPlugin(APlugin):\n    def __init__(self, project: Project, plugin_path: str, name: str):\n        super().__init__(name=name, project=project, plugin_path=plugin_path)\n        # Initialisez votre plugin ici\n</code></pre> <ul> <li><code>project</code> : Le projet Panoptic charg\u00e9.</li> <li><code>plugin_path</code> : Le chemin du syst\u00e8me de fichiers o\u00f9 se trouve votre plugin.</li> <li><code>name</code> : L'identifiant unique de votre plugin.</li> </ul> <p>Pour \u00e9viter de bloquer le thread de l'application, vous pouvez ex\u00e9cuter des charges de travail lourdes en surchargeant la fonction asynchrone <code>_start()</code>. <code>_start()</code> est appel\u00e9e automatiquement lors du chargement du plugin.</p> <pre><code>async def _start(self):\n    # Charger les mod\u00e8les, cr\u00e9er les propri\u00e9t\u00e9s initiales, etc.\n</code></pre>"},{"location":"plugins/dev/#attributs-disponibles","title":"Attributs disponibles","text":"Attribut Type Description <code>name</code> <code>str</code> L'identifiant du plugin, fourni par l'utilisateur lors de son enregistrement dans Panoptic. <code>params</code> <code>Any</code> Objet <code>params</code> personnalisable qui offre un stockage persistant pour les param\u00e8tres du plugin. Ceux-ci peuvent \u00eatre mis \u00e0 jour depuis l'interface utilisateur. <code>path</code> <code>str</code> Chemin du syst\u00e8me de fichiers vers le r\u00e9pertoire du plugin. <code>data_path</code> <code>Path</code> Chemin vers le dossier de donn\u00e9es personnel du plugin. Le dossier est automatiquement supprim\u00e9 lors de la suppression du plugin. <code>project</code> <code>PluginProjectInterface</code> Interface principale pour interagir avec le projet en cours. Donne acc\u00e8s aux m\u00e9thodes du projet et aux op\u00e9rations de base de donn\u00e9es. <code>_project</code> <code>Project</code> Attention : L'objet projet r\u00e9el donn\u00e9 \u00e0 l'initialisation. \u00c0 n'utiliser qu'en cas de n\u00e9cessit\u00e9. Les mises \u00e0 jour de l'interface utilisateur ne sont pas garanties pour les modifications directes. <code>registered_functions</code> <code>List[FunctionDescription]</code> Liste des actions actuellement enregistr\u00e9es par ce plugin. <code>vector_types</code> <code>list[VectorType]</code> Types de vecteurs enregistr\u00e9s par votre plugin, mis \u00e0 jour automatiquement lors de leur modification. <code>base_key</code> <code>str</code> Cl\u00e9 de base de donn\u00e9es unique utilis\u00e9e pour stocker les param\u00e8tres du plugin (<code>&lt;nom_plugin&gt;.base</code>)."},{"location":"plugins/dev/#methodes-disponibles","title":"M\u00e9thodes disponibles","text":"M\u00e9thode Type Description <code>def add_action(self, function, description)</code> M\u00e9thode Enregistre manuellement une action personnalis\u00e9e en fournissant une <code>FunctionDescription</code>. <code>def add_action_easy(self, function, hooks: list[str] = None)</code> M\u00e9thode Enregistre rapidement une fonction asynchrone en tant qu'action. Vous pouvez sp\u00e9cifier o\u00f9 l'action appara\u00eet dans l'interface utilisateur en d\u00e9finissant les hooks. Valeurs possibles : <code>'vector_type'</code>, <code>'vector'</code>, <code>'similar'</code>, <code>'group'</code>, <code>'execute'</code>"},{"location":"plugins/dev/#parametres-du-plugin","title":"Param\u00e8tres du plugin","text":"<p>Les param\u00e8tres de plugin permettent aux utilisateurs de configurer le comportement d'un plugin sans modifier son code. D\u00e9finissez les param\u00e8tres de votre plugin en cr\u00e9ant un <code>BaseModel</code> Pydantic. Ces param\u00e8tres peuvent \u00eatre ajust\u00e9s via l'interface utilisateur et sont automatiquement conserv\u00e9s dans la base de donn\u00e9es.</p> <pre><code>from pydantic import BaseModel\n\nclass MesParamsPlugin(BaseModel):\n    # Drapeaux bool\u00e9ens\n    auto_process_imports: bool = True\n\n    # Param\u00e8tres num\u00e9riques\n    batch_size: int = 32\n    confidence_threshold: float = 0.75\n\n    # Options de cha\u00eene de caract\u00e8res\n    output_format: str = \"json\"\n</code></pre> <p>Pour chaque type, l'interface utilisateur affiche un champ de saisie adapt\u00e9 :</p> <ul> <li><code>int</code> : Champ num\u00e9rique</li> <li><code>float</code> : Champ num\u00e9rique avec d\u00e9cimales</li> <li><code>str</code> : Champ de texte</li> <li><code>bool</code> : Case \u00e0 cocher</li> <li><code>PropertyId</code> : S\u00e9lection de propri\u00e9t\u00e9</li> <li><code>Enum</code> : Champ de s\u00e9lection</li> <li><code>VectorType</code> : S\u00e9lection de n'importe quel vecteur enregistr\u00e9</li> <li><code>OwnVectorType</code> : S\u00e9lection de vecteur enregistr\u00e9 par le plugin lui-m\u00eame</li> </ul> <p>Initialisez les param\u00e8tres dans le <code>__init__</code> de votre plugin :</p> <pre><code>class MonPlugin(APlugin):\n    def __init__(\n        self, \n        project: PluginProjectInterface, \n        plugin_path: str, \n        name: str\n    ):\n        super().__init__(name=name, project=project, plugin_path=plugin_path)\n\n        # Initialiser avec les valeurs par d\u00e9faut\n        self.params = MesParamsPlugin()\n</code></pre>"},{"location":"plugins/dev/#creation-de-fonctions","title":"Cr\u00e9ation de fonctions","text":"<p>Les fonctions de plugin sont des m\u00e9thodes asynchrones qui effectuent des op\u00e9rations sur les donn\u00e9es du projet. Elles re\u00e7oivent un <code>ActionContext</code> et peuvent \u00e9galement d\u00e9clarer des entr\u00e9es suppl\u00e9mentaires :</p> <pre><code>async def ma_fonction(self, context: ActionContext, param1: str):\n\n    # Obtenir les instances s\u00e9lectionn\u00e9es par l'utilisateur\n    instances = await self.project.get_instances(context.instance_ids)\n\n    # Traiter les donn\u00e9es\n    results = process_data(instances, param1)\n\n    # Retourner les r\u00e9sultats\n    return ActionResult(\n        groups=[results],\n        notifs=[Notif(NotifType.INFO, \"Succ\u00e8s\", \"Traitement termin\u00e9\")]\n    )\n</code></pre> <p><code>ActionContext</code> est d\u00e9fini comme suit :</p> <p><pre><code>@dataclass  \nclass ActionContext:  \n    instance_ids: List[int] | None = None  \n</code></pre> Les valeurs refl\u00e8tent le contexte actuel de l'interface utilisateur dans lequel l'action a \u00e9t\u00e9 appel\u00e9e. Utilisez <code>instance_ids</code> pour savoir sur quelles instances appliquer l'action.</p> <p>Des param\u00e8tres suppl\u00e9mentaires peuvent \u00eatre d\u00e9finis tant qu'ils sont l'un des types pris en charge : <code>int, float, str, bool, PropertyId, Enum, VectorType, OwnVectorType</code></p> <p>Une fonction de plugin valide doit retourner un <code>ActionResult</code> :</p> <pre><code>@dataclass  \nclass ActionResult:  \n    groups: list[Group] = None  \n    notifs: list[Notif] = None  \n    value: Any = None\n</code></pre> <ul> <li><code>groups</code> : Groupes d'images \u00e0 afficher dans l'interface utilisateur.</li> <li><code>notifs</code> : Notifications (<code>INFO</code>, <code>ERROR</code>, <code>WARNING</code>).</li> <li><code>value</code> : Espace r\u00e9serv\u00e9 pour les r\u00e9sultats \u00e0 valeur unique.</li> </ul>"},{"location":"plugins/dev/#actionresult","title":"ActionResult","text":"<p>L'objet <code>ActionResult</code> sert de type de retour unifi\u00e9 pour les actions des plugins.</p> <pre><code>@dataclass  \nclass ActionResult:  \n    groups: list[Group] = None  \n    notifs: list[Notif] = None  \n    value: Any = None\n</code></pre>"},{"location":"plugins/dev/#groupes","title":"Groupes","text":"<p>Lorsqu'elles sont appel\u00e9es depuis les vues d'instances, les actions <code>group</code>, <code>similar</code> et <code>execute</code> peuvent montrer des groupes d'instances \u00e0 l'utilisateur en remplissant le champ <code>groups</code>.</p> <p>Un <code>Group</code> est d\u00e9fini comme suit : <pre><code>@dataclass  \nclass Group:  \n    ids: list[int] = None  \n    sha1s: list[str] = None  \n    # scores des ids ou sha1s  \n    scores: ScoreList = None  \n    # score du groupe  \n    score: Score = None  \n    name: str = None\n</code></pre></p> <p>Vous pouvez peupler le groupe avec des <code>instances</code> ou des <code>images</code> en remplissant les champs <code>ids (instances)</code> ou <code>sha1s (images)</code>. Remplir les deux champs ne doit pas \u00eatre fait et donnera des r\u00e9sultats inattendus dans l'interface utilisateur.</p> <p>Les groupes et les instances/images peuvent avoir un score. <pre><code>@dataclass  \nclass Score:  \n    value: float  \n    min: float  \n    max: float  \n    description: str = ''  \n    max_is_best: bool = True\n</code></pre></p> <p>D\u00e9finir les champs <code>min</code>/<code>max</code> permet \u00e0 l'interface utilisateur d'afficher des options de filtrage adapt\u00e9es. Le champ <code>max_is_best</code> est utilis\u00e9 pour inverser le sens du tri. Le champ <code>description</code> donne des informations \u00e0 l'utilisateur sur l'interpr\u00e9tation de ce score.</p> <p>Pour noter les instances/images, remplissez le champ <code>scores</code> avec une <code>ScoreList</code> : <pre><code>@dataclass  \nclass ScoreList:  \n    values: list[float]  \n    min: float  \n    max: float  \n    description: str = ''  \n    max_is_best: bool = True\n</code></pre> La seule diff\u00e9rence est que le champ <code>value</code> est maintenant un tableau. Les valeurs doivent \u00eatre dans le m\u00eame ordre que les <code>ids</code> ou <code>sha1s</code>.</p> <p>Vous pouvez \u00e9galement donner un nom personnalis\u00e9 \u00e0 votre groupe \u00e0 afficher avec <code>name</code>. Si aucun nom n'est d\u00e9fini, un nom par d\u00e9faut sera donn\u00e9.</p>"},{"location":"plugins/dev/#notifications","title":"Notifications","text":"<p>Une action peut retourner des notifications pour l'utilisateur. <pre><code>class Notif:  \n    type: NotifType  \n    name: str = None  \n    message: str = None  \n    data: Any = None  \n    functions: list[NotifFunction] = None  \n\nclass NotifType(Enum):  \n    DEBUG = \"debug\"  \n    INFO = \"info\"  \n    WARNING = \"warning\"  \n    ERROR = \"error\"\n\nclass NotifFunction:  \n    function: str  \n    context: ActionContext\n    message: str\n</code></pre></p> <ul> <li><code>type</code> : type de notification pour le filtrage</li> <li><code>name</code> : nom de la notification \u00e0 afficher</li> <li><code>message</code> : message de la notification</li> <li><code>data</code> : Toutes donn\u00e9es affich\u00e9es en JSON dans l'interface utilisateur</li> <li><code>functions</code> : Suggestion d'actions \u00e0 afficher dans l'interface utilisateur.</li> </ul> <p>Le champ <code>NotifFunction.function</code> attend l'identifiant de cha\u00eene de la fonction. Vous pouvez l'obtenir en sauvegardant la description de la fonction lors de l'enregistrement des actions, comme indiqu\u00e9 dans la section suivante.</p> <pre><code>description = self.add_action_easy(self.ma_fonction, hooks)\ndescription.id # contient l'identifiant de cha\u00eene de la fonction\n</code></pre>"},{"location":"plugins/dev/#enregistrement-des-actions","title":"Enregistrement des actions","text":"<p>Les fonctions peuvent \u00eatre enregistr\u00e9es dans le constructeur du plugin <code>__init__()</code>. Deux fonctions sont disponibles pour ce faire : <pre><code>def add_action_easy(\n    self, \n    function: AsyncCallable, \n    hooks: list[str] = None\n) -&gt; FunctionDescription\n\ndef add_action(\n    self, \n    function: AsyncCallable, \n    description: FunctionDescription\n) -&gt; FunctionDescription\n</code></pre> La fonction <code>add_action_easy()</code> analyse automatiquement la signature de la fonction donn\u00e9e et la documentation en ligne pour g\u00e9n\u00e9rer une <code>FunctionDescription</code>. Le tableau <code>hooks</code> d\u00e9finit o\u00f9 dans l'interface utilisateur la fonction doit \u00eatre rendue disponible. Les hooks actuels sont : - <code>'vector_type'</code> : Actions de cr\u00e9ation de type de vecteur - <code>'vector'</code> : Actions de calcul de vecteur - <code>'similar'</code> : Actions de recherche de similarit\u00e9 - <code>'group'</code> : Actions de clustering et de regroupement - <code>'execute'</code> : Actions d'ex\u00e9cution g\u00e9n\u00e9rales</p> <p>La <code>FunctionDescription</code> donne \u00e0 l'interface utilisateur toutes les informations n\u00e9cessaires pour cr\u00e9er un \u00e9l\u00e9ment d'interface adapt\u00e9 aux entr\u00e9es des fonctions. Les param\u00e8tres ont des \u00e9tiquettes, des descriptions et des champs de saisie personnalisables. Pour plus de contr\u00f4le sur l'interface utilisateur, vous pouvez remplir vous-m\u00eame l'objet <code>FunctionDescription</code> et enregistrer la fonction avec <code>add_action()</code>.</p>"},{"location":"plugins/dev/#evenements-systeme","title":"\u00c9v\u00e9nements syst\u00e8me","text":"<p>Les plugins peuvent \u00e9galement \u00e9couter des \u00e9v\u00e9nements pour r\u00e9agir en cons\u00e9quence :</p> <pre><code>def on_instance_import(self, \n    callback: Callable[[Instance], \n    Awaitable[None]]\n)\n\ndef on_folder_delete(\n    self, \n    callback: Callable[[DeleteFolderConfirm],\n    Awaitable[None]]\n)\n</code></pre> <p>Par exemple, le plugin <code>PanopticML</code> utilise l'\u00e9v\u00e9nement d'importation d'instance pour calculer automatiquement les vecteurs d'image et l'\u00e9v\u00e9nement de suppression de dossier pour mettre \u00e0 jour ses index de vecteurs FAISS.</p>"},{"location":"plugins/dev/#donnees","title":"Donn\u00e9es","text":"<p>Les plugins ont souvent besoin de lire et d'\u00e9crire des donn\u00e9es de projet. Cette section d\u00e9taille comment acc\u00e9der aux instances, aux tags et aux vecteurs depuis la base de donn\u00e9es, et comment valider en toute s\u00e9curit\u00e9 les modifications tout en gardant l'interface utilisateur synchronis\u00e9e avec l'\u00e9tat du projet.</p>"},{"location":"plugins/dev/#lecture","title":"Lecture","text":"<p>L'interface du plugin fournit des m\u00e9thodes pour interroger divers types de donn\u00e9es de la base de donn\u00e9es du projet.</p> <p>La premi\u00e8re \u00e9tape consiste g\u00e9n\u00e9ralement \u00e0 r\u00e9cup\u00e9rer plus d'informations sur les instances \u00e0 partir de <code>ActionContext</code> :</p> <pre><code># Obtenir des instances par ID\ninstances = await self.project.get_instances(ids=[1, 2, 3])\n# Obtenir des instances par hachages SHA1\ninstances = await self.project.get_instances(sha1s=[\"abc123...\", \"def456...\"])\n# Obtenir toutes les instances (sans filtres)\ninstances = await self.project.get_instances()\n</code></pre> <p>Pour chaque type de donn\u00e9es dans Panoptic, l'interface donne acc\u00e8s aux requ\u00eates de base de donn\u00e9es correspondantes :</p> <pre><code># Dossiers\nget_folders() -&gt; list[Folder]\n\n# Propri\u00e9t\u00e9s\nget_properties(ids: list[int] = None, computed: bool = False) -&gt; list[Property]\n\n# Tags\nget_tags(ids: list[int] = None, property_ids: list[int] = None) -&gt; list[Tag]\n\n# Valeurs de propri\u00e9t\u00e9 d'instance\nget_instance_property_values(\n    property_ids: list[int] = None, \n    instance_ids: list[int] = None\n) -&gt; list[PropertyValue]\n\n# Valeurs de propri\u00e9t\u00e9 d'image\nget_image_property_values(\n    property_ids: list[int] = None, \n    sha1s: list[str] = None\n) -&gt; list[PropertyValue]\n\n# Vecteurs\nget_vectors(type_id: int, sha1s: list[str] = None) -&gt; list[Vector]\nvector_exist(type_id: int, sha1: str) -&gt; bool\n\n# Types de vecteurs\nget_vector_types(source: str = None) -&gt; list[VectorType]\n</code></pre> <p>Plusieurs options de filtrage sont trait\u00e9es comme des conditions OU.</p>"},{"location":"plugins/dev/#ecriture","title":"\u00c9criture","text":"<p>L'\u00e9criture dans la base de donn\u00e9es du projet se fait principalement avec le syst\u00e8me de commit. Les types suivants prennent en charge la fonctionnalit\u00e9 d'annulation/r\u00e9tablissement et la synchronisation automatique de l'interface utilisateur lors de l'utilisation de commits :</p> <p><code>folders</code>, <code>instances</code>, <code>properties</code>, <code>property_groups</code>, <code>tags</code>, <code>instance_values</code> et <code>image_values</code>.</p> <p>Un objet de commit contient un lot de mises \u00e0 jour :</p> <pre><code>class DbCommit:  \n    empty_instances: list[int]\n    empty_property_groups: list[int]\n    empty_properties: list[int]\n    empty_tags: list[int]\n    empty_instance_values: list[InstancePropertyKey]\n    empty_image_values: list[ImagePropertyKey]\n\n    folders: list[Folder] \n    instances: list[Instance]\n    property_groups: list[PropertyGroup]\n    properties: list[Property]\n    tags: list[Tag]  \n    instance_values: list[InstanceProperty]\n    image_values: list[ImageProperty]\n\n    timestamp: datetime\n</code></pre> <p>Pour supprimer des objets, marquez-les dans les listes <code>empty_</code> correspondantes.</p> <p>Certains objets ont un ID unique de type <code>int</code>. Lors de la cr\u00e9ation de nouveaux objets, vous devez d\u00e9finir un ID n\u00e9gatif. Des fonctions d'assistance sont fournies pour garantir une attribution d'ID correcte :</p> <pre><code>def create_instance(\n    self, \n    folder_id: int, \n    name: str, \n    extension: str, \n    sha1: str, \n    url: str, \n    width: int, \n    height: int, \n    ahash: str\n) -&gt; Instance\n\ndef create_property(\n    self, \n    name: str, \n    type_: PropertyType, \n    mode: PropertyMode\n) -&gt; Property\n\ndef create_property_group(\n    self,\n    name: str\n) -&gt; PropertyGroup\n\n\ndef create_tag(\n    self, \n    property_id: int,\n    value: str, \n    parent_ids: list[int] = None, \n    color=-1\n) -&gt; Tag\n\ndef create_vector_type(\n    self, \n    params: dict \n) -&gt; VectorType\n</code></pre> <p>Les ID n\u00e9gatifs sont valides \u00e0 l'int\u00e9rieur d'un commit et peuvent \u00eatre r\u00e9f\u00e9renc\u00e9s par d'autres nouveaux objets. Par exemple, une <code>InstanceValue</code> peut r\u00e9f\u00e9rencer \u00e0 la fois une nouvelle instance et une nouvelle propri\u00e9t\u00e9 avec des ID n\u00e9gatifs. Lors de l'\u00e9criture dans la base de donn\u00e9es, Panoptic d\u00e9termine automatiquement l'ordre d'insertion correct et met \u00e0 jour les ID une fois les objets stock\u00e9s.</p> <p>Ex\u00e9cutez un commit \u00e0 l'aide de l'une des m\u00e9thodes suivantes :</p> <pre><code>async def apply_commit(self, commit: DbCommit)\n\nasync def do(self, commit: DbCommit)\n</code></pre> <p>La fonction <code>do()</code> calcule le commit oppos\u00e9 avant d'appeler <code>apply_commit()</code>, permettant \u00e0 l'op\u00e9ration d'\u00eatre invers\u00e9e plus tard avec <code>undo()</code>.</p> <p>Deux types d'objets ne sont pas \u00e9crits via des commits : <code>vector_type</code> et <code>vector</code>. Utilisez plut\u00f4t les m\u00e9thodes correspondantes :</p> <pre><code>async def add_vector_type(self, vec: VectorType) -&gt; VectorType\n\nasync def add_vector(self, vector: Vector) -&gt; Vector\n</code></pre>"},{"location":"plugins/dev/#calcul-lourd-et-concurrence","title":"Calcul lourd et concurrence","text":"<p>Le backend de Panoptic s'ex\u00e9cute dans une boucle d'\u00e9v\u00e9nements asynchrone. Pour \u00e9viter de bloquer le thread principal, les charges de travail lourdes doivent \u00eatre ex\u00e9cut\u00e9es dans un <code>ThreadPoolExecutor</code>. Il existe deux mani\u00e8res principales de le faire dans Panoptic.</p>"},{"location":"plugins/dev/#assistant-asynchrone","title":"Assistant asynchrone","text":"<p>Le moyen le plus simple de d\u00e9l\u00e9guer une fonction bloquante \u00e0 l'ex\u00e9cuteur est d'utiliser l'assistant :</p> <pre><code>res = await self.project.run_async(function, *args)\n</code></pre> <p>Utilisez cet assistant pour les t\u00e2ches d'arri\u00e8re-plan simples qui n'ont pas besoin d'\u00eatre suivies ou visualis\u00e9es dans l'interface utilisateur. Il est id\u00e9al pour les op\u00e9rations l\u00e9g\u00e8res o\u00f9 vous avez juste besoin de d\u00e9charger une fonction bloquante sur un thread d'arri\u00e8re-plan et d'attendre le r\u00e9sultat de mani\u00e8re asynchrone.</p> <p>Les exemples incluent :</p> <ul> <li>Ex\u00e9cuter de petites transformations de donn\u00e9es</li> <li>Effectuer des op\u00e9rations d'E/S de fichiers l\u00e9g\u00e8res</li> <li>Appeler une fois une fonction de biblioth\u00e8que bloquante</li> </ul>"},{"location":"plugins/dev/#la-file-dattente-des-taches","title":"La file d'attente des t\u00e2ches","text":"<p>La <code>TaskQueue</code> est con\u00e7ue pour g\u00e9rer et suivre les t\u00e2ches d'arri\u00e8re-plan. Chaque t\u00e2che peut inclure une s\u00e9quence de fonctions asynchrones ou synchrones trait\u00e9es comme une seule unit\u00e9 de travail.</p> <p>Son principal avantage est de fournir un retour visuel dans l'interface utilisateur via une barre de progression. De plus, il prend en charge l'ex\u00e9cution de fonctions sp\u00e9cifiques une fois qu'un ensemble de t\u00e2ches est termin\u00e9.</p>"},{"location":"plugins/dev/#creation-dune-tache","title":"Cr\u00e9ation d'une t\u00e2che","text":"<p>H\u00e9ritez de la classe de base <code>Task</code> et impl\u00e9mentez la m\u00e9thode <code>run()</code> :</p> <pre><code>from panoptic.core.task.task import Task\n\nclass MaTacheDeTraitement(Task):\n    def __init__(self, plugin, instance, config):\n        super().__init__(priority=False)  # Mettez priority=True pour les t\u00e2ches urgentes\n        self.plugin = plugin\n        self.instance = instance\n        self.config = config\n\n        # Personnaliser l'identification de la t\u00e2che\n        self.name = 'Traiter l'image'  # Montr\u00e9 dans l'interface utilisateur\n        self.key = f'task_1'  # Identifiant unique\n\n    async def run(self):\n        \"\"\"Ex\u00e9cution principale de la t\u00e2che - s'ex\u00e9cute en arri\u00e8re-plan\"\"\"\n        # Utiliser _async() pour les op\u00e9rations gourmandes en CPU\n        result = await self.run_async(\n            self._calcul_lourd,\n            self.instance.url,\n            self.config\n        )\n\n        # Stocker les r\u00e9sultats (les op\u00e9rations de base de donn\u00e9es sont d\u00e9j\u00e0 asynchrones)\n        await self.plugin.project.add_vector(result)\n\n        return result\n\n    async def run_if_last(self):\n        \"\"\"Appel\u00e9 une fois que toutes les t\u00e2ches avec cette cl\u00e9 sont termin\u00e9es\"\"\"\n        # Reconstruire les index, mettre \u00e0 jour l'interface utilisateur ou effectuer un nettoyage\n        await self.plugin.rebuild_index()\n\n    @staticmethod\n    def _calcul_lourd(image_path, config):\n        \"\"\"Le travail gourmand en CPU s'ex\u00e9cute dans le thread de l'ex\u00e9cuteur\"\"\"\n        # Charger et traiter l'image\n        image = Image.open(image_path)\n\n        # Effectuer un calcul lourd\n        vectors = extract_vectors(image, config)\n\n        return vectors\n</code></pre> <p>Le champ <code>self.key</code> a deux objectifs :</p> <ul> <li>Ex\u00e9cute la fonction <code>run_if_last()</code> sur la derni\u00e8re t\u00e2che avec la m\u00eame cl\u00e9.</li> <li>Regroupe les t\u00e2ches associ\u00e9es dans l'interface utilisateur.</li> </ul>"},{"location":"plugins/dev/#ajout-de-taches-a-la-file-dattente","title":"Ajout de t\u00e2ches \u00e0 la file d'attente","text":"<p>Ajoutez des t\u00e2ches depuis votre plugin \u00e0 l'aide de l'interface de projet :</p> <pre><code>def add_task(self, task: Task):\n</code></pre> <p>La barre des t\u00e2ches devrait maintenant \u00eatre visible dans l'interface utilisateur.</p>"},{"location":"plugins/dev/#exemple-etape-par-etape","title":"Exemple \u00e9tape par \u00e9tape","text":"<p>Ce guide vous montrera comment cr\u00e9er un nouveau plugin \u00e9tape par \u00e9tape. Notre objectif est d'ajouter des fonctions personnalis\u00e9es \u00e0 Panoptic : - <code>compute_vectors()</code> : une fonction qui calcule les vecteurs d'image - <code>compute_clusters()</code> : une fonction qui calcule des clusters pour une liste d'instances</p> <p>Pour que ce soit tr\u00e8s simple, nous impl\u00e9menterons une fonction qui calcule les vecteurs d'une s\u00e9lection d'instances avec le hook <code>execute</code>. Et une fonction de clustering avec le hook <code>group</code>. Nous n'aurons qu'un seul type de vecteur par d\u00e9faut.</p>"},{"location":"plugins/dev/#dossier","title":"Dossier","text":"<p>Un plugin est contenu dans un dossier que nous appellerons <code>mon_plugin</code>. \u00c0 l'int\u00e9rieur de ce dossier, nous cr\u00e9ons trois fichiers : <code>__init__.py</code>, <code>mon_plugin.py</code> et <code>requirements.txt</code>.</p> <pre><code>mon_plugin\n| __init__.py\n| mon_plugin.py\n| requirements.txt\n</code></pre> <ul> <li><code>__init__.py</code> est le point d'entr\u00e9e pour le chargeur de plugins.</li> <li><code>requirements.txt</code> contient les d\u00e9pendances de modules pip pour le plugin. Dans notre cas, il sera vide.</li> <li><code>mon_plugin.py</code> contient le code du plugin.</li> </ul>"},{"location":"plugins/dev/#initialisation-du-plugin","title":"Initialisation du plugin","text":"<pre><code># mon_plugin.py\n\nfrom panoptic.core.plugin.plugin import APlugin  \nfrom panoptic.core.project.project import Project  \nfrom panoptic.models import ActionContext  \nfrom panoptic.models.results import ActionResult  \n\n\nclass MonPlugin(APlugin):  \n    def __init__(self, project: Project, plugin_path: str, name: str):  \n        \"\"\"  \n        La m\u00e9thode d'initialisation pour un plugin Panoptic. \n        Est appel\u00e9e par Panoptic au lancement du projet.        \n        :param project: L'instance du projet        \n        :param plugin_path: Le chemin vers le module du plugin        \n        :param name: L'identifiant du plugin en tant que nom unique\n        \"\"\"        \n        # n'oubliez pas d'appeler le constructeur parent  \n        super().__init__(name=name, project=project, plugin_path=plugin_path)  \n        self.add_action_easy(self.compute_vectors, ['vector'])  \n        self.add_action_easy(self.compute_clusters, ['group'])  \n\n    async def compute_vectors(self, ctx: ActionContext):  \n        res = ActionResult()  \n        # du code ...  \n        return res  \n\n    async def compute_clusters(self, ctx: ActionContext, nb_clusters: int):  \n        res = ActionResult()  \n        # du code ...  \n        return res\n</code></pre> <p>Cet extrait de code d\u00e9finit notre classe de plugin. Il est important d'appeler le constructeur parent dans notre propre fonction <code>__init__(..)</code> pour initialiser correctement le plugin. Nous pouvons ensuite enregistrer notre fonction et s\u00e9lectionner nos hooks d'action. La fonction <code>compute_vectors()</code> est enregistr\u00e9e en tant qu'action <code>vector</code> et la fonction <code>compute_clusters()</code> en tant qu'action <code>group</code>.</p> <p>Le corps de la fonction est vide pour l'instant, mais pour s'assurer que l'interface utilisateur est satisfaite, nous retournons d\u00e9j\u00e0 un <code>ActionResult</code>.</p> <pre><code># __init__.py\nfrom mon_plugin import MonPlugin  \n\nplugin_class = MonPlugin\n</code></pre> <p>Enfin, nous d\u00e9clarons la <code>plugin_class</code> dans le fichier <code>__init__.py</code>.</p> <p>Vous pouvez maintenant d\u00e9marrer Panoptic et ajouter votre plugin. Vous devriez voir votre fonction de clustering sur le <code>ActionButton</code> de <code>group</code>.</p> <p></p> <p>Comme vous pouvez le voir, notre fonction de calcul de vecteur n'est pas visible dans l'interface utilisateur. C'est parce que nous n'avons enregistr\u00e9 aucun <code>vector_type</code> pour notre plugin. Les types de vecteurs servent d'identifiant pour les vecteurs.</p> <p></p>"},{"location":"plugins/dev/#creation-de-vecteurs","title":"Cr\u00e9ation de vecteurs","text":"<p>Pour stocker des vecteurs dans la base de donn\u00e9es, nous devons enregistrer un <code>vector_type</code> pour eux. Pour cet exemple, nous n'aurons qu'un seul type pour nos vecteurs factices.</p> <pre><code>async def _start(self):  \n    if len(self.vector_types) == 0:  \n        vec_type = self.project.create_vector_type({\"model\": \"fake_vector\"})  \n        await self.project.add_vector_type(vec_type)  \n        print('cr\u00e9\u00e9 ', vec_type)\n</code></pre> <p>Nous impl\u00e9mentons la fonction <code>_start()</code>, qui est automatiquement appel\u00e9e lors du chargement du plugin. La variable <code>self.vector_types</code> est automatiquement mise \u00e0 jour avec les types de vecteurs cr\u00e9\u00e9s par ce plugin. Si la liste est vide, nous voulons en cr\u00e9er un. Comme d'autres objets, les types de vecteurs ont un ID entier unique g\u00e9r\u00e9 par la base de donn\u00e9es. Vous pouvez cr\u00e9er un nouveau type de vecteur \u00e0 l'aide de la fonction utilitaire : <pre><code>self.project.create_vector_type(params: dict)\n</code></pre> Ensuite, nous ajoutons le type de vecteur \u00e0 la base de donn\u00e9es avec <pre><code>await self.project.add_vector_type(vec_type) \n</code></pre></p> <p><code>self.vec_type</code> contient maintenant notre nouveau type de vecteur, et il est visible dans l'interface utilisateur.</p> <p> Et notre fonction de calcul de vecteur est maintenant appelable en cliquant sur le bouton <code>compute</code> dans la ligne du vecteur.</p> <p>Nous voulons placer les images dans un espace vectoriel \u00e0 1 dimension o\u00f9 la valeur repr\u00e9sente la teinte principale (0-255) de l'image. Notre fonction de calcul ressemble \u00e0 ceci : <pre><code>@staticmethod  \ndef compute_hue_vector(path: str):  \n    img = Image.open(path)  \n    img = img.convert('RGB')  \n    img_hsv = img.convert('HSV')  \n\n    # Obtenir les donn\u00e9es HSV en tant que tableau numpy  \n    hsv_array = np.array(img_hsv)  \n\n    # Extraire le canal de teinte (premier canal en HSV)  \n    hue_channel = hsv_array[:, :, 0]  \n\n    # Aplatir et calculer l'histogramme  \n    hue_flat = hue_channel.flatten()  \n\n    # Obtenir la valeur de teinte la plus courante  \n    counts = np.bincount(hue_flat)  \n    dominant_hue = np.argmax(counts)  \n\n    # Vecteur \u00e0 1 dimension. Convertir en float32 pour correspondre au type de la base de donn\u00e9es\n    return np.array(int(dominant_hue), dtype='float32')\n</code></pre></p> <p>et notre fonction <code>compute_vectors()</code> mise \u00e0 jour</p> <pre><code>async def compute_vectors(self, ctx: ActionContext):  \n    # obtenir les instances de la base de donn\u00e9es  \n    instances = await self.project.get_instances(ids=ctx.instance_ids)  \n    # ne garder qu'une seule instance par sha1  \n    unique = list({i.sha1: i for i in instances}.values())  \n    # obtenir notre id de type de vecteur  \n    type_id = self.vector_types[0].id  \n\n    for instance in unique:  \n        # calculer le vecteur de teinte dans l'ex\u00e9cuteur pour \u00e9viter de bloquer \n        # le thread principal  \n        hue_vector = await self.project.run_async(\n            self.compute_hue_vector, instance.url\n        )  \n        # cr\u00e9er l'objet vecteur \u00e0 \u00e9crire dans la base de donn\u00e9es  \n        vector = Vector(type_id=type_id, sha1=instance.sha1, data=hue_vector)  \n        # \u00e9crire dans la base de donn\u00e9es  \n        await self.project.add_vector(vector)  \n\n    # envoyer une notification de succ\u00e8s  \n    notif = Notif(\n        type=NotifType.INFO, \n        name='compute_vectors', \n        message='Tous les vecteurs ont \u00e9t\u00e9 calcul\u00e9s'\n    )  \n    # toujours retourner un ActionResult  \n    return ActionResult(notifs=[notif])\n</code></pre> <p>Il est important d'envelopper les fonctions gourmandes en calcul avec la fonction <code>run_async</code>. Encore mieux, vous pouvez utiliser les interfaces <code>Task</code> et <code>TaskQueue</code> pour ex\u00e9cuter des calculs en arri\u00e8re-plan. Vous pouvez vous r\u00e9f\u00e9rer au plugin officiel PanopticML pour un exemple qui utilise un objet <code>Task</code>.</p> <p>\u00c0 la fin, nous retournons une notification pour indiquer que le calcul s'est termin\u00e9 avec succ\u00e8s. Cette notification appara\u00eetra dans l'interface utilisateur une fois l'action termin\u00e9e.</p> <p> Si votre fonction plante sans gestion d'erreur appropri\u00e9e, Panoptic g\u00e9n\u00e9rera automatiquement une notification d'erreur qui inclut la stacktrace.</p> <p></p>"},{"location":"plugins/dev/#clustering","title":"Clustering","text":"<p>Maintenant que nous avons des vecteurs, nous pouvons commencer le clustering. Pour notre exemple, nous allons trier les images par valeur de teinte, puis cr\u00e9er un nombre choisi de groupes de taille \u00e9gale.</p> <p>Le calcul ressemble \u00e0 ceci : <pre><code>@staticmethod  \ndef group_instances_by_hue(\n    instances: list[Instance], \n    sha1_to_hue: dict[str, int], \n    num_groups: int\n    ):  \n    \"\"\"  \n    Trier les instances par teinte et les regrouper.    \n    \"\"\"   \n    # Utiliser np pour la simplicit\u00e9\n    id_array =  np.array([i.id for i in instances])  \n    hue_array =  np.array([sha1_to_hue[i.sha1] for i in instances])  \n\n    # Trier par teinte  \n    sorted_indices = np.argsort(hue_array)  \n    sorted_ids = id_array[sorted_indices]  \n    sorted_hue = hue_array[sorted_indices]  \n\n    # Diviser en groupes de taille \u00e9gale  \n    id_groups = np.array_split(sorted_ids, num_groups)  \n    hue_groups = np.array_split(sorted_hue, num_groups) \n\n    return id_groups, hue_groups\n</code></pre></p> <p>Nous devons int\u00e9grer ce r\u00e9sultat dans l'API <code>ActionResult</code>. <pre><code>async def compute_clusters(self, ctx: ActionContext, nb_clusters: int):  \n    # obtenir les instances de la base de donn\u00e9es  \n    instances = await self.project.get_instances(ids=ctx.instance_ids)  \n    # obtenir nos propres vecteurs de la base de donn\u00e9es  \n    vectors = await self.project.get_vectors(self.vector_types[0].id)  \n    # mapper sha1 \u00e0 la teinte avec les donn\u00e9es du vecteur  \n    sha1_to_hue = {v.sha1: v.data.tolist()[0] for v in vectors}  \n    # calculer les vecteurs avec les donn\u00e9es  \n    id_groups, hue_groups = self.group_instances_by_hue(\n        instances, sha1_to_hue, nb_clusters\n    )  \n\n    # it\u00e9rer sur le r\u00e9sultat et remplir les objets Group  \n    groups = []  \n    for id_group, hue_group in zip(id_groups, hue_groups):  \n        # obtenir la teinte min et max de chaque groupe  \n        min_hue = hue_group.min()  \n        max_hue = hue_group.max()  \n        # cr\u00e9er un groupe d'ID d'instance  \n        group = Group(\n            # extraire les ID d'instance du tableau np.array\n            ids=id_group.tolist(), \n            # choisir un nom pour le groupe\n            name=f\"Groupe de teintes : {min_hue}-{max_hue}\"\n        )  \n        groups.append(group)  \n\n    # retourner les clusters  \n    return ActionResult(groups=groups)\n</code></pre></p> <p>L'impl\u00e9mentation de <code>compute_vectors</code> est facile \u00e0 suivre. D'abord, nous r\u00e9cup\u00e9rons toutes les donn\u00e9es n\u00e9cessaires pour calculer notre clustering, puis nous utilisons <code>ActionResult</code> pour retourner les groupes \u00e0 l'interface utilisateur.</p> <p></p> <p>Appelez la fonction depuis l'<code>ActionButton</code> \"Cr\u00e9er des clusters\" et le r\u00e9sultat devrait \u00eatre visible dans l'interface utilisateur. Assurez-vous d'avoir ex\u00e9cut\u00e9 l'action de calcul de vecteur auparavant.</p> <p>Nous esp\u00e9rons que ce guide a pu rendre la logique derri\u00e8re le syst\u00e8me de plugins plus compr\u00e9hensible. Le plugin officiel PanopticML est la meilleure ressource pour avoir des exemples plus complexes d'utilisation de plugins.</p>"},{"location":"plugins/intro/","title":"Les plugins","text":"<p>Du fait de la multicit\u00e9 des usages et des traitements possibles applicables aux images, Panoptic n'int\u00e8gre pas de nombreuses fonctionnalit\u00e9s de base, ce qui permet de faciliter l'installation mais surtout de surcharger les utilisateurs avec un grand nombre de mod\u00e8les et de fonctionnalit\u00e9s. Ainsi, comme nous l'avons vu, m\u00eame les fonctionnalit\u00e9s \"natives\" de similarit\u00e9s de panoptic sont sous forme de plugin et il est en r\u00e9alit\u00e9 possible d'installer l'outil sans ce dernier si l'on souhaite simplement explorer un corpus et l'annoter sans utilisation de mod\u00e8les d'images. </p>"},{"location":"plugins/intro/#exemples-de-plugins","title":"Exemples de plugins","text":"<ul> <li>Une fonctionnalit\u00e9 souvent demand\u00e9e qui a \u00e9t\u00e9 d\u00e9velopp\u00e9e sous forme de plugin c'est l'OCRisation des images</li> <li>Un plugin pour faire du clustering sur les images bas\u00e9 sur les propri\u00e9t\u00e9s textuelles accompagnant ces images</li> <li>Un plugin permettant de calculer les couleurs dominantes d'images</li> <li>... </li> </ul>"},{"location":"plugins/list/","title":"Plugins existants","text":""},{"location":"plugins/list/#liste-des-plugins-existant","title":"Liste des plugins existant","text":"<p>Ci-dessous sont list\u00e9s bri\u00e8vement les plugins (autre que le plugin de similarit\u00e9), pour plus de d\u00e9tails, cliquer sur le lien: - PanopticOCR: Utilisation de DOCtr pour r\u00e9aliser de l'OCR sur les images s\u00e9lectionn\u00e9es, les r\u00e9sultats sont loin d'\u00eatre parfaits, mais permettent de faire une recherche approximative dans les propri\u00e9t\u00e9s textes cr\u00e9\u00e9es par le plugin. - PanopticColor: Calculs des valeurs de teinte, saturation, valeur, luminosit\u00e9 ainsi que rouge, bleu et vert des images, permettant de manipuler par la suite les images gr\u00e2ce \u00e0 leurs propri\u00e9t\u00e9s colorim\u00e9triques. - PanopticText: Permet de regrouper les images en fonction de propri\u00e9t\u00e9s textuelles associ\u00e9es \u00e0 ces images.</p>"},{"location":"start/annotate/","title":"Annoter les propri\u00e9t\u00e9s","text":"<p>Une fois une propri\u00e9t\u00e9 cr\u00e9\u00e9e et affich\u00e9e, il est possible d'annoter les images import\u00e9es.</p> <p>Lorsqu'une propri\u00e9t\u00e9 est affich\u00e9e, une ligne vide est affich\u00e9e en dessous de chaque image. Si l'on affiche deux propri\u00e9t\u00e9s, il y en aura deux d'afficher sous chaque image, etc.</p>"},{"location":"start/annotate/#annoter-une-image","title":"Annoter une image","text":"<p>Pour annoter une seule image, il suffit de cliquer sur l'espace vide associ\u00e9 \u00e0 la bonne propri\u00e9t\u00e9 sous l'image, et de compl\u00e9ter par l'annotation que l'on souhaite.</p> <p></p> <p>Une fois une annotation cr\u00e9\u00e9e, celle-ci est automatiquement propos\u00e9e pour les prochaines annotations.</p> <p></p>"},{"location":"start/annotate/#annoter-par-lots","title":"Annoter par lots","text":"<p>Il est possible d'annoter les images par lots. Lorsque l'on passe la souris sur une image, une coche cliquable s'affiche en haut \u00e0 droite de l'image. En cliquant, la coche devient bleue : l'image est s\u00e9lectionn\u00e9e. On peut comme cela en s\u00e9lectionner plusieurs. Il est possible de s\u00e9lectionner toutes les images situ\u00e9es entre deux images, en s\u00e9lectionnant ces deux images tout en maintenant la touche maj/shift appuy\u00e9e.</p> <p>Lorsque plusieurs images sont ainsi s\u00e9lectionn\u00e9es, appara\u00eet en haut \u00e0 droite de Panoptic une option \"Tagger les X images s\u00e9lectionn\u00e9es\". En cliquant dessus, on peut s\u00e9lectionner autant d'annotations qu'on le souhaite pour toutes les images s\u00e9lectionn\u00e9es. Cliquez enfin sur \"Appliquer\" et les images seront annot\u00e9es.</p> <p>Attention</p> <p>Une fois les images annot\u00e9es de cette mani\u00e8re, pensez bien \u00e0 d\u00e9s\u00e9lectionner les images s\u00e9lectionn\u00e9es pour ne pas les r\u00e9annoter plus tard. Pour les d\u00e9s\u00e9lectionner, cela se fait en cliquant sur la crois (x) \u00e0 gauche de \"Tagger les X images s\u00e9lectionn\u00e9es\" </p> <p></p>"},{"location":"start/annotate/#annoter-un-cluster-dimages-similaires","title":"Annoter un cluster d'images similaires","text":""},{"location":"start/annotate/#annoter-un-cluster-en-entier","title":"Annoter un cluster en entier","text":"<p>Pour r\u00e9aliser des clusters d'images similaires, voir la documentation sur les clusters.</p> <p>Il est possible d'annoter tout un cluster en cliquant sur l'option \"Tagger le groupe\" au-dessus d'un cluster.</p> <p>Dans la fen\u00eatre qui s\u2019ouvre, cliquez \u00e0 c\u00f4t\u00e9 de la propri\u00e9t\u00e9 cr\u00e9\u00e9e (sur \"None\"), et choisissez un tag d\u00e9j\u00e0 existant ou cr\u00e9ez en un. Enfin, faites \"Appliquer\".</p> <p></p>"},{"location":"start/annotate/#annoter-une-partie-dun-cluster-ou-plusieurs-parties-de-plusieurs-clusters","title":"Annoter une partie d\u2019un cluster, ou plusieurs parties de plusieurs clusters","text":"<p>Si les clusters propos\u00e9s ne conviennent pas suffisamment pour annoter, il est possible de ne s\u00e9lectionner qu\u2019une partie des images qui s\u2019affichent pour les annoter. Il suffit ici de reproduire l'annotation par lots d\u00e9crite plus t\u00f4t, mais au sein d'un cluster.</p> <p></p> <p>Important</p> <p>Il est possible de r\u00e9aliser des sous-clusters (voir la documentation sur les clusters). Ils fonctionnent comme les clusters et sont donc annotable de la m\u00eame mani\u00e8re.</p>"},{"location":"start/annotate/#sauvegarder-les-clusters","title":"Sauvegarder les clusters.","text":"<p>Par d\u00e9faut, les clusters ne sont pas sauvegard\u00e9s, car il s\u2019agit de propositions informatiques d\u2019associations d\u2019images qu\u2019un humain doit valider.</p> <p>Si l\u2019on souhaite sauvegarder un cluster, il faut donc le sp\u00e9cifier en cliquant sur l\u2019ic\u00f4ne de disquette \u00e0 c\u00f4t\u00e9 des clusters ouverts. On peut sauvegarder chaque cluster ou sous-cluster ind\u00e9pendament, ou bien l\u2019ensemble des clusters directement, en cliquant sur la disquette situ\u00e9e \u00e0 la racine (tout en haut, au-dessus des premi\u00e8res images).</p> <p>Lorsque l\u2019on sauvegarde des clusters, ceux-ci s\u2019enregistrent dans une propri\u00e9t\u00e9 d\u00e9di\u00e9e, nomm\u00e9e \"clustering\", que vous pouvez retrouver dans la partie gauche de l\u2019\u00e9cran, sous la section propri\u00e9t\u00e9.</p> <p>Vous pouvez ensuite renommer chaque \u00e9l\u00e9ment de cette propri\u00e9t\u00e9 pour donner du sens au clustering r\u00e9alis\u00e9, en vous rendant dans la fen\u00eatre de gestion des tags (voir la documentation sur la gestion des propri\u00e9t\u00e9s de type Tag et Multitags).</p> <p></p>"},{"location":"start/annotate/#annoter-des-images-similaires-a-une-image","title":"Annoter des images similaires \u00e0 une image","text":"<p>Lorsque l'on clique sur une image, s'ouvre une fen\u00eatre contextuelle proposant, \u00e0 gauche, les propri\u00e9t\u00e9s de l'image, et \u00e0 droite, les images similaires \u00e0 cette image s\u00e9lectionn\u00e9e.</p> <p></p> <p>Vous pouvez annoter directement, par lots, ces diff\u00e9rentes images. Plusieur soptions ici : </p> <p>Vous pouvez au choix : s\u00e9lectionner toutes les images affich\u00e9es (1), ou bien s\u00e9lectionner (ou d\u00e9s\u00e9lectionner) certaines images (2) pour affiner.</p> <p>Vous pouvez ensuite cliquer sur l\u2019ic\u00f4ne \"pot de peinture\" (3) pour annoter toutes les images s\u00e9lectionn\u00e9es en fonction de la propri\u00e9t\u00e9 choisie. Vous pouvez \u00e9galement cliquer en haut \u00e0 droite sur \"Tagger les X images s\u00e9lectionn\u00e9es\" pour ouvrir un menu affichant toutes les propri\u00e9t\u00e9s disponibles, et tagger les images s\u00e9lectionn\u00e9es comme bon vous semble (\u00e0 l\u2019identique de l\u2019image originale, ou bien diff\u00e9remment).</p> <p></p>"},{"location":"start/annotate/#annoter-des-images-similaires-a-un-groupe-dimages","title":"Annoter des images similaires \u00e0 un groupe d'images","text":"<p>Si vous avez d\u00e9j\u00e0 commenc\u00e9 \u00e0 annoter votre corpus d\u2019images, vous pouvez poursuivre l\u2019annotation en cherchant des images similaires \u00e0 un groupe d\u2019images d\u00e9j\u00e0 annot\u00e9es. Pour ce faire, il faut d\u2019abord grouper les images en fonction d\u2019une propri\u00e9t\u00e9 (voir la documentation sur le groupage d'images). Pour chaque groupe, il y a alors un bouton \"Propositions d\u2019images\" sur lequel vous pouvez cliquer (1).</p> <p></p> <p>Si des filtres sont actifs dans la vue dans laquelle vous travaillez, il est possible de choisir d\u2019afficher des images similaires seulement pr\u00e9sentes dans cette vue, ou non, en activant ou d\u00e9sactivant le filtre (2).</p> <p>Ajouter des images au groupe :</p> <p>Une fois que la fen\u00eatre de proposition d\u2019images est apparue, il vous suffit de cliquez sur la coche verte ou la croix rouge (3), pour accepter que l\u2019image propos\u00e9e rejoigne le groupe associ\u00e9e, ou non (c\u2019est-\u00e0-dire, pour valider ou non que l\u2019image soit tagg\u00e9e avec l\u2019annotation correspondante).</p> <p></p>"},{"location":"start/clusters/","title":"Les Clusters","text":"<p>Les clusters sont une notion particuli\u00e8rement importante dans le fonctionnement de Panoptic. Une fois les vecteurs calcul\u00e9s, les images peuvent \u00eatre regroup\u00e9es automatiquement gr\u00e2ce en clusters. Contrairement aux groupes cr\u00e9\u00e9s avec des propri\u00e9t\u00e9s, les clusters sont param\u00e9trables, peuvent \u00eatre g\u00e9n\u00e9r\u00e9s avec diff\u00e9rents algorithmes, et ne sont pas d\u00e9terministes (un m\u00eame clustering peut produire des r\u00e9sultats l\u00e9g\u00e8rement diff\u00e9rents selon les ex\u00e9cutions).</p>"},{"location":"start/clusters/#creer-des-clusters","title":"Cr\u00e9er des clusters","text":"<p>Une fois le projet lanc\u00e9 et les plugins charg\u00e9s, cliquer sur le bouton \"Cr\u00e9er des clusters\":</p> <p></p> <p>Cela devrait s\u00e9parer vos images en 10 groupes distincts par similarit\u00e9 comme sur l'image ci dessous:</p> <p></p>"},{"location":"start/clusters/#les-parametres","title":"Les param\u00e8tres","text":"<p>Il est \u00e9galement possible de choisir le nombre de clusters que l'on souhaite produire en cliquant sur la petite fl\u00e8che se situant sur le bouton \"Cr\u00e9er les clusters pour ouvrir les param\u00e8tres\".</p> <p></p> <p>Il suffit ensuite de modifier la valeur de nb_clusters pour indiquer le nombre de clusters \u00e0 cr\u00e9er.</p> <p></p> <p>Info</p> <p>Il existe d'autres param\u00e8tres visibles sur cette image pour des usages plus avanc\u00e9s que nous verrons plus tard.</p> <p>Nombre</p> <p>Il est \u00e9galement possible de demander un nombre automatique de clusters \u00e0 produire en entrant <code>-1</code> dans la valeur nb_clusters, mais il est \u00e0 noter que cela prendra plus de temps \u00e0 calculer et que le r\u00e9sultat sera vraiment variable d'un corpus \u00e0 l'autre.</p>"},{"location":"start/clusters/#les-scores","title":"Les scores","text":"<p>Les clusters produits poss\u00e8dent chacun un score affich\u00e9 en couleur \u00e0 c\u00f4t\u00e9 de leur nom, ces scores sont un indicateur de la pertinence du cluster, c'est \u00e0 dire \u00e0 quel point les images au sein de ce dernier sont proches les unes des autres. Plus le score est faible et plus le cluster est consid\u00e9r\u00e9 comme coh\u00e9rent. Ce score est l\u00e0 pour donner une id\u00e9e g\u00e9n\u00e9rale et peut varier d'un corpus \u00e0 l'autre. Autrement dit, si un score de 15 peut donner un cluster avec des images presque visuellement identiques dans certains corpus, cela sera peut \u00eatre plus disparate dans d'autres. Cela d\u00e9pend de la diversit\u00e9 et du nombre d'images pr\u00e9sentes dans ce dernier.</p>"},{"location":"start/clusters/#imbriquer-des-clusters","title":"Imbriquer des clusters","text":"<p>Une fonctionnalit\u00e9 importante de panoptic et la possibilit\u00e9 d'imbriquer des clusters. En effet, le postulat suivi ici est de dire que les mod\u00e8les d'apprentissage automatique ne produiront jamais de clustering parfait et que celui ci doit / peut \u00eatre retravaill\u00e9 par la personne utilisant panoptic. De fait il est possible de rediviser un cluster en rappuyant sur le bouton \"Cr\u00e9er des clusters\" afin d'affiner le regroupement des images. </p> <p>Ce processus peut \u00eatre d'ailleurs r\u00e9p\u00e9t\u00e9 ind\u00e9finiment (enfin tant qu'il reste des images \u00e0 s\u00e9parer).</p>"},{"location":"start/clusters/#sauvegarder-un-clustering","title":"Sauvegarder un clustering","text":"<p>Le processus de clustering est avant tout un outil d'exploration est n'est pas sauvegard\u00e9 automatiquement dans panoptic. Si l'on veut persister le travail effectu\u00e9 gr\u00e2ce \u00e0 cet outil, il faut soit avoir annot\u00e9 les images se trouvant dans les clusters soit cliquer sur le bouton de sauvegarde des clusters:</p> <p></p> <p>Ce bouton cr\u00e9\u00e9 une nouvelle propri\u00e9t\u00e9 nomm\u00e9e \"Clustering\" qui assignera \u00e0 chaque image le cluster o\u00f9 elle se trouvait sous forme de tag. Il est \u00e0 noter que comme les clusters peuvent \u00eatre imbriqu\u00e9s les tags pourront eux m\u00eames \u00eatre hi\u00e9rarchiques.</p>"},{"location":"start/clusters/#differentes-facons-de-clusteriser","title":"Diff\u00e9rentes fa\u00e7ons de clusteriser","text":"<p>La m\u00e9thode principale pr\u00e9sent\u00e9e jusqu'ici est celle par d\u00e9faut \"PanopticML.compute_clusters\" mais il existe dans le plugin de similarit\u00e9 d'autres fa\u00e7ons de cr\u00e9er des clusters, et d'autres plugins pourront \u00e9galement proposer d'autres fa\u00e7ons. Celles disponibles par d\u00e9faut dans le plugin de similarit\u00e9 sont les suivantes:</p> <ul> <li>compute_clusters: version par d\u00e9faut qui utiliser l'algorithme KMeans et regroupe les images en fonction d'un nombre de clusters demand\u00e9s, pratique pour it\u00e9rer rapidement et effectuer de \"grosses coupes\" dans un corpus.</li> <li>find_duplicates: cr\u00e9\u00e9 des groupes en assurant un minimum de seuil de similarit\u00e9 entre les images de ce groupes, cela peut \u00eatre pratique pour identifier les doublons ou doublons proches dans un corpus. Le seuil de similarit\u00e9 peut \u00eatre modifi\u00e9 pour \u00eatre plus ou moins permissif.</li> <li>cluster_by_tags: experimental, prend en entr\u00e9e une propri\u00e9t\u00e9 de type tags ou multitags et essaie de ratacher chaque image au tag dont elle est le plus proche.</li> </ul> <p>Cette m\u00e9thode peut \u00eatre choisie depuis un champ d\u00e9roulant dans les param\u00e8tres de clustering: </p> <p></p>"},{"location":"start/clusters/#pour-aller-plus-loin","title":"Pour aller plus loin","text":"<p>Pour des exemples concrets d'utilisation voir un exemple de m\u00e9thodologie utilisant le clustering</p>"},{"location":"start/filters/","title":"Manipuler les Images \u00e0 partir de leurs propri\u00e9t\u00e9s","text":"<p>Important</p> <p>Pr\u00e9alable n\u00e9cessaire au (r\u00e9)agencement d\u2019un corpus :</p> <p>Pour faire des FILTRES, des TRIS ou des GROUPES, des PROPRI\u00c9T\u00c9S doivent exister et \u00eatre remplies. Par exemple, on a r\u00e9alis\u00e9 de premi\u00e8res annotations d\u2019images du corpus de fa\u00e7on th\u00e9matique : \"papillon\", \"sport\"... Autre exemple, on a import\u00e9 au pr\u00e9alable des donn\u00e9es associ\u00e9es aux images, qui sont constitu\u00e9es en tant que propri\u00e9t\u00e9s lors de leur import.</p> <p>Ces diff\u00e9rentes fonctionnalit\u00e9s sont des fonctionnalit\u00e9s d'exploration visuelle~: tout se passe \u00e0 l'\u00e9cran, les (r\u00e9)agencements ne sont ni d\u00e9finitifs, ni destructifs du corpus. On peut constamment les annuler, les refaire, les modifier... On peut aussi multiplier ces (r\u00e9)agencements, pour explorer son corpus de diff\u00e9rentes mani\u00e8res, gr\u00e2ce \u00e0 la possibilit\u00e9 de cr\u00e9er diff\u00e9rents onglets au sein de Panoptic.</p> <p>Les (r\u00e9)agencements peuvent \u00eatre r\u00e9alis\u00e9s \u00e0 n'importe quel moment de l'exploration. On peut aussi les pr\u00e9voir \u00e0 l'avance, une fois les propri\u00e9t\u00e9s cr\u00e9\u00e9es, mais avant d'avoir annot\u00e9 quoique ce soit. Si l'on annote au cours du travail, on peut d\u00e9cider d'activer ou non l'actualisation automatique, pour que le corpus se r\u00e9agence dans la fen\u00eatre en temps r\u00e9el, ou seulement lorsqu'on le souhaite.</p>"},{"location":"start/filters/#filtrer","title":"Filtrer","text":"<ul> <li>Appuyez sur le \u201c+\u201d \u00e0 c\u00f4t\u00e9 de FILTRER.</li> <li>S\u00e9lectionnez la propri\u00e9t\u00e9 \u00e0 partir de laquelle vous voulez filtrer les images. Vous d\u00e9finissez ici les conditions d\u2019affichage des images</li> </ul>"},{"location":"start/filters/#pourquoi-filtrer","title":"Pourquoi filtrer ?","text":"<p>Les filtres peuvent \u00eatre pratiques dans diff\u00e9rents cas. Pour prendre un exemple, vous pouvez choisir de filtrer les images que vous avez d\u00e9j\u00e0 annot\u00e9, pour n\u2019afficher que celles que vous devez encore travailler.</p> <p>Autre exemple, vous pouvez \u00e9galement cr\u00e9er une propri\u00e9t\u00e9 de type CHECKBOX (\"case \u00e0 cocher\"), la nommer \"hors sujet\" ou encore \"annotation r\u00e9alis\u00e9e ?\", et d\u00e9cider que les images ne s\u2019affichent plus dans l\u2019onglet Panoptic actif d\u00e8s lors que vous avez coch\u00e9 la case.</p>"},{"location":"start/filters/#grouper","title":"Grouper","text":"<p>En cliquant sur le \"+\" \u00e0 c\u00f4t\u00e9 de la fonction GROUPE, s\u00e9lectionnez la propri\u00e9t\u00e9 \u00e0 partir de laquelle vous voulez faire le groupage d\u2019images. Une fois la propri\u00e9t\u00e9 s\u00e9lectionn\u00e9e, les groupes se constituent directement \u00e0 l\u2019\u00e9cran, dans le panneau central de Panoptic, suivant le crit\u00e8re donn\u00e9.</p>"},{"location":"start/filters/#reordonner-les-groupes-entre-eux","title":"R\u00e9ordonner les groupes entre eux :","text":"<p>Lorsque l\u2019on ajoute un type de groupage, celui-ci s\u2019indique \u00e0 c\u00f4t\u00e9 de l\u2019option GROUPER. Il est possible de changer le type de tri (nombre d\u2019\u00e9l\u00e9ments, alphab\u00e9tique) et l\u2019ordre (croissant ou d\u00e9croissant) en cliquant sur les fl\u00e8ches aff\u00e9rentes.</p>"},{"location":"start/filters/#groupes-et-sous-groupes","title":"Groupes et sous-groupes :","text":"<p>Il est possible de faire des groupes dans les groupes, par exemple en groupant par une propri\u00e9t\u00e9 th\u00e9matique (ce que l\u2019on a annot\u00e9 pour d\u00e9crire l\u2019image avec un mot cl\u00e9), puis par une propri\u00e9t\u00e9 import\u00e9e en m\u00e9tadonn\u00e9e, le nom du/de la photographe par exemple.</p>"},{"location":"start/filters/#supprimer-un-groupe","title":"Supprimer un groupe :","text":"<p>Pour supprimer un groupe, il suffit de cliquer sur le nom de la propri\u00e9t\u00e9 que l\u2019on veut supprimer, \u00e0 c\u00f4t\u00e9 de l\u2019option GROUPER.</p>"},{"location":"start/filters/#faire-des-clusters-dans-un-groupe","title":"Faire des clusters dans un groupe :","text":"<p>Il est possible de faire des clusters d\u2019images similaires au sein d\u2019un m\u00eame groupe d\u2019images afin de le r\u00e9agencer.</p>"},{"location":"start/filters/#trier","title":"Trier","text":"<ul> <li>Appuyez sur le \"+\" \u00e0 c\u00f4t\u00e9 de \"TRIER\".</li> <li>S\u00e9lectionnez la propri\u00e9t\u00e9 \u00e0 partir de laquelle vous voulez trier les images.</li> </ul> <p>Il est possible de les agencer par ordre alphab\u00e9tique, ou encore de fa\u00e7on chronologique par exemple.</p> <p>Il est possible de combiner des fonctions de GROUPAGE et de TRI : on peut alors r\u00e9aliser des groupes en fonction de certaines propri\u00e9t\u00e9s, et trier les images rang\u00e9es dans ces groupes en fonction d\u2019autres propri\u00e9t\u00e9s. Le tri \u00e0 l\u2019int\u00e9rieur de groupes peut par exemple \u00eatre r\u00e9alis\u00e9 \u00e0 partir de la propri\u00e9t\u00e9 calcul\u00e9e par Panoptic \"average hash\". Il s\u2019agit d\u2019un calcul de similarit\u00e9s sommaire. Cela peut par exemple permettre de trier les photos d\u2019un-e m\u00eame photographe (grouper par \"auteur\") en fonction de leurs ressemblances g\u00e9n\u00e9rales (trier par \"average hash\").</p> <p></p>"},{"location":"start/first_start/","title":"Premier Lancement","text":"<p>Au premier d\u00e9marrage de Panoptic un tutoriel interactif vous sera propos\u00e9. Vous pouvez le suivre ou continuer ici en suivant ce guide. </p>"},{"location":"start/first_start/#plugin-de-similarites","title":"Plugin de similarit\u00e9s","text":"<p>Si vous ne l'avez pas encore fait installez le plugin de similarit\u00e9s</p>"},{"location":"start/images/","title":"Importer des images","text":"<p>Une fois un projet cr\u00e9\u00e9 ou ouvert, la fen\u00eatre principale de Panoptic s'ouvre.</p> <p>Pour importer des images, il faut cliquer sur le \"+\" en haut \u00e0 gauche dans Panoptic. Il faut alors s\u00e9lectionner le dossier o\u00f9 se trouvent les images que vous souhaitez importer. </p> <p>Pr\u00e9cision</p> <p>L'import d'un dossier importe \u00e9galement tous les sous-dossiers contenus dans le dossier.</p> <p>Vous pouvez importer successivement plusieurs dossiers contenant des images.</p> <p>Il ne faudra pas bouger le dossier qui contient les images, ni en renommer le chemin ensuite.</p>"},{"location":"start/images/#suivi-de-limport","title":"Suivi de l'import","text":"<p>Une fois que vous avez s\u00e9lectionn\u00e9 le ou les dossiers d'images \u00e0 importer, le temps d'import et de calcul prend g\u00e9n\u00e9ralement plusieurs minutes. Cela d\u00e9pend de la puissance de votre ordinateur et du nombre d'images import\u00e9es. </p> <p>Vous pouvez suivre l'avanc\u00e9e de l'import \u00e0 gauche, dans la section \"T\u00e2che de fond\". Plusieurs informations sont indiqu\u00e9es : l'avancement de l'import des images, de leurs miniatures, et de leur vectorisation.</p> <p>Important</p> <p>Important ! Pour que les images soient vectoris\u00e9es lors de leur import, il faut avoir au pr\u00e9alable install\u00e9 le module \"PanopticML\".</p> <p>Rappel</p> <p>A quoi sert la vectorisation des images ? Dans les grandes lignes, la vectorisation des images est un pr\u00e9alable n\u00e9cessaire \u00e0 la recherche d'images similaires les unes aux autres, en fonction de leur contenu formel (ce que l'on voit dans les images).</p>"},{"location":"start/projets/","title":"Les Projets","text":"<p>Panoptic permet de travailler avec vos corpus, localement, sur votre ordinateur. Panoptic ne propose donc pas de collections d'images pr\u00e9d\u00e9finies, les jeux de donn\u00e9es doivent \u00eatre constitu\u00e9s en amont.</p> <p>Toutes les actions r\u00e9alis\u00e9es au sein d'un projet sont automatiquement sauvegard\u00e9es, localement, sur votre ordinateur. Si vous fermez un projet, avant d'y revenir plus tard, vous y retrouverez toutes les actions que vous y avez effectu\u00e9es.</p> <p>Panoptic permet de travailler avec autant de projets qu'on le souhaite.</p> <p>Dans un projet, vous pouvez travailler avec plusieurs corpus d'images si vous le souhaitez, import\u00e9s en une seule fois ou en plusieurs fois.</p>"},{"location":"start/projets/#page-de-gestion-des-projets-panoptic","title":"Page de gestion des projets Panoptic","text":"<p>Les projets se g\u00e8rent dans une page d\u00e9di\u00e9e (cr\u00e9ation, importation, suppression), qui est la page d'accueil de Panoptic : elle s'ouvre lors du lancement du logiciel et reste accessible n'importe quand.</p> <p>Dans la page de gestion de projets, cliquez sur \"Cr\u00e9er\" \u00e0 c\u00f4t\u00e9 de \"Cr\u00e9er un nouveau projet\".</p> <p></p> <p>Il s'agit alors de d\u00e9finir l'endroit dans votre ordinateur \u2013 (le \"dossier\") \u2013 o\u00f9 vous voulez enregistrer votre projet.</p> <p>Attention</p> <p>Il ne faudra pas bouger ce dossier/en renommer le chemin ensuite.</p> <p>Cr\u00e9ez ce dossier dans un dossier diff\u00e9rent de celui qui contient votre corpus d'images.</p> <p>Cr\u00e9ez donc au pr\u00e9alable, o\u00f9 cela vous arrange, un dossier \"panoptic\" dans lequel vous viendrez enregistrer tous vos projets \u00e0 l'avenir.</p> <p>Nommez ensuite votre projet dans le champ \"Nom du projet\".</p> <p>Faites enfin \"Cr\u00e9er\" : votre projet est cr\u00e9\u00e9 et la page de travail de Panoptic s'ouvre.</p>"},{"location":"start/projets/#acceder-a-un-projet-existant","title":"Acc\u00e9der \u00e0 un projet existant","text":"<p>Lorsque vous ouvrez Panoptic, choisissez \u00e0 gauche le projet que vous souhaitez ouvrir en cliquant dessus. </p> <p></p> <p>Si vous \u00eates d\u00e9j\u00e0 dans un projet ouvert et que souhaitez changer de projet, en haut \u00e0 gauche, cliquez sur la fl\u00e8che.</p>"},{"location":"start/properties/","title":"Les Propri\u00e9t\u00e9s","text":"<p>Pour donner du sens aux images \u00e9tudi\u00e9es dans l\u2019interface de Panoptic, cela se fait en cr\u00e9ant et d\u00e9finissant un ensemble de PROPRI\u00c9T\u00c9S. C\u2019est \u00e0 partir des propri\u00e9t\u00e9s cr\u00e9\u00e9es que vous pouvez annoter les images. Ces propri\u00e9t\u00e9s sont de plusieurs types (en anglais) : </p> <ul> <li>text, </li> <li>numeric, </li> <li>tag, </li> <li>multi_tags, </li> <li>checkbox (case \u00e0 cocher),</li> <li>url, </li> <li>date,</li> <li>color.</li> </ul> <p>Une fois les propri\u00e9t\u00e9s cr\u00e9\u00e9es, vous pouvez associer des annotations \u00e0 chaque image s\u00e9par\u00e9ment, ou bien \u00e0 des lots d\u2019images, en lien avec une propri\u00e9t\u00e9 particuli\u00e8re, ou bien avec plusieurs propri\u00e9t\u00e9s. Les propri\u00e9t\u00e9s peuvent \u00eatre cr\u00e9\u00e9es au fur et \u00e0 mesure, et pas n\u00e9cessairement d\u00e9finies en amont.</p>"},{"location":"start/properties/#creer-et-afficher-une-propriete","title":"Cr\u00e9er et afficher une propri\u00e9t\u00e9","text":"<p>Pour annoter vos images, il faut au pr\u00e9alable cr\u00e9er au moins une propri\u00e9t\u00e9, qui contiendra des annotations de types sp\u00e9cifiques (tag, date, text, number...).</p> <p>Pour cr\u00e9er une propri\u00e9t\u00e9 (par exemple de type \"MultiTags\") :</p> <ul> <li>\u00c0 gauche, cliquez sur \"Nouvelle propri\u00e9t\u00e9\".</li> </ul> <p></p> <ul> <li>Nommez la propri\u00e9t\u00e9, choisissez son type et choisissez s'il s'agit d'une propri\u00e9t\u00e9 d'image ou d'instance. Faites \"Confirmer\".</li> </ul> <p></p> <ul> <li>Affichez (ou masquez) la propri\u00e9t\u00e9 cr\u00e9\u00e9e en cliquant sur l'ic\u00f4ne d'oeil situ\u00e9 \u00e0 c\u00f4t\u00e9 de son nom.</li> </ul> <p></p> <p>Important</p> <p>Il n'est pas n\u00e9cessaire de d\u00e9finir en amont les propri\u00e9t\u00e9s dont vous aurez besoin au cours du travail. Celles-ci peuvent \u00eatre cr\u00e9\u00e9es au fur et \u00e0 mesure.</p>"},{"location":"start/properties/#proprietes-dimages-proprietes-dinstances","title":"Propri\u00e9t\u00e9s d'images, propri\u00e9t\u00e9s d'instances","text":"<p>Un point qui peut \u00eatre compliqu\u00e9 \u00e0 d\u00e9cider est le choix entre propri\u00e9t\u00e9s d'images et propri\u00e9t\u00e9s d'instances. Pour comprendre la diff\u00e9rence entre les notions d'images et d'instances d'images, vous pouvez vous r\u00e9f\u00e9rer au glossaire.</p> <ul> <li>Si vous choisissez l'option propri\u00e9t\u00e9 d'images, vous annoterez, pour la propri\u00e9t\u00e9 cr\u00e9\u00e9e, toutes les instances d'une m\u00eame image. </li> <li>Si vous choisissez l'option propri\u00e9t\u00e9 d'instance, vous annoterez une seule instance de l'image.</li> </ul> <p>Par exemple, vous travaillez avec des tweets qui contiennent des images. Si 50 tweets diff\u00e9rents mobilisent une m\u00eame image :</p> <ul> <li>Choisir l'option propri\u00e9t\u00e9 d'images vous permettra d'annoter les 50 tweets d'un coup, qui mobilisent une m\u00eame image : c'est pertinent si vous souhaitez d\u00e9crire l'image en tant que telle, mais \u00e7a ne l'est pas si vous souhaitez annoter le contexte de mobilisation de l'image.</li> <li>Choisir l'option propri\u00e9t\u00e9 d'instance vous permettra d'annoter les tweets un par un : c'est pertinent si vous souhaitez d\u00e9crire le contexte de mobilisation de l'image, mais \u00e7a ne l'est pas si vous voulez annoter l'image en tant que telle.</li> </ul>"},{"location":"start/properties/#relations-entre-proprietes","title":"Relations entre propri\u00e9t\u00e9s","text":"<p>Il est possible de d\u00e9finir des relations hi\u00e9rarchiques (parent-enfant) entre annotations, pour les propri\u00e9t\u00e9s de type Tag et MultiTags. Ces propri\u00e9t\u00e9s sont en effet sp\u00e9cifiques et peuvent \u00eatre g\u00e9r\u00e9es dans un espace d\u00e9di\u00e9. Cet espace s'ouvre depuis le volet des propri\u00e9t\u00e9s, situ\u00e9 \u00e0 gauche de l'\u00e9cran, en cliquant sur le symbole associ\u00e9.</p> <p></p> <p>Important</p> <p>Dans cet espace de gestion des tags et de leurs relations, deux vues sur ces relations sont disponibles en fonction des besoins : la vue \"arbre\" et la vue \"liste\".</p>"},{"location":"start/properties/#vue-arbre-des-proprietes-tag-et-multitags","title":"Vue \"arbre\" des propri\u00e9t\u00e9s Tag et Multitags","text":"<p>Dans l'exemple, la vue \"arbre\" montre les relations parents-enfants existantes (sport/athl\u00e9tisme/saut \u00e0 la perche ; images m\u00e9dicales/poumons). Le parentage des diff\u00e9rentes annotations r\u00e9alis\u00e9es s\u2019effectue en attrapant avec la souris une annotation et en la glissant sur l\u2019annotation de niveau plus g\u00e9n\u00e9ral.</p> <p></p> <p>Dans cet espace de gestion des tags, vous pouvez renommer vos diff\u00e9rents tags, pour les am\u00e9liorer si besoin, ou encore les fusionner entre eux, si vous rep\u00e9rez des doublons par exemple. Pour les fusionner, s\u00e9lectionnez plusieurs tags (\u00e0 l\u2019aide de la touche maj/shift) et faites \"Merge Tags\".</p> <p></p>"},{"location":"start/properties/#vue-liste-des-proprietes-tag-et-multitags","title":"Vue \"liste\" des propri\u00e9t\u00e9s Tag et Multitags","text":"<p>Vous pouvez \u00e9galement afficher les images en vue \"liste\". Ici, lorsque vous s\u00e9lectionnez un tag, cela affiche ses diff\u00e9rentes relations : parents, fr\u00e8res (m\u00eames parents), enfants.</p> <p></p>"},{"location":"start/properties/#les-proprietes-panoptic","title":"Les Propri\u00e9t\u00e9s Panoptic","text":"<p>Les \"PROPRI\u00c9T\u00c9S PANOPTIC\" sont des propri\u00e9t\u00e9s non manipulables. Elles sont calcul\u00e9es par le logiciel lors de l\u2019import des images, et vous fournissent quelques m\u00e9triques : un identifiant uniquement pour chaque image (\"ID\"), une signature propre \u00e0 chaque image, pour rep\u00e9rer les doublons parfaits (\"sha1\"), une signature propre aux images grossi\u00e8rement similaires (\"average hash\"), leur dossier d\u2019origine sur votre ordinateur (\"folder\"), ainsi que leur chemin absolu (\"path\"), et enfin leurs dimensions (\"width\" et \"height\")</p>"},{"location":"start/propsexport/","title":"Exporter des propri\u00e9t\u00e9s","text":"<p>Une fois vos annotations r\u00e9alis\u00e9es, vous pouvez d\u00e9cider d'exporter ces derni\u00e8res, avec ou sans une reproduction des images.</p> <p>Vous pourrez alors choisir si vous souhaitez exporter toutes les propri\u00e9t\u00e9s, ou seulement une partie d'entre elles. </p> <p></p> <p>Afin de personaliser votre export vous pouve : (1) Choisir un nom pour le dossier d\u2019export, si vous ne pr\u00e9cisez rien, il sera nomm\u00e9 apr\u00e8s la date et l\u2019heure actuelle, au format AAAA \u2212 M M \u2212DD \u2212HH \u2212M M \u2212SS. (2) S\u00e9lectionner une sous-partie de vos images et donn\u00e9es associ\u00e9es. (3) choisir entre \u201cID\u201d, \u201cChemin relatif\u201d et \u201cChemin absolu\u201d. (4) S\u00e9lectionner les propri\u00e9t\u00e9s \u00e0 exporter. (5) Inclure les images dans l\u2019export.</p> <p>Pour finir, appuyez sur le bouton \u201cexport\u201d (6) pour valider vos choix et lancer l\u2019export.</p> <p></p>"},{"location":"start/propsimport/","title":"Importer des propri\u00e9t\u00e9s","text":"<p>Panoptic \u00e9tant pens\u00e9 pour le travail avec des donn\u00e9es pluris\u00e9miotiques, il est possible d\u2019importer dans l\u2019interface du logiciel des PROPRI\u00c9T\u00c9S ASSOCI\u00c9ES AUX IMAGES. Les propri\u00e9t\u00e9s im- port\u00e9es dans Panoptic sont automatiquement structur\u00e9es comme les propri\u00e9t\u00e9s que l\u2019on peut cr\u00e9er soi-m\u00eame. Elles peuvent donc \u00eatre modifi\u00e9es comme vous le souhaitez.</p> <p>Panoptic permet l'exploration de corpus pluris\u00e9miotiques. Pour r\u00e9pondre \u00e0 ce besoin m\u00e9thodologique, Panoptic propose une s\u00e9rie de fonctionnalit\u00e9s pour manipuler des images ET des donn\u00e9es textuelles associ\u00e9es. Il est donc possible d'associer aux images import\u00e9es un fichier de propri\u00e9t\u00e9s, en format .csv.</p>"},{"location":"start/propsimport/#quest-ce-quun-fichier-en-format-csv","title":"Qu'est-ce qu'un fichier en format .csv ?","text":"<p>Un fichier avec l'extension .csv (pour \"Comma-Separated Values\", \"valeurs s\u00e9par\u00e9es par des virgules\" en fran\u00e7ais) est un format de fichier texte utilis\u00e9 pour stocker des donn\u00e9es tabulaires, comme celles que l'on trouve dans une feuille de calcul (Excel par exemple). Dans un fichier .csv, chaque ligne repr\u00e9sente une ligne de donn\u00e9es, et les valeurs de chaque colonne sont s\u00e9par\u00e9es par un point-virgule. Ce type de fichier se g\u00e8re g\u00e9n\u00e9ralement dans une application d'\u00e9dition de texte brut (bloc-note, textedit).</p>"},{"location":"start/propsimport/#quels-types-de-donnees-peuvent-etre-importees","title":"Quels types de donn\u00e9es peuvent \u00eatre import\u00e9es ?","text":"Nom Explication text Des donn\u00e9es textuelles : lorem ipsum... number Des donn\u00e9es num\u00e9riques : 0123456789 tag du texte, qui sera pr\u00e9sent\u00e9 sous forme de tags dans l'interface de Panoptic multi_tags plusieurs blocs de texte, s\u00e9par\u00e9s par des virgules (,), qui seront pr\u00e9sent\u00e9s sous forme de tags dans l'interface de Panoptic checkbox une valeur true (case coch\u00e9e) ou false (case non coch\u00e9e) url un lien vers un site web date une date color Des couleurs, dans la liste suivante : red, pink, grape, violet, indigo, blue, cyan, teal, green, lime, yellow, orange"},{"location":"start/propsimport/#comment-formater-correctement-ces-donnees","title":"Comment formater correctement ces donn\u00e9es ?","text":"<p>Le fichier .csv contenant les donn\u00e9es associ\u00e9es aux images doit \u00eatre structur\u00e9 de la mani\u00e8re suivante : - Toutes les donn\u00e9es doivent \u00eatre s\u00e9par\u00e9es par des points-virgules ( ; ). - La premi\u00e8re ligne du .csv doit contenir les ent\u00eates. La partie entre crochets correspond au type de la propri\u00e9t\u00e9 (cf. page pr\u00e9c\u00e9dente). La partie en dehors des crochets correspond au nom que vous souhaitez donner \u00e0 la propri\u00e9t\u00e9.     - Cette premi\u00e8re ligne doit \u00eatre \u00e9crite de la mani\u00e8re suivante : path;date de cr\u00e9ation[date];lien vers l\u2019image[url];code couleur 1[color];code couleur 2[color];     - Important : la toute premi\u00e8re donn\u00e9e a un format diff\u00e9rent (\"path\") : il s\u2019agit du chemin (relatif ou complet) vers l\u2019endroit o\u00f9 est situ\u00e9e l\u2019image sur votre ordinateur : C:/mon/dossier/personnelle/image1.jpg. Pour le reste, vous pouvez ordonner les m\u00e9tadonn\u00e9es comme vous le souhaitez. - Les lignes suivantes contiennent les m\u00e9tadonn\u00e9es de chaque image, remplies en fonction du type de propri\u00e9t\u00e9s : C:/mon/dossier/personnel/image1.jpg;24/10/2024;https://instagram.com/image.png;blue;red</p> <p>Sp\u00e9cificit\u00e9s pour le formatage :</p> <ul> <li>Plusieurs possibilit\u00e9s pour l\u2019horodatage : 2024 ; 02/2024 ; 19/02/2024 ; 19/02/2024 12:45 ; 19/02/2024 12:45:55 ; 19-02-2024T12:45:55.000Z ; 2024/02/19 12:45:55.</li> <li>Pour l\u2019import des multi_tags, les diff\u00e9rents tags inscrits doivent \u00eatre s\u00e9par\u00e9s par une virgule ( , ).</li> </ul>"},{"location":"start/propsimport/#exemple-dun-fichier-csv-bien-formate-pour-panoptic","title":"Exemple d'un fichier .csv bien format\u00e9 pour Panoptic","text":""},{"location":"start/propsimport/#comment-importer-les-donnees-bien-formatees-dans-panoptic","title":"Comment importer les donn\u00e9es bien format\u00e9es dans Panoptic ?","text":"<p>Quand votre fichier \u00e0 importer est bien structur\u00e9, rendez-vous dans votre projet Panoptic et, \u00e0 droite de la section \"Propri\u00e9t\u00e9s\", cliquez sur l\u2019ic\u00f4ne d\u2019import de propri\u00e9t\u00e9s. Dans la fen\u00eatre qui s\u2019ouvre, choisissez le fichier .csv \u00e0 importer. Panoptic ouvre alors le fichier, et en indique une synth\u00e8se dans un tableau \u00e0 cinq colonnes. Vous pouvez agir sur la premi\u00e8re et la derni\u00e8re : - Cocher ou d\u00e9cocher les propri\u00e9t\u00e9s \u00e0 importer (de base toutes les propri\u00e9t\u00e9s du tableau .csv seront import\u00e9es). - Indique le num\u00e9ro de colonne dans le .csv d\u2019origine. - Indique le nom des propri\u00e9t\u00e9s et leur type sous forme de logo. - Indique si la propri\u00e9t\u00e9 existe d\u00e9j\u00e0 dans Panoptic ou non. - Changer le mode de la propri\u00e9t\u00e9 dans panoptic : \"instance\" ou \"image\".</p> <p>Pr\u00e9cisez en cochant ou non la case \"Relative Path\" si le chemin des images indiqu\u00e9 dans le fichier .csv est relatif ou absolu.</p> <p>Vous pouvez ensuite valider l\u2019import en cliquant sur \"Import\". Les donn\u00e9es s\u2019importent dans la section \"propri\u00e9t\u00e9s\" de Panoptic et sont en donc manipulables d\u00e9sormais.</p> <p></p> <p></p>"},{"location":"start/propsimport/#precision-sur-le-mode-de-fusion-des-donnees","title":"Pr\u00e9cision sur le mode de fusion des donn\u00e9es","text":"<p>Si l\u2019on cherche \u00e0 importer des propri\u00e9t\u00e9s d\u00e9j\u00e0 existantes (typiquement, si deux personnes travaillent chacune de leur c\u00f4t\u00e9 sur un m\u00eame corpus d\u2019images et l\u2019annotent avant de se partager leurs annotations pour mettre \u00e0 jour leurs avanc\u00e9es respectives), il y a la possibilit\u00e9 de choisir le mode de fusion des donn\u00e9es. Quatre possibilit\u00e9s sont propos\u00e9es :</p> <ul> <li>New : ce mode cr\u00e9e une nouvelle instance de l\u2019image renseign\u00e9e dans la colonne path (n\u2019\u00e9crase donc pas les donn\u00e9es existantes)</li> <li>First : ce mode \u00e9crase les propri\u00e9t\u00e9s de la plus ancienne instance d\u2019une image enregistr\u00e9e dans Panoptic, et les remplace par celles renseign\u00e9es dans le fichier .csv en cours d\u2019import.</li> <li>Last : ce mode \u00e9crase les propri\u00e9t\u00e9s de la plus r\u00e9cente instance d\u2019une image enregistr\u00e9e dans Panoptic, et les remplace par celles renseign\u00e9es dans le fichier .csv en cours d\u2019import.</li> <li>All : ce mode \u00e9crase toutes les propri\u00e9t\u00e9s correspondant aux diff\u00e9rentes instances d\u2019uneimage pour les remplacer par les propri\u00e9t\u00e9s renseign\u00e9es dans le fichier .csv import\u00e9. </li> </ul>"},{"location":"start/reco/","title":"Les recommandations","text":"<p>Un troisi\u00e8me outil de similarit\u00e9 sont les recommandations pour compl\u00e9ter un groupe existant. </p> <p>Il faut pr\u00e9alablement avoir group\u00e9 ses images par une propri\u00e9t\u00e9 de type tags ou multi_tags et cliquer sur le bouton \"Proposition d'images\":</p> <p></p> <p>Cela ouvre alors une liste de propositions d'images similaires \u00e0 toutes les images du groupe source, on peut venir ensuite pour chaque image soit valider ou refuser. En validant une image cela va venir l'ajouter au groupe en lui assignant le tag du groupe.</p>"},{"location":"start/similar/","title":"Trouver des images similaires","text":"<p>Un autre outil de similarit\u00e9 fourni par Panoptic est la recherche d'images similaires \u00e0 une image.  Il suffit pour cela de cliquer sur une image pour ouvrir une fen\u00eatre contenant cette image, toutes ses priori\u00e9t\u00e9s ainsi que toutes les images similaires \u00e0 cette image:</p> <p></p> <p>En bas \u00e0 droite de chaque image s'affiche son score de similarit\u00e9 avec l'image \"source\", le plugin de similarit\u00e9 de base de panoptic affiche un score allant de 0 \u00e0 1, 1 \u00e9tant le plus proche.  Un filtre permet de s\u00e9lectionner les taux de similarit\u00e9 minimum et maximum.</p> <p>Il est ensuite possible d'annoter ces images soit en les s\u00e9lectionnant et en proc\u00e9dant \u00e0 une annotation de groupe, soit en cliquant sur le pot de peinture au niveau des propri\u00e9t\u00e9s de l'image source ce qui va venir assigner la m\u00eame valeur \u00e0 toutes les images similaires.</p> <p></p>"},{"location":"start/tagsimport/","title":"Importer des Tags ou un Th\u00e9saurus","text":"<p>Si il est possible d'importer des m\u00e9tadonn\u00e9es sous forme de propri\u00e9t\u00e9s comme nous l'avons vu pr\u00e9c\u00e9demment, il se peut que dans certain cas l'on veuille simplement importer une liste de tags sans forc\u00e9ment les lier \u00e0 des images. </p> <p>Cela peut \u00eatre particuli\u00e8rement utile dans le cas on l'on souhaite annoter des images \u00e0 partir d'un th\u00e9saurus pr\u00e9existant, il suffit alors d'importer le th\u00e9saurus dans panoptic pour avoir ensuite \u00e0 disposition tous les tags possibles d\u00e9j\u00e0 pr\u00e9-cr\u00e9es et organis\u00e9s sous forme hi\u00e9rarchique. </p>"},{"location":"start/tagsimport/#preparer-ses-donnees-pour-limport","title":"Pr\u00e9parer ses donn\u00e9es pour l'import","text":"<p>Encore une fois le format de l'import est en <code>csv</code> mais cette fois sans en t\u00eate. Les trois colonnes correspondent au nom du tag, \u00e0 la couleur du tag, et au nom du tag parent si on souhaite cr\u00e9er une hi\u00e9rarchie. Exemple de csv fonctionnel:</p> <pre><code>animal;1;\nfunny;0;\ndog;4;animal,funny\ncat;5;animal\nmeme;11;funny\ngolden retriever;6;dog\npersian cat;7;cat\nwholesome;2;\ncute;3;wholesome\npuppy;8;dog,cute\nkitten;9;cat,cute\nwildlife;10;animal\nbear;1;wildlife\n</code></pre>"},{"location":"start/tagsimport/#importer-les-donnees","title":"Importer les donn\u00e9es","text":"<p>Une fois le csv pr\u00eat, il faut \u00e9galement s'assurer d'avoir d\u00e9j\u00e0 cr\u00e9\u00e9 une propri\u00e9t\u00e9 de type <code>tag</code>ou <code>multi_tags</code> dans lequel on va venir importer nos tags.</p> <p>Comme pour l'import des propri\u00e9t\u00e9s on se rend ici:</p> <p></p> <p>Il suffit ensuite de:</p> <ul> <li>cliquer sur Tags</li> <li>choisir un fichier csv \u00e0 importer</li> <li>choisir la propri\u00e9t\u00e9 dans laquelle importer les tags</li> <li>cliquer sur \"Importer des Tags\"</li> </ul> <p>Si tout se passe sans erreurs les Tags sont maintenant disponibles dans la propri\u00e9t\u00e9 qui a \u00e9t\u00e9 s\u00e9lectionn\u00e9e.</p>"},{"location":"start/text/","title":"Similarit\u00e9 textuelle","text":"<p>Le dernier outil de similarit\u00e9 fourni par d\u00e9faut dans panoptic est celui permettant de faire de la similarit\u00e9 textuelle. C'est \u00e0 dire de pouvoir venir chercher au sein du corpus les images qui correspondent le plus \u00e0 une requ\u00eate textuelle. </p> <p></p> <p>Cela renverra ensuite toutes les images tri\u00e9es par similarit\u00e9 d\u00e9croissante, un param\u00e8tre peut \u00eatre choisir pour ne renvoyer que les images d\u00e9passant un certain seuil de similarit\u00e9. </p>"},{"location":"usecases/bd/","title":"R\u00e9cits picturaux\u202f: du code \u00e0 la transgression","text":""},{"location":"usecases/bd/#corpus","title":"Corpus","text":"<p>Le corpus est compos\u00e9 d'images de personnages de bande dessin\u00e9e.</p> <p>C'est un corpus adjacent au corpus principal. L'objet principal \u00e9tant de r\u00e9aliser l'annotation, sur plusieurs axes s\u00e9mantiques, de personnages issus de r\u00e9cits picturaux. Les BDs sont issues de France, Belgique, Cote d'ivoire, et de la RDA.</p> <p>L'id\u00e9e de ce sorpus adjacant est avant tout de permettre la visualisation des oppositions entre les personnages sur les diverses cat\u00e9gories d'annotation.</p> <p>Il y a une centaine d'annotations dont la pluspart placent les personages sur un spectre.</p>"},{"location":"usecases/bd/#question-de-recherche","title":"Question de recherche","text":"<p>Nous cherchons \u00e0 \u00e9tudier le langage iconique au sein de r\u00e9cits picturaux. L'id\u00e9e \u00e9tant de d\u00e9celer les codes ainsi que leurs trangressions.</p>"},{"location":"usecases/bd/#usage-de-panoptic","title":"Usage de panoptic","text":""},{"location":"usecases/bd/#ce-que-je-mattendais-a-trouver-dans-panoptic-et-dont-je-me-suis-servi","title":"Ce que je m'attendais \u00e0 trouver dans panoptic et dont je me suis servi","text":"<p>Panoptic a servi a filtrer et grouper les personnages, soit sur nos annotations, soit sur le contexte de production de l'\u0153uvre. Par la suite, nous pouvons utiliser des tris pour ordonner les persos et ainsi comparer leurs annotations. Ayant un total de 418 personnages, nous aurions pu placer tous les persos d'un coup sur un axe (\u00e0 l'aide d'un tri), cependant cela aurait donn\u00e9 un r\u00e9sultat que peu lisible. \u00c0 l'aide des groupes, nous avons alors pu alors s\u00e9parer les persos par \u0153uvre, franchise, contexte de production, ou encore en fonction d'autres annoations (identit\u00e9 de genre, animaux/humains, ...).</p> <p></p>"},{"location":"usecases/bd/#ce-que-je-ne-mattendais-pas-a-trouver-dans-panoptic-et-dont-je-me-suis-servi","title":"Ce que je ne m'attendais PAS \u00e0 trouver dans panoptic et dont je me suis servi","text":"<p>En parall\u00e8le, nous voulions tirer des corr\u00e9lations de ces annotations. On a fait des petits scripts python pour faire toutes nos stats et visualisations. Ces derniers nous permettent de calculer les cor\u00e9lations entre chaque axe d'annotation et les autres, mais aussi de comparer plusieurs axes, ou de le faire sur une partie des personnages seulement. L'arriv\u00e9e des plugins dans panotpic nous a alors donn\u00e9 l'id\u00e9e d'interfacer nos scripts de visualisations pour  avec panoptic dans l'id\u00e9e de permettre \u00e0 n'importe qui d'utiliser notre code. Cependant, nous ne nous y sommes pas encore attel\u00e9s.</p> <p>L'interface web de panoptic nous a \u00e9galement permis de d\u00e9ployer le tout sur un serveur, \u00e7a permettait de consulter les annotations \u00e0 plusieurs, mais \u00e9galement de facilement le montrer en colloque et autres.</p>"},{"location":"usecases/bd/#ce-que-je-mattendais-a-trouver-et-quil-ny-avait-pas-quelles-difficultes-ai-je-rencontrees","title":"Ce que je m'attendais \u00e0 trouver et qu'il n'y avait PAS / Quelles difficult\u00e9s ai-je rencontr\u00e9es ?","text":"<p>Afin de continuer l'annotation de nos donn\u00e9es, nous aurions aim\u00e9 deux choses\u202f: avoir des annoations num\u00e9riques mais continues, avec un slider; et pouvoir annoter \u00e0 plusieurs \u00e0 partir d'une seule instance en gardant l'information de qui a annot\u00e9 quoi.</p>"},{"location":"usecases/template/","title":"Titre de mon Usecase","text":"<p>Ceci est une phrase r\u00e9sum\u00e9e de ce qui sera pr\u00e9sent\u00e9 dans mon usecase</p>"},{"location":"usecases/template/#mon-corpus","title":"Mon corpus","text":"<p>Pr\u00e9sentation du corpus avec peut \u00eatre une capture d'\u00e9cran de quelques images (ou de panoptic avec les images)</p>"},{"location":"usecases/template/#ma-question-de-recherche","title":"Ma question de recherche","text":"<p>Quelle est ma question de recherche, qu'est ce que je cherche \u00e0 \u00e9tudier dans mes images ? </p>"},{"location":"usecases/template/#mon-usage-de-panoptic","title":"Mon usage de panoptic","text":"<p>Comment je me suis servi de panoptic pour r\u00e9pondre \u00e0 ma question. D\u00e9j\u00e0 est ce que j'ai r\u00e9ussi ou non ? </p>"},{"location":"usecases/template/#ce-que-je-mattendais-a-trouver-dans-panoptic-et-dont-je-me-suis-servi","title":"Ce que je m'attendais \u00e0 trouver dans panoptic et dont je me suis servi","text":"<p>Concr\u00e8tement, quels outils je pensais trouver dans panoptic, et que j'ai effectivement pu utiliser </p>"},{"location":"usecases/template/#ce-que-je-ne-mattendais-pas-a-trouver-dans-panoptic-et-dont-je-me-suis-servi","title":"Ce que je ne m'attendais PAS \u00e0 trouver dans panoptic et dont je me suis servi","text":"<p>Est ce que j'ai d\u00e9couvert des nouveaux usages ? Des nouveaux outils ? Est ce que ma question de recherche a \u00e9volu\u00e9 en cons\u00e9quence ?</p>"},{"location":"usecases/template/#est-ce-que-jai-utilise-des-plugins-autre-que-celui-de-similarite","title":"Est ce que j'ai utilis\u00e9 des plugins (autre que celui de similarit\u00e9) ?","text":"<p>tout est dans le titre</p>"},{"location":"usecases/template/#ce-que-je-mattendais-a-trouver-et-quil-ny-avait-pas-quelles-difficultes-ai-je-rencontrees","title":"Ce que je m'attendais \u00e0 trouver et qu'il n'y avait PAS / Quelles difficult\u00e9s ai-je rencontr\u00e9es ?","text":"<p>Parler de difficult\u00e9s techniques, de manque de l'outil, de contournement m\u00e9thodo (un outil n'existe pas, comment je bricole pour m'en sortir quand m\u00eame), est ce qu'il y a eu des d\u00e9veloppements sp\u00e9cifiques pour r\u00e9pondre \u00e0 ces probl\u00e8mes ? </p>"},{"location":"usecases/template/#eventuelle-conclusion","title":"Eventuelle Conclusion","text":""},{"location":"usecases/virapic/","title":"Recherche d'images historiques sur le projet Virapic","text":"<p>Ceci est une phrase r\u00e9sum\u00e9e de ce qui sera pr\u00e9sent\u00e9 dans mon usecase</p>"},{"location":"usecases/virapic/#mon-corpus","title":"Mon corpus","text":"<p>Pr\u00e9sentation du corpus avec peut \u00eatre une capture d'\u00e9cran de quelques images (ou de panoptic avec les images)</p>"},{"location":"usecases/virapic/#ma-question-de-recherche","title":"Ma question de recherche","text":"<p>Quelle est ma question de recherche, qu'est ce que je cherche \u00e0 \u00e9tudier dans mes images ? </p>"},{"location":"usecases/virapic/#mon-usage-de-panoptic","title":"Mon usage de panoptic","text":"<p>Comment je me suis servi de panoptic pour r\u00e9pondre \u00e0 ma question. D\u00e9j\u00e0 est ce que j'ai r\u00e9ussi ou non ? </p>"},{"location":"usecases/virapic/#ce-que-je-mattendais-a-trouver-dans-panoptic-et-dont-je-me-suis-servi","title":"Ce que je m'attendais \u00e0 trouver dans panoptic et dont je me suis servi","text":"<p>Concr\u00e8tement, quels outils je pensais trouver dans panoptic, et que j'ai effectivement pu utiliser </p>"},{"location":"usecases/virapic/#ce-que-je-ne-mattendais-pas-a-trouver-dans-panoptic-et-dont-je-me-suis-servi","title":"Ce que je ne m'attendais PAS \u00e0 trouver dans panoptic et dont je me suis servi","text":"<p>Est ce que j'ai d\u00e9couvert des nouveaux usages ? Des nouveaux outils ? Est ce que ma question de recherche a \u00e9volu\u00e9 en cons\u00e9quence ?</p>"},{"location":"usecases/virapic/#est-ce-que-jai-utilise-des-plugins-autre-que-celui-de-similarite","title":"Est ce que j'ai utilis\u00e9 des plugins (autre que celui de similarit\u00e9) ?","text":"<p>tout est dans le titre</p>"},{"location":"usecases/virapic/#ce-que-je-mattendais-a-trouver-et-quil-ny-avait-pas-quelles-difficultes-ai-je-rencontrees","title":"Ce que je m'attendais \u00e0 trouver et qu'il n'y avait PAS / Quelles difficult\u00e9s ai-je rencontr\u00e9es ?","text":"<p>Parler de difficult\u00e9s techniques, de manque de l'outil, de contournement m\u00e9thodo (un outil n'existe pas, comment je bricole pour m'en sortir quand m\u00eame), est ce qu'il y a eu des d\u00e9veloppements sp\u00e9cifiques pour r\u00e9pondre \u00e0 ces probl\u00e8mes ? </p>"},{"location":"usecases/virapic/#eventuelle-conclusion","title":"Eventuelle Conclusion","text":""},{"location":"en/","title":"What is Panoptic?","text":"<p>Panoptic is a research software dedicated to exploring and annotating large image corpora.</p> <p></p> <p>This tool integrates numerous functions with the objective of helping researchers work with a large mass of data: image grouping, visual similarity search, fine or batch annotations, import of data associated with images, management of multi-semiotic corpora, etc.</p>"},{"location":"en/#summary-of-available-features","title":"Summary of available features","text":"<p>Panoptic allows to:</p> <ul> <li>Explore all elements of an image corpus imported by researchers.</li> <li>Group images together based on their similarity.</li> <li>Find images similar to a particular image or groups of images.</li> <li>Annotate images based on different properties: date, url, tag(s), numerical value, true/false</li> <li>Group, sort and filter images based on their properties (imported or annotated in the interface).</li> <li>Import, manage and export properties associated with images.</li> </ul>"},{"location":"en/concepts/","title":"Glossary","text":"<p>This page provides an overview of all concepts used in Panoptic. It can be a good reference for quickly understanding a term or getting a general overview of the software. For more information on a specific concept, consult the dedicated page.</p>"},{"location":"en/concepts/#project","title":"Project","text":"<p>Projects in Panoptic are a way to store your work. For example, you can create different projects on the same corpus if you wish to perform different annotations, import different data related to images, or even mix several image corpora within the same project.</p> <p>For example, it may be interesting to work on a set of historical photographs to make annotations and explore recurring themes, but it could also be relevant to mix this corpus with a corpus collected on the Internet to see if some of these historical images can be found on websites and, if so, in what context they appear.</p>"},{"location":"en/concepts/#data","title":"Data","text":"<p>When creating a project, you must select a folder where the project data will be stored. Each project stores its data separately in an SQLite database (see detailed schema).</p>"},{"location":"en/concepts/#settings","title":"Settings","text":"<p>A project can be configured with settings to define the default values for each plugin at the project level. It is also possible, for example, to store a copy of the images directly in the database, which facilitates sharing a Panoptic project by sending a single file.</p>"},{"location":"en/concepts/#images-and-instances","title":"Images and Instances","text":"<p>One of the most complex concepts to understand in Panoptic is the difference between images and instances. To understand the necessity of this distinction, let's take the example of an image found on Twitter, but posted by two different users, at different times, and with very distinct messages. Technically, it's the same image, but since the contexts in which it appears are very different, one could consider that it is not semantically identical.</p> <p>Thus, if we wish to observe images in Panoptic with their contexts stored as properties, the same image may appear multiple times if it has been found multiple times in the corpus with different properties.</p> <p>In summary:</p> <ul> <li>An image corresponds only to a set of pixels.</li> <li>An image instance represents the occurrence of this set of pixels in a specific context.</li> </ul> <p>Consequently, an image can have multiple instances, but an instance can only be linked to a single image.</p>"},{"location":"en/concepts/#properties","title":"Properties","text":"<p>Properties are used in Panoptic to add additional data that are not images. They can be imported or added manually to create annotations on images.</p>"},{"location":"en/concepts/#property-types","title":"Property Types","text":"<p>Properties can be of different types depending on the type of annotation to add. Each type has specific behavior. For example, date type properties allow dynamically grouping images by year, month, week, etc.</p> Property Type Description Tag Contains a single tag MultiTags Contains multiple tags URL Clickable web link Date A date Color One of 12 colors available in Panoptic Checkbox Simple checkbox Number Integer or floating-point number Text Textual data"},{"location":"en/concepts/#image-instance","title":"Image / Instance","text":"<p>When created or imported, properties can be linked to images or instances:</p> <ul> <li>An image property is shared by all instances of that image and is often used to describe visual characteristics.</li> <li>An instance property is linked to a single specific occurrence of an image.</li> </ul> <p>For example, for the same image posted twice on Twitter, the authors, publication date, and associated comment for the post must be instance properties and not image properties.</p>"},{"location":"en/concepts/#tags","title":"Tags","text":"<p>The most commonly used property types in Panoptic are \"tag\" and \"multi_tags\" because they are easy to create and manipulate, with autocompletion facilitating image annotation. However, when there are a large number of tags, their organization can become complex. In Panoptic, tags can be hierarchical and have multiple parents.</p> <p>This is why a dedicated module for tag management has been created, often called \"tags modal\", allowing tags to be visually reorganized or renamed.</p>"},{"location":"en/concepts/#import","title":"Import","text":"<p>Properties can be imported via the import module using a CSV file.</p>"},{"location":"en/concepts/#export","title":"Export","text":"<p>Properties can be exported via the export module to a CSV file. A selection of images can also be exported with the CSV file.</p>"},{"location":"en/concepts/#filters-sort-and-groups","title":"Filters, Sort, and Groups","text":"<p>Panoptic allows creating dynamic views of images using filters, sorts, and groupings.</p>"},{"location":"en/concepts/#filters","title":"Filters","text":"<p>Filters allow displaying only images that match the defined criteria. Multiple filters can be combined using AND or OR operators.</p>"},{"location":"en/concepts/#sort","title":"Sort","text":"<p>Sorting allows changing the display order of images. It can be ascending or descending and applied to multiple properties, for example: \"sort by ascending date, then by descending textual description\".</p>"},{"location":"en/concepts/#groups","title":"Groups","text":"<p>Groups allow grouping images based on a selected property. Subgroups can be created by selecting another property. Groups can be sorted by property value or by the number of elements.</p>"},{"location":"en/concepts/#search","title":"Search","text":"<p>Full-text search is possible on all textual properties via the search bar.</p>"},{"location":"en/concepts/#views","title":"Views","text":"<p>When displaying images, several presentation modes are available:</p> <ul> <li>Grid view: default display centered on images.</li> <li>Table view: allows visualizing more properties and/or long properties.</li> <li>Graph view: displays a graph when a grouping is made on a numerical value or a date.</li> </ul>"},{"location":"en/concepts/#tabs","title":"Tabs","text":"<p>One of Panoptic's main objectives is to allow multiple ways to explore an image corpus simultaneously. For this, tabs are used as distinct workspaces, each capable of having its own filters, sorts, groups, views, and displayed properties.</p>"},{"location":"en/concepts/#vectors","title":"Vectors","text":"<p>To enable the use of machine learning algorithms, images are transformed into vectors (or embeddings) when imported into Panoptic. A vector is a list of numbers representing characteristics of the image.</p> <p>These characteristics are not necessarily directly interpretable, but they allow comparing images with each other. For example, two images of cats will have closer vectors than those of a dog.</p>"},{"location":"en/concepts/#clusters","title":"Clusters","text":"<p>Once vectors are calculated, images can be automatically grouped into clusters. Unlike groups created with properties, clusters are configurable, can be generated with different algorithms, and are not deterministic (the same clustering can produce slightly different results depending on the executions).</p>"},{"location":"en/concepts/#similarity","title":"Similarity","text":"<p>Once vectors are calculated, the similarity between images can be measured. Different algorithms can be used. Panoptic uses cosine similarity by default, with values ranging between 0 and 1.</p>"},{"location":"en/concepts/#execute","title":"Execute","text":"<p>Calculations not listed above can be launched with the \"Execute\" button, which groups all actions provided by the plugins. Examples:</p> <ul> <li>Detect the main colors of images and save them as a property.</li> <li>Perform OCR on images.</li> <li>Identify the main subjects of texts associated with images.</li> <li>Extract objects from images.</li> </ul>"},{"location":"en/concepts/#plugins","title":"Plugins","text":"<p>Plugins allow adding new functionalities to Panoptic. Each project can activate only the necessary plugins, which optimizes the software's lightness. Even Panoptic's deep learning functionalities are integrated as plugins.</p> <p>Plugins can add new possibilities for:</p> <ul> <li>Creating clusters.</li> <li>Calculating similarities.</li> <li>Adding specific actions via the \"Execute\" button.</li> </ul>"},{"location":"en/faq/","title":"Frequently Asked Questions","text":""},{"location":"en/faq/#does-panoptic-create-image-corpora-automatically","title":"Does Panoptic create image corpora automatically?","text":"<p>No, Panoptic is an analysis tool for existing corpora. To use it, you must first have downloaded your image corpus locally.</p>"},{"location":"en/faq/#is-my-corpus-in-iiif-format-can-i-import-it-into-panoptic","title":"Is my corpus in IIIF format? Can I import it into Panoptic?","text":"<p>Not at the moment, but we are working on it.</p>"},{"location":"en/faq/#i-cant-import-my-additional-data-into-panoptic","title":"I can't import my additional data into Panoptic","text":"<p>Make sure you have followed the tutorial correctly</p> <p>Most errors commonly come from:</p> <ul> <li>the first column must imperatively be named 'path' and contain a path to the image</li> <li>the 'path' column must only be called 'path' and nothing else</li> <li>there must not be both a 'path' column and an 'id' column at the same time</li> <li>each column other than 'path' must have a property type specified in square brackets</li> </ul>"},{"location":"en/faq/#can-i-use-a-graphics-card-with-panoptic","title":"Can I use a graphics card with Panoptic?","text":"<p>Yes, it is possible. During installation, if you have an NVidia graphics card, you will be offered to install GPU-compatible libraries. It should be noted that this will only speed up the calculation of image vectors, which only happens once.</p>"},{"location":"en/faq/#if-my-images-have-already-been-imported-can-i-share-them-without-recalculating","title":"If my images have already been imported, can I share them without recalculating?","text":"<p>Image calculation can be long, so if several people are going to work on the same project, the import can be done on a computer with good computing capabilities, then the .db file can be shared. This file is located in the folder you chose when creating the project.</p>"},{"location":"en/faq/#can-i-annotate-collaboratively-online-on-panoptic","title":"Can I annotate collaboratively online on Panoptic?","text":"<p>No, Panoptic is a tool designed to be used locally. We aim to make it collaborative later, but this will require a lot of development.</p>"},{"location":"en/faq/#where-does-panoptic-store-data","title":"Where does Panoptic store data?","text":"<p>When you create a project, you choose a folder in which to create it. This folder will contain the entire SQLite database (the panoptic.db file) as well as any plugin data. This .db file is what you can use to share a project with someone else or to save a project elsewhere than on your computer (to make a backup).</p>"},{"location":"en/resources/","title":"Additional Resources in Image Analysis","text":"<ul> <li>Distant Viewing</li> <li>Tropy</li> <li>Panoptic Publications</li> <li>PictorIA Consortium</li> <li>Teklia</li> </ul>"},{"location":"en/advanced/astuces/","title":"Tips and Shortcuts","text":"<p>This section aims to list some keyboard shortcuts and usage tips to facilitate the use of Panoptic.</p>"},{"location":"en/advanced/astuces/#shortcuts","title":"Shortcuts","text":"<p>Note</p> <p>On Mac, CTRL is replaced by Command</p> <ul> <li>ctrl + z: undo,</li> <li>ctrl + alt + z: redo,</li> <li>ctrl held while hovering over an image: displays an enlargement of an image,</li> <li>shift-click selection: selects all images between the first and last selected image,</li> <li>ctrl-click selection: selects an image without canceling the current selection</li> <li>tab when annotating an image: moves to annotating the same property on the next image,</li> <li>enter validates most actions (annotation, clusters, execute etc.)</li> </ul>"},{"location":"en/advanced/astuces/#tips","title":"Tips","text":"<ul> <li>when performing a text similarity search, if you enter an image URL instead of text, Panoptic will download this image and perform an image similarity search on this external image.</li> </ul>"},{"location":"en/advanced/import/","title":"Image Import and Similarity","text":"<p>All Panoptic similarity tools rely on a first step that occurs during image import: vectorization.</p> <p>This process consists of using a Deep Learning model, in this case the open-source OpenAI - CLIP model to transform images into embeddings.</p> <p>These embeddings will allow easy comparison of images with each other, not only based on their visual resemblance, but also on what they represent.</p>"},{"location":"en/advanced/import/#illustrated-example","title":"Illustrated Example","text":"<p>Concretely, embeddings are lists of numbers; the number of digits may vary depending on the model used, but for CLIP, for example, images are transformed into lists of 512 numbers. These represent visual and/or semantic characteristics of the images, but are difficult to interpret if one only looks at the numbers.</p> <p>Here is a fictitious and extremely simplified example of embeddings with only 3 numbers that could be obtained for the following images:</p> <p></p> <p>The two cat vectors are a priori closer in value. One could then try to interpret what each value represents for the model (for example, the type of muzzle, posture, type of ear), but this is a separate field of research, and here we content ourselves with using the model assuming that it has been previously well-trained and will be able to convert our images into vectors such that it can properly identify the images.</p> <p>Once the model has transformed our images into vectors, we can create groups of images based on these characteristics (which are, let us remember, not purely visual characteristics as we have seen in the first methods, but indeed characteristics of what is represented.)</p> <p>These groups can be represented on a graph, which however implies keeping only two points per image. There are statistical methods for calculating these two points regardless of the size of the input vector but here for simplicity we will only keep the points corresponding to the muzzles and ears since they are a priori the most significant.</p> <p>We thus obtain the following graph:</p> <p></p> <p>Which allows us to observe that we can indeed visually group our images into groups, the cats together and the dog separately.</p>"},{"location":"en/advanced/instances/","title":"Instances","text":"<p>One of the most complex concepts to understand in Panoptic is the difference between images and instances. To understand the necessity of this distinction, let's take the example of an image found on Twitter, but posted by two different users, at different times, and with very distinct messages. Technically, it's the same image, but since the contexts in which it appears are very different, one could consider that it is not semantically identical.</p> <p>Thus, if we wish to observe images in Panoptic with their contexts stored as properties, the same image may appear multiple times if it has been found multiple times in the corpus with different properties.</p> <p></p> <p>In summary</p> <p>An image corresponds only to a set of pixels.</p> <p>An image instance represents the occurrence of this set of pixels in a specific context.</p> <p>Consequently, an image can have multiple instances, but an instance can only be linked to a single image.</p>"},{"location":"en/advanced/instances/#instance-properties","title":"Instance Properties","text":"<p>Due to the difference we have just observed, there are two types of annotations that can be produced in Panoptic:</p> <ul> <li>Annotations used to describe all instances of the same image. In the example above, this would be annotating the image by saying it's a cat. For this, we use image properties which will automatically be applied to all instances.</li> <li>Annotations used to describe a particular instance. In the example above, this would be annotating by saying that instance 1 is \"pro-cat\" while instance 2 is \"anti-cat\". For this, we use instance properties.</li> </ul>"},{"location":"en/advanced/models/","title":"Choosing Your Model","text":"<p>For more advanced uses, it is possible to compare image vectorization models. The one used by default by Panoptic's similarity plugin is OpenAI's CLIP model (when they were still Open). But there are other models that will offer a different vectorial representation and that can be more or less effective depending on the datasets. Some of them are directly integrated into the similarity plugin:</p> <ul> <li>Mobilenet: model with average performance but much lighter in terms of computation, good for use on a machine with low CPU power, does not allow text/image similarity.</li> <li>CLIP: Panoptic's default model, good performance and runs relatively fast on most machines, allows text/image similarity.</li> <li>SIGLIP: heavier model than CLIP, but achieving better performance in text/image similarity, vectors will take much longer to compute on an average machine.</li> <li>DINOSv2: heavier model than CLIP, supposed to have better performance on visual similarity, does not allow text/image similarity.</li> </ul>"},{"location":"en/advanced/models/#creating-new-vectors","title":"Creating New Vectors","text":"<p>In order to test these different models, you need to generate the vectors associated with that model, so go to the project settings:</p> <p></p> <ul> <li>Then go to Vectors &gt; Create new vectors.</li> <li>Choose the name of the model you want to use, in the example below SIGLIP.</li> <li>Confirm by pressing Create and the calculation should start in a few seconds.</li> </ul> <p></p> <p>Note</p> <p>It is also possible to check the \"greyscale\" option before pressing \"Create\" if you wish to ignore the color of the images. This can be useful, for example, in a corpus containing black and white images and others in color, if you do not want color to be a determining criterion for what is represented in the image.</p> <p>Note</p> <p>If for any reason the vector calculation is interrupted, it can be restarted by pressing the following button: </p>"},{"location":"en/advanced/models/#using-vectors","title":"Using Vectors","text":"<p>Once generated, the new vectors are not used by default. As other vectors (CLIP for example) remain available, you must choose which vectors you want to use when executing an action.</p> <p>Thus, in any Panoptic similarity action, clustering, visual similarity, textual similarity, group recommendation, it is always possible to specify which vectors to use:</p> <ul> <li>When executing a function, click on vec_type and choose the vectors you have just generated:</li> </ul> <p></p>"},{"location":"en/advanced/onglets/","title":"Tabs","text":"<p>As briefly discussed earlier, Panoptic offers a tab system allowing different viewpoints to be maintained in parallel on the same corpus.</p>"},{"location":"en/advanced/onglets/#example-use-case","title":"Example Use Case","text":"<p>The objective is to create workspaces dedicated to certain objects using filters, sorts, and groups. A basic example is the use of a \"trash\" tab. A first exploration tab is used, in which images are annotated with a \"out of corpus\" checkbox property while applying a filter on this property. All checked images then instantly disappear from the first tab thanks to this filter and appear in another tab that has the inverse filter (i.e., only showing images that have the \"out of corpus\" box checked). This allows one to occasionally refocus on the \"trash\" tab to review images that have been designated as out of corpus and to verify that no errors have been made, without having to see these images in the main view.</p>"},{"location":"en/advanced/onglets/#views","title":"Views","text":"<p>If each tab can have its own filters, sorts, and groups, it is also possible to configure the desired display at the tab level by choosing the view. </p>"},{"location":"en/advanced/onglets/#grid-view","title":"Grid View","text":"<p>The default view displays a simple grid of images.</p>"},{"location":"en/advanced/onglets/#table-view","title":"Table View","text":"<p>A classic table view, it allows focusing more on the properties accompanying the images, especially text properties that can take up space.</p>"},{"location":"en/advanced/onglets/#graph-view","title":"Graph View","text":"<p>A view that is still a bit experimental but allows displaying graphs showing the number of images contained in a grouping. Example, if I group my images by date and switch to graph view, I can display the number of images at each date, as well as a preview of the images at that date by hovering over a point:</p> <p></p> <p>Note</p> <p>It should be noted that all filters and sorts are also applied in real time in this view, which allows you to modify your graph on the fly according to other properties you might have. In the example above, only the graph between certain dates is displayed, and only images that have been tagged as \"rimbaud\". Similarly, grouping by date allows changing the granularity of the grouping by choosing by minute, hour, day, week, month, year. These changes are also reflected in the graph.</p> <p>It is also possible to add a new grouping to split the graph according to another property. Here, for example, we add a grouping after the date to then group by the type of source from which the images originate at each date. (We also changed the graph type to histogram by clicking on the \"Histogram\" button).</p> <p></p>"},{"location":"en/advanced/projectimport/","title":"Share a Project","text":"<p>It is possible to import an existing project, which allows transferring a project from one computer to another. To do this, simply click on import from the main menu, and navigate to a folder containing the .db file of the project you wish to import.</p> <p></p> <p>!!! info  An advantage of importing a project is that it avoids recalculating image vectors, as these are already automatically stored in the .db file.  A common use is therefore to calculate vectors on a powerful computer and then share the project for exploration on less powerful projects.</p>"},{"location":"en/advanced/projectimport/#integrate-images","title":"Integrate Images","text":"<p>It should be noted, however, that by default only image thumbnails are integrated into a .db file. Thus, to function correctly, you will first need to enable saving HD versions of images in the project settings.</p>"},{"location":"en/advanced/projectparams/","title":"Project and Plugin Settings","text":"<p>It is possible to manage a number of options in the project settings.</p> <p>To access them, click on the small gear icon next to the name of the open project in the interface:</p> <p></p> <p>Here you can manage:</p> <ul> <li>the image formats to save in the database. By default, only thumbnails and medium-sized versions calculated during import are kept, but it is also possible to check \"Save large image\". Doing this allows for a relatively autonomous .db project file that can be easily shared with others without them needing the images.</li> <li>the default functions to execute for each similarity tool</li> <li>the default vector type to use for similarity tools</li> <li>the parameters related to each installed plugin</li> </ul>"},{"location":"en/advanced/projectparams/#activate-or-deactivate-plugins-for-a-project","title":"Activate or Deactivate Plugins for a Project","text":"<p>When a plugin is installed in Panoptic, it is automatically activated for all projects. However, in reality, not all projects will necessarily need all plugins. For example, a project without images containing text will not need the OCR plugin. It is therefore possible to deactivate unnecessary plugins for a project from the home page by clicking on the three small dots next to the project name:</p> <p></p> <p>Then simply check or uncheck the plugins to activate/deactivate.</p>"},{"location":"en/advanced/tags/","title":"Tags","text":"<p>Tags are the most common property types for creating annotations. There are two different types: - simple tags: they allow assigning a single, unique tag to an image - multi-tags: they allow assigning as many tags as desired to an image</p>"},{"location":"en/advanced/tags/#hierarchical-tags","title":"Hierarchical Tags","text":"<p>In some cases, it can be useful to create several annotations simultaneously. For example, if I want to annotate my image with the term \"Mona Lisa\" and later I want to group all my images that are paintings, it can be useful to create a \"painting\" tag and add the \"Mona Lisa\" tag as a \"child\" to it. An image tagged with \"Mona Lisa\" will thus be tagged as both \"Mona Lisa\" and \"painting.\"</p> <p>It is possible to create hierarchical links between tags by clicking on the button below:</p> <p></p> <p>Then simply choose an existing tag or create a new one in the field that appears to add a \"child\" tag.</p> <p>## Multi \"parents\"</p> <p>It is possible to create complex hierarchical links. A parent can have several children, but it is also possible for a child to have several parents.</p> <p>This allows assigning different categories in a single step. If we take the previous example, \"Mona Lisa\" could also have the \"woman\" tag as a parent. Assigning the \"Mona Lisa\" tag would then also assign \"painting\" and \"woman.\"</p> <p>Tag management can become a bit complex if there are many tags and multiple hierarchical links. Therefore, there is a dedicated window for more finely managing tags and associated images.</p>"},{"location":"en/advanced/tagsmodal/","title":"The Tag Management Window","text":"<p>The tag management window (or modal) allows for easier manipulation of tags in order to: - rename them - manage hierarchical links - merge tags if deemed necessary</p> <p>There are two possible views: - the list view, the default view, which displays the list of tags, allowing them to be sorted alphabetically or by the number of images associated with these tags  - the tree view, which is more visual and particularly useful when trying to understand the hierarchical organization of tags </p>"},{"location":"en/advanced/tagsmodal/#access","title":"Access","text":"<p>To open this window, simply click on the enlargement icon next to a tag or multi-tag property: </p>"},{"location":"en/advanced/tagsmodal/#sort-tags","title":"Sort Tags","text":"<p>In the list view, it is easy to filter tags by searching in the search field, or to sort them by either their name or the number of images associated with each tag.</p> <p>To do this, simply use the sort buttons</p> <p></p>"},{"location":"en/advanced/tagsmodal/#multiple-selection","title":"Multiple Selection","text":"<p>When you click on a tag, its associated images are displayed on the right. But it is also possible to select several tags at once, by holding down the control key (or shift to select a range of tags). It is then interesting to note that the images associated with all the selected tags are displayed at the same time, which can be practical for comparing tags.</p>"},{"location":"en/advanced/tagsmodal/#merge","title":"Merge","text":"<p>When several tags are selected, it is possible to merge them. The tag \"resulting from the merge\" will be the first selected tag. It is possible to merge as many tags at once as desired. All parent links will also be preserved.</p>"},{"location":"en/advanced/tagsmodal/#create-hierarchical-links","title":"Create Hierarchical Links","text":"<p>As stated on the previous page, it is possible to create hierarchical links between tags. This operation is facilitated here in the modal, especially in the tree view.</p> <p>Simply click on a tag and hold to drag a link to the tag you wish to add as a child. The link is therefore made in the direction \"parent -&gt; child\".</p> <p>It is also possible to manage these links in the list view; simply take a tag and drag and drop it into the desired column (parent or child) of another tag.</p>"},{"location":"en/install/install/","title":"Installation","text":"<p>Hardware Prerequisites</p> <p>Panoptic has been designed and conceived to be executed on a local computer. Many optimization efforts have been made so that the software can run on as many machines as possible; nevertheless, as the number of images increases, a machine with a good processor and at least 16GB of RAM will be recommended for a good user experience.</p>"},{"location":"en/install/install/#with-installation-files-recommended","title":"With Installation Files (Recommended)","text":""},{"location":"en/install/install/#installation_1","title":"Installation","text":"<p>This script-based installation allows you to install the correct version of Python, as well as all dependencies to ensure compatibility:</p> <p>Note</p> <p>You will be asked during the installation if you wish to install a version for a graphics card. This speeds up image import, which can be long, but will take up more space on your disk. It is important to note that this only works with NVidia graphics cards.</p> WindowsLinuxmacOS <p>An executable is available at this link and allows you to install and launch Panoptic within a virtual environment.</p> <pre><code>wget https://raw.githubusercontent.com/CERES-Sorbonne/Panoptic/refs/heads/main/install/start_panoptic_linux.sh -O start_panoptic_linux.sh\nchmod +x start_panoptic_linux.sh\n./start_panoptic_linux.sh\n</code></pre> <pre><code>curl -O https://raw.githubusercontent.com/CERES-Sorbonne/Panoptic/refs/heads/main/install/start_panoptic_mac.sh\nchmod +x start_panoptic_mac.sh\n./start_panoptic_mac.sh\n</code></pre>"},{"location":"en/install/install/#launch","title":"Launch","text":"Windows (cmd)LinuxmacOS <p>Simply launch panoptic.exe</p> <pre><code>./start_panoptic_linux.sh\n</code></pre> <p>In addition, the script normally also adds an icon allowing you to launch Panoptic with a click on the icon.</p> <pre><code>./start_panoptic_mac.sh\n</code></pre>"},{"location":"en/install/install/#with-python","title":"With Python","text":""},{"location":"en/install/install/#installation_2","title":"Installation","text":"<p>If you already have Python installed, with a version greater than or equal to <code>3.10</code>, you can simply execute in a terminal:</p> Windows (cmd)LinuxmacOS <pre><code>pip install panoptic\n</code></pre> <pre><code>pip3 install panoptic\n</code></pre> <pre><code>pip3 install panoptic\n</code></pre> <p>Mac OS Users</p> <p>Xcode tools need to be installed beforehand for Panoptic to function properly on MacOS.</p> <p>These can be installed via: <code>xcode-select --install</code></p> <p>Furthermore, many dependencies must have precise versions to work on Mac. It is therefore recommended to use the Panoptic installation script provided below.</p> <p>Note</p> <p>In all three cases, it is possible to replace <code>panoptic</code> in the command with <code>panoptic[vision]</code> to install Panoptic directly with the similarity module.</p>"},{"location":"en/install/install/#launch_1","title":"Launch","text":"<p>Enter the command <code>panoptic</code> in your terminal</p>"},{"location":"en/install/install/#using-a-virtual-environment","title":"Using a Virtual Environment","text":"<p>Since Python packages can easily conflict depending on versions, it is advisable to install Panoptic in a dedicated Python environment.</p> Windows (cmd)LinuxmacOS <pre><code>python -m venv panoptic_env\npanoptic_env\\Scripts\\activate\npip install panoptic\n</code></pre> <pre><code>python3 -m venv panoptic_env\nsource panoptic_env/bin/activate\npip3 install panoptic\n</code></pre> <pre><code>python3 -m venv panoptic_env\nsource panoptic_env/bin/activate\npip3 install panoptic\n</code></pre>"},{"location":"en/install/install/#launch_2","title":"Launch","text":"Windows (cmd)LinuxmacOS <pre><code>panoptic_env\\Scripts\\activate\npanoptic\n</code></pre> <pre><code>source panoptic_env/bin/activate\npanoptic\n</code></pre> <pre><code>source panoptic_env/bin/activate\npanoptic\n</code></pre>"},{"location":"en/install/install/#installation-with-docker","title":"Installation with Docker","text":"<p>If you have encountered problems with the classic installation, or if you prefer to use Docker, an image is available. First, you need to:</p>"},{"location":"en/install/install/#install-docker","title":"Install Docker","text":"<ul> <li>On MacOS</li> <li>On Windows</li> <li>On Linux</li> </ul>"},{"location":"en/install/install/#option-1-a-single-folder-for-images-and-for-panoptic-data","title":"Option 1: A single folder for images and for Panoptic data:","text":"<p>This implies having created a special folder called \"images\" within the folder you will specify as input to Panoptic. In the following example, it would therefore be necessary that in the folder: <code>/path/to/your/folder</code>, there exists an <code>images</code> folder whose full path would consequently be <code>/path/to/your/folder/images</code>.</p> <p>Then, run the following command (with Docker already launched):</p> <pre><code>docker run -it -p 8000:8000 -v /path/to/your/folder:/data --name panoptic ceressorbonne/panoptic\n</code></pre>"},{"location":"en/install/install/#option-2-a-folder-for-images-and-a-folder-for-panoptic-data","title":"Option 2: A folder for images, and a folder for Panoptic data:","text":"<pre><code>docker run -it -p 8000:8000 \\\n-v /path/to/your/data:/data \\\n-v /path/to/your/images:/data/images \\\n--name panoptic \\\nceressorbonne/panoptic\n</code></pre>"},{"location":"en/install/install_dev/","title":"Installation (Development)","text":"<p>If you wish to contribute to Panoptic by modifying the code or developing plugins, you will need to be able to run Panoptic in development mode.</p> <p>Start by cloning the repository with:</p> <pre><code>git clone https://github.com/CERES-Sorbonne/Panoptic.git\n</code></pre>"},{"location":"en/install/install_dev/#backend-development-only","title":"Backend Development Only","text":"<p>To test and modify the backend functionality, we provide an already built front-end in the backend's html folder:</p> <ul> <li>go to the <code>panoptic-back</code> folder</li> <li>to install dependencies: <pre><code>pip install -e .\n</code></pre></li> <li>launch:  <pre><code>panoptic\n</code></pre></li> </ul>"},{"location":"en/install/install_dev/#front-end-and-back-end-development","title":"Front-end and Back-end Development","text":"<ol> <li>first, complete the backend installation steps</li> <li>go to the <code>panoptic-front</code> folder</li> <li>run <code>npm install</code></li> <li>run <code>npm run dev</code></li> <li>before launching the backend, the <code>PANOPTIC_ENV</code> environment variable must be set to <code>DEV</code> to use the development frontend.</li> </ol>"},{"location":"en/install/install_plugin/","title":"Installation (Final)","text":"<p>Info</p> <p>If you have installed Panoptic with a script / an exe or by using panoptic[vision], this step can be ignored.</p> <p>For flexibility, Panoptic is installed without similarity tools. In most cases, you will want to install them to use the clustering and image similarity features.</p> <p>To do this, simply click on the \"Install Similarity Plugin\" button on the Panoptic home page once it is launched. This will take a few moments as the libraries can be a bit heavy to download (several hundred MB).</p> <p></p> <p>Using a Graphics Card</p> <p>If you have a graphics card (GPU), this can speed up Panoptic's operation during image import. However, depending on how you installed Panoptic and your operating system, you may not always have the GPU libraries installed by default. Installation information for CUDA versions of PyTorch is available for each OS at this link.</p> <p>Note that Panoptic's execution will not be impacted if you do not have a GPU; only image import (which only happens once) will be slower.</p>"},{"location":"en/method/clusters/","title":"Creating Clusters to Identify Trends","text":""},{"location":"en/method/clusters/#nested-clustering","title":"Nested Clustering","text":""},{"location":"en/method/clusters/#saving-clusters","title":"Saving Clusters","text":""},{"location":"en/method/clusters/#requesting-recommendations","title":"Requesting Recommendations","text":""},{"location":"en/method/clusters/#renaming-clusters","title":"Renaming Clusters","text":""},{"location":"en/method/duplicates/","title":"Identify duplicates","text":"<p>This is a placeholder for the Identify duplicates documentation.</p>"},{"location":"en/method/noise/","title":"Denoise your corpus","text":"<p>This is a placeholder for the Denoise your corpus documentation.</p>"},{"location":"en/method/workspaces/","title":"Manage your workspaces","text":"<p>This is a placeholder for the Manage your workspaces documentation.</p>"},{"location":"en/plugins/add/","title":"Install a Plugin","text":"<p>Installing a plugin is (normally) relatively easy; you just need the address of a GitHub (or GitLab) repository where the plugin's code is stored. For example: https://github.com/PanopticOrg/PanopticOCR</p> <p>In Panoptic, you then need to go to the main page and click on the +:</p> <p></p> <p>Enter the git URL, click in the name field (which should automatically fill from the URL), then click Install.</p> <p></p> <p>The plugin should then install, and once finished, it becomes available for all projects.</p>"},{"location":"en/plugins/create/","title":"Create Your Own Plugins","text":"<p>If existing plugins do not meet your needs, feel free to create your own. They largely consist of free Python code in which you will write the desired behavior. You just need to follow a format and know the few Panoptic functions that allow you to connect to the interface actions.</p> <p>A detailed guide with an example is available here:</p> <p>https://github.com/CERES-Sorbonne/Panoptic/wiki/Plugin</p>"},{"location":"en/plugins/dev/","title":"Create plugins","text":""},{"location":"en/plugins/dev/#overview","title":"Overview","text":"<p>Panoptic implements a plugin system that lets you customize how you work with your image data. The interface can adapt to various action results, making it a convenient tool for data visualization and manipulation.</p>"},{"location":"en/plugins/dev/#how-it-works","title":"How It Works","text":"<p>Plugins extend Panoptic by hooking into multiple points:</p> <ul> <li>UI Actions \u2013 Register custom actions that appear in the interface and operate on selected images</li> <li>System Events \u2013 Respond to events such as image imports or folder deletions to automate data updates</li> <li>Data Layer \u2013 Define custom properties, store vectors, and manage data structures within the project database</li> </ul> <p>Panoptic\u2019s own machine learning features\u2014CLIP vectors, FAISS clustering, similarity search, and duplicate detection\u2014are implemented inside the PanopticML plugin: https://github.com/CERES-Sorbonne/PanopticML</p> <p>It serves as a good example for understanding how to develop your own plugin.</p>"},{"location":"en/plugins/dev/#plugin-loading-and-lifecycle","title":"Plugin Loading and Lifecycle","text":"<p>Plugins are loaded at the project level, meaning each Panoptic project can have its own set of active plugins with project-specific configurations. When a project opens, its plugins are initialized and remain active throughout the project's lifetime. A plugin is identified by a unique name.</p>"},{"location":"en/plugins/dev/#core-components","title":"Core Components","text":"<p>PluginProjectInterface: The main interface that plugins use to interact with the Panoptic project. It provides access to:</p> <ul> <li>Database operations (instances, properties, tags, vectors</li> <li>Task management for long-running operations</li> <li>Event system for reacting to project changes</li> <li>UI update triggers</li> </ul> <p>APlugin: The base class that all plugins must inherit from. It handles:</p> <ul> <li>Action registration for UI integration</li> <li>Event subscription management</li> <li>Access to plugin-specific resources</li> </ul>"},{"location":"en/plugins/dev/#plugin-resources","title":"Plugin Resources","text":"<p>Each plugin has access to:</p> <ul> <li>Data folder: A dedicated directory for storing plugin-specific data, models, caches, or any persistent files the plugin needs</li> <li>Project interface: Full access to project data and operations through the <code>PluginProjectInterface</code></li> <li>Base path: The project\u2019s root directory for accessing project files</li> </ul>"},{"location":"en/plugins/dev/#plugin-setup","title":"Plugin Setup","text":"<p>Before a plugin can interact with a Panoptic project, it must be properly initialized and registered. This section explains how to define the plugin class, configure its parameters, and register actions or events so that it integrates seamlessly into the Panoptic environment.</p>"},{"location":"en/plugins/dev/#base-class","title":"Base Class","text":"<p>Every plugin inherits from <code>APlugin</code> and is instantiated with three parameters:</p> <pre><code>class MyPlugin(APlugin):\n    def __init__(self, project: Project, plugin_path: str, name: str):\n        super().__init__(name=name, project=project, plugin_path=plugin_path)\n        # Initialize your plugin here\n</code></pre> <ul> <li><code>project</code>: The loaded Panoptic project</li> <li><code>plugin_path</code>: The filesystem path where your plugin is located</li> <li><code>name</code>: Your plugin\u2019s unique identifier</li> </ul> <p>To avoid blocking the application thread, you can execute heavy workloads by overriding the asynchronous function <code>_start()</code>. <code>_start()</code> is called automatically when the plugin is loaded.</p> <pre><code>async def _start(self):\n    # Load models, create initial properties, etc.\n</code></pre>"},{"location":"en/plugins/dev/#available-attributes","title":"Available Attributes","text":"Attribute Type Description <code>name</code> <code>str</code> The plugin\u2019s identifier, provided by the user when registering it into Panoptic. <code>params</code> <code>Any</code> Customizable <code>params</code> object that provides persistent storage for plugin settings. These can be updated from the UI. <code>path</code> <code>str</code> Filesystem path to the plugin directory. <code>data_path</code> <code>Path</code> Path to the plugin\u2019s personal data folder. The folder is automatically deleted when removing the plugin. <code>project</code> <code>PluginProjectInterface</code> Main interface for interacting with the current project. Provides access to project methods and database operations. <code>_project</code> <code>Project</code> Warning: The real project object given at initialization. Use only if necessary. UI updates are not guaranteed for direct modifications. <code>registered_functions</code> <code>List[FunctionDescription]</code> List of actions currently registered by this plugin. <code>vector_types</code> <code>list[VectorType]</code> Vector types registered by your plugin, automatically updated when modified. <code>base_key</code> <code>str</code> Unique database key used to store plugin parameters (<code>&lt;plugin_name&gt;.base</code>)."},{"location":"en/plugins/dev/#available-methods","title":"Available Methods","text":"Method Type Description <code>def add_action(self, function, description)</code> Method Register a custom action manually by providing a <code>FunctionDescription</code>. <code>def add_action_easy(self, function, hooks: list[str] = None)</code> Method Quickly register an async function as an action. You can specify where the action appears in the UI by setting the hooks.  Possible values: <code>'vector_type'</code>, <code>'vector'</code>, <code>'similar'</code>, <code>'group'</code>, <code>'execute'</code>"},{"location":"en/plugins/dev/#plugin-parameters","title":"Plugin Parameters","text":"<p>Plugin parameters let users configure a plugin\u2019s behavior without modifying its code. Define your plugin\u2019s parameters by creating a Pydantic <code>BaseModel</code>. These parameters can be adjusted through the UI and are automatically persisted in the database.</p> <pre><code>from pydantic import BaseModel\n\nclass MyPluginParams(BaseModel):\n    # Boolean flags\n    auto_process_imports: bool = True\n\n    # Numeric settings\n    batch_size: int = 32\n    confidence_threshold: float = 0.75\n\n    # String options\n    output_format: str = \"json\"\n</code></pre> <p>For each type, the UI shows an adapted input field:</p> <ul> <li><code>int</code>: Number input</li> <li><code>float</code>: Number input with decimal</li> <li><code>str</code>: Text input</li> <li><code>bool</code>: Checkbox input</li> <li><code>PropertyId</code>: Property selection</li> <li><code>Enum</code>: Selection field</li> <li><code>VectorType</code>: Any registered vector selection</li> <li><code>OwnVectorType</code>: Own registered vector selection</li> </ul> <p>Initialize parameters in your plugin\u2019s <code>__init__</code>:</p> <pre><code>class MyPlugin(APlugin):\n    def __init__(\n        self, \n        project: PluginProjectInterface, \n        plugin_path: str, \n        name: str\n    ):\n        super().__init__(name=name, project=project, plugin_path=plugin_path)\n\n        # Initialize with defaults\n        self.params = MyPluginParams()\n</code></pre>"},{"location":"en/plugins/dev/#creating-functions","title":"Creating Functions","text":"<p>Plugin functions are async methods that perform operations on project data. They receive an <code>ActionContext</code> and can also declare additional inputs:</p> <pre><code>async def my_function(self, context: ActionContext, param1: str):\n\n    # Get instances selected by user\n    instances = await self.project.get_instances(context.instance_ids)\n\n    # Process data\n    results = process_data(instances, param1)\n\n    # Return results\n    return ActionResult(\n        groups=[results],\n        notifs=[Notif(NotifType.INFO, \"Success\", \"Processing complete\")]\n    )\n</code></pre> <p><code>ActionContext</code> is defined as follows:</p> <p><pre><code>@dataclass  \nclass ActionContext:  \n    instance_ids: List[int] | None = None  \n</code></pre> The values reflect the current UI context in which the action was called. Use <code>instance_ids</code> to know on which instances to apply the action.</p> <p>Additional parameters can be defined as long as they are one of the supported types: <code>int, float, str, bool, PropertyId, Enum, VectorType, OwnVectorType</code></p> <p>A valid plugin function must return an <code>ActionResult</code>:</p> <pre><code>@dataclass  \nclass ActionResult:  \n    groups: list[Group] = None  \n    notifs: list[Notif] = None  \n    value: Any = None\n</code></pre> <ul> <li><code>groups</code>: Groups of images to be shown in the UI</li> <li><code>notifs</code>: Notifications (<code>INFO</code>, <code>ERROR</code>, <code>WARNING</code>)</li> <li><code>value</code>: Placeholder for single-value results</li> </ul>"},{"location":"en/plugins/dev/#actionresult","title":"ActionResult","text":"<p>The <code>ActionResult</code>object serves a unified return type for plugin actions.</p> <pre><code>@dataclass  \nclass ActionResult:  \n    groups: list[Group] = None  \n    notifs: list[Notif] = None  \n    value: Any = None\n</code></pre>"},{"location":"en/plugins/dev/#groups","title":"Groups","text":"<p>When called from the instance views the actions <code>group</code>, <code>similar</code>and <code>execute</code> can show instance groups to the user by filling the <code>groups</code>field.</p> <p>A <code>Group</code>is defined as follows: <pre><code>@dataclass  \nclass Group:  \n    ids: list[int] = None  \n    sha1s: list[str] = None  \n    # scores of the ids or sha1's  \n    scores: ScoreList = None  \n    # score of the group  \n    score: Score = None  \n    name: str = None\n    ```\n\nyou can populate the group with `instances`or `images`by fillings the `ids (instances)`or `sha1s (images)`fields. Populating both fields should not be done and will give unexpected results in the UI.\n\nGroups and instances/images can have a score.\n```python\n@dataclass  \nclass Score:  \n    value: float  \n    min: float  \n    max: float  \n    description: str = ''  \n    max_is_best: bool = True\n</code></pre></p> <p>setting the min/max fields allows the UI to show adapted filtering options. the <code>max_is_best</code>field is used to inverse the sorting direction. The <code>description</code>field gives information to the user about the interpretation of this score.</p> <p>To score the instances/images fill the <code>scores</code>field with a <code>ScoreList</code>: <pre><code>@dataclass  \nclass ScoreList:  \n    values: list[float]  \n    min: float  \n    max: float  \n    description: str = ''  \n    max_is_best: bool = True\n</code></pre> The only difference is that the value field is now an array. The values should be in the same order as the <code>ids</code>or <code>sha1s</code>.</p> <p>You can also give a custom name to your group to be displayed with <code>name</code>. If no name is set a default name will be given.</p>"},{"location":"en/plugins/dev/#notifications","title":"Notifications","text":"<p>An action can return notifications for the user. <pre><code>class Notif:  \n    type: NotifType  \n    name: str = None  \n    message: str = None  \n    data: Any = None  \n    functions: list[NotifFunction] = None  \n\nclass NotifType(Enum):  \n    DEBUG = \"debug\"  \n    INFO = \"info\"  \n    WARNING = \"warning\"  \n    ERROR = \"error\"\n\nclass NotifFunction:  \n    function: str  \n    context: ActionContext\n    message: str\n</code></pre></p> <ul> <li><code>type</code>: type of notification for filtering</li> <li><code>name</code>: notification name to be displayed</li> <li><code>message</code>: notification message</li> <li><code>data</code>: Any data displayed as JSON in the UI</li> <li><code>functions</code>: Actions suggestion to be displayed in the UI.</li> </ul> <p>The <code>NotifFunction.function</code>field expects the function string id. You can get it by saving the function description when registering actions as shown in the next section.</p> <pre><code>description = self.add_action_easy(self.my_func, hooks)\ndescription.id # contains the function string id\n</code></pre>"},{"location":"en/plugins/dev/#registering-actions","title":"Registering Actions","text":"<p>Function can be registered in the plugin constructor <code>__init__()</code>. Two functions are available to do so: <pre><code>def add_action_easy(\n    self, \n    function: AsyncCallable, \n    hooks: list[str] = None\n) -&gt; FunctionDescription\n\ndef add_action(\n    self, \n    function: AsyncCallable, \n    description: FunctionDescription\n) -&gt; FunctionDescription\n</code></pre> The function <code>add_action_easy()</code>automatically parses the given function signature and inline documentation to generate a <code>FunctionDescription</code>. The <code>hooks</code>array defines where in the UI the function should be made available.  Current hooks are: - <code>'vector_type'</code>: Vector type creation actions - <code>'vector'</code>: Vector computation actions - <code>'similar'</code>: Similarity search actions - <code>'group'</code>: Clustering and grouping actions - <code>'execute'</code>: General execution actions</p> <p>The <code>FunctionDescription</code>gives the UI all needed information to make an UI element adapted to the functions inputs. Parameter have customizable label, descriptions, input fields. For more control over the UI you can populate the <code>FunctionDescription</code>object yourself and register the function with <code>add_action()</code>.</p>"},{"location":"en/plugins/dev/#system-events","title":"System Events","text":"<p>Plugins can also listen to events to react accordingly:</p> <pre><code>def on_instance_import(self, \n    callback: Callable[[Instance], \n    Awaitable[None]]\n)\n\ndef on_folder_delete(\n    self, \n    callback: Callable[[DeleteFolderConfirm],\n    Awaitable[None]]\n)\n</code></pre> <p>For example, the <code>PanopticML</code> plugin uses the instance import event to automatically calculate image vectors and the folder delete event to update its FAISS vector indexes.</p>"},{"location":"en/plugins/dev/#data","title":"Data","text":"<p>Plugins often need to read and write project data. This section details how to access instances, tags, and vectors from the database, and how to safely commit changes while keeping the UI synchronized with the project state.</p>"},{"location":"en/plugins/dev/#reading","title":"Reading","text":"<p>The plugin interface provides methods to query various types of data from the project database.</p> <p>The first step is usually to retrieve more information about the instances from the <code>ActionContext</code>:</p> <pre><code># Get instances by IDs\ninstances = await self.project.get_instances(ids=[1, 2, 3])\n# Get instances by SHA1 hashes\ninstances = await self.project.get_instances(sha1s=[\"abc123...\", \"def456...\"])  # Get all instances (no filters)\ninstances = await self.project.get_instances()\n</code></pre> <p>For every data type in Panoptic, the interface gives access to corresponding database queries:</p> <pre><code># Folders\nget_folders() -&gt; list[Folder]\n\n# Properties\nget_properties(ids: list[int] = None, computed: bool = False) -&gt; list[Property]\n\n# Tags\nget_tags(ids: list[int] = None, property_ids: list[int] = None) -&gt; list[Tag]\n\n# Instance property values\nget_instance_property_values(\n    property_ids: list[int] = None, \n    instance_ids: list[int] = None\n) -&gt; list[PropertyValue]\n\n# Image property values\nget_image_property_values(\n    property_ids: list[int] = None, \n    sha1s: list[str] = None\n) -&gt; list[PropertyValue]\n\n# Vectors\nget_vectors(type_id: int, sha1s: list[str] = None) -&gt; list[Vector]\nvector_exist(type_id: int, sha1: str) -&gt; bool\n\n# Vector types\nget_vector_types(source: str = None) -&gt; list[VectorType]\n</code></pre> <p>Multiple filtering options are treated as OR conditions.</p>"},{"location":"en/plugins/dev/#writing","title":"Writing","text":"<p>Writing to the project database is mostly done with the commit system. The following types support undo/redo functionality and automatic UI synchronization when using commits:</p> <p><code>folders</code>, <code>instances</code>, <code>properties</code>, <code>property_groups</code>, <code>tags</code>, <code>instance_values</code>, and <code>image_values</code>.</p> <p>A commit object contains one batch of updates:</p> <pre><code>class DbCommit:  \n    empty_instances: list[int]\n    empty_property_groups: list[int]\n    empty_properties: list[int]\n    empty_tags: list[int]\n    empty_instance_values: list[InstancePropertyKey]\n    empty_image_values: list[ImagePropertyKey]\n\n    folders: list[Folder] \n    instances: list[Instance]\n    property_groups: list[PropertyGroup]\n    properties: list[Property]\n    tags: list[Tag]  \n    instance_values: list[InstanceProperty]\n    image_values: list[ImageProperty]\n\n    timestamp: datetime\n</code></pre> <p>To delete objects, mark them in the corresponding <code>empty_</code> lists.</p> <p>Some objects have a unique ID of type <code>int</code>. When creating new objects, you should set a negative Id. Helper functions are provided to ensure correct Id attribution:</p> <pre><code>def create_instance(\n    self, \n    folder_id: int, \n    name: str, \n    extension: str, \n    sha1: str, \n    url: str, \n    width: int, \n    height: int, \n    ahash: str\n) -&gt; Instance\n\ndef create_property(\n    self, \n    name: str, \n    type_: PropertyType, \n    mode: PropertyMode\n) -&gt; Property\n\ndef create_property_group(\n    self,\n    name: str\n) -&gt; PropertyGroup\n\ndef create_tag(\n    self, \n    property_id: int,\n    value: str, \n    parent_ids: list[int] = None, \n    color=-1\n) -&gt; Tag\n\ndef create_vector_type(\n    self, \n    params: dict \n) -&gt; VectorType\n</code></pre> <p>Negative IDs are valid inside a commit and can be referenced by other new objects. For example, an <code>InstanceValue</code> can reference both a new instance and a new property with negative IDs. When writing to the database, Panoptic automatically determines the correct insertion order and updates the IDs once the objects are stored.</p> <p>Execute a commit using one of the following methods:</p> <pre><code>async def apply_commit(self, commit: DbCommit)\n\nasync def do(self, commit: DbCommit)\n</code></pre> <p>The <code>do()</code> function computes the opposite commit before calling <code>apply_commit()</code>, allowing the operation to be reversed later with <code>undo()</code>.</p> <p>Two object types are not written through commits: <code>vector_type</code> and <code>vector</code>. Use the corresponding methods instead:</p> <pre><code>async def add_vector_type(self, vec: VectorType) -&gt; VectorType\n\nasync def add_vector(self, vector: Vector) -&gt; Vector\n</code></pre>"},{"location":"en/plugins/dev/#heavy-computation-concurrency","title":"Heavy Computation &amp; Concurrency","text":"<p>The Panoptic backend runs in an asynchronous event loop. To avoid blocking the main thread, heavy workloads should be executed in a <code>ThreadPoolExecutor</code>. There are two main ways to do this in Panoptic.</p>"},{"location":"en/plugins/dev/#async-helper","title":"Async Helper","text":"<p>The easiest way to delegate a blocking function to the executor is with the helper:</p> <pre><code>res = await self.project.run_async(function, *args)\n</code></pre> <p>Use this helper for simple background tasks that don\u2019t need to be tracked or visualized in the UI. It\u2019s ideal for lightweight operations where you just need to offload a blocking function to a background thread and asynchronously wait for the result.</p> <p>Examples include:</p> <ul> <li>Running small data transformations</li> <li>Performing lightweight file I/O operations</li> <li>Calling a blocking library function once</li> </ul>"},{"location":"en/plugins/dev/#the-task-queue","title":"The Task Queue","text":"<p>The <code>TaskQueue</code> is designed to manage and track background tasks. Each task can include a sequence of asynchronous or synchronous functions treated as a single work unit.</p> <p>Its main advantage is providing visual feedback in the UI through a progress bar. Additionally, it supports executing specific functions once a set of tasks has completed.</p>"},{"location":"en/plugins/dev/#creating-a-task","title":"Creating a Task","text":"<p>Inherit from the <code>Task</code> base class and implement the <code>run()</code> method:</p> <pre><code>from panoptic.core.task.task import Task\n\nclass MyProcessingTask(Task):\n    def __init__(self, plugin, instance, config):\n        super().__init__(priority=False)  # Set priority=True for urgent tasks\n        self.plugin = plugin\n        self.instance = instance\n        self.config = config\n\n        # Customize task identification\n        self.name = 'Process Image'  # Shown in UI\n        self.key = f'task_1'  # Unique identifier\n\n    async def run(self):\n        \"\"\"Main task execution - this runs in the background\"\"\"\n        # Use _async() for CPU-intensive operations\n        result = await self.run_async(\n            self._heavy_computation,\n            self.instance.url,\n            self.config\n        )\n\n        # Store results (database operations are already async)\n        await self.plugin.project.add_vector(result)\n\n        return result\n\n    async def run_if_last(self):\n        \"\"\"Called once when all tasks with this key are complete\"\"\"\n        # Rebuild indexes, update UI, or perform cleanup\n        await self.plugin.rebuild_index()\n\n    @staticmethod\n    def _heavy_computation(image_path, config):\n        \"\"\"CPU-intensive work runs in executor thread\"\"\"\n        # Load and process image\n        image = Image.open(image_path)\n\n        # Perform heavy computation\n        vectors = extract_vectors(image, config)\n\n        return vectors\n</code></pre> <p>The <code>self.key</code> field serves two purposes:</p> <ul> <li>Executes the <code>run_if_last()</code> function on the last task with the same key</li> <li>Groups related tasks together in the UI</li> </ul>"},{"location":"en/plugins/dev/#adding-tasks-to-the-queue","title":"Adding Tasks to the Queue","text":"<p>Add tasks from your plugin using the project interface:</p> <pre><code>def add_task(self, task: Task):\n</code></pre> <p>The TaskBar should now be visible in the UI.</p>"},{"location":"en/plugins/dev/#step-by-step-example","title":"Step by Step example","text":"<p>This guide will show you how to create a new plugin step by step. Our goal is to add some custom functions to Panoptic: - <code>compute_vectors()</code>: a function that computes image vectors - <code>compute_clusters()</code> a function that computes clusters for a list of instances</p> <p>To keep it very simple we will implement one function that computes the vectors of an instance selection with the <code>execute</code>hook. And a clustering function with the <code>group</code>hook. We will have only one default vector type.</p>"},{"location":"en/plugins/dev/#folder","title":"Folder","text":"<p>A plugin is contained in a folder that we will call <code>my_plugin</code> inside this folder we create three files: <code>__init__.py</code>, <code>my_plugin.py</code> and <code>requirements.txt</code></p> <pre><code>my_plugin\n| __init__.py\n| my_plugin.py\n| requirements.txt\n</code></pre> <ul> <li><code>__init__.py</code>is the entry point for the plugin loader.</li> <li><code>requirements.txt</code>contains the pip module requirements for the plugin. In our case it will be empty.</li> <li><code>my_plugin.py</code>contains the plugin code</li> </ul>"},{"location":"en/plugins/dev/#plugin-initialization","title":"Plugin Initialization","text":"<pre><code># my_plugin.py\n\nfrom panoptic.core.plugin.plugin import APlugin  \nfrom panoptic.core.project.project import Project  \nfrom panoptic.models import ActionContext  \nfrom panoptic.models.results import ActionResult  \n\n\nclass MyPlugin(APlugin):  \n    def __init__(self, project: Project, plugin_path: str, name: str):  \n        \"\"\"  \n        The initialization method for a Panoptic Plugin. \n        Is called by Panoptic at Project launch.        \n        :param project: The Project instance        \n        :param plugin_path: The path to the plugin module        \n        :param name: The identifier of the plugin as a unique name\n        \"\"\"        \n        # dont forget to call parent constructor  \n        super().__init__(name=name, project=project, plugin_path=plugin_path)  \n        self.add_action_easy(self.compute_vectors, ['vector'])  \n        self.add_action_easy(self.compute_clusters, ['group'])  \n\n    async def compute_vectors(self, ctx: ActionContext):  \n        res = ActionResult()  \n        # some code ...  \n        return res  \n\n    async def compute_clusters(self, ctx: ActionContext, nb_clusters: int):  \n        res = ActionResult()  \n        # some code ...  \n        return res\n</code></pre> <p>This code snippet defines our plugin class. It is important to call the parent constructor in our own <code>__init__(..)</code> function to properly initialize the plugin. We can then register our function and select our action hooks. The <code>compute_vectors()</code>function is registered as an <code>vector</code>action and the <code>compute_clusters()</code> function as an <code>group</code>action.</p> <p>The function body is empty for now but to ensure that UI is happy we already return an <code>ActionResult</code>.</p> <pre><code># __init__.py\nfrom my_plugin import MyPlugin  \n\nplugin_class = MyPlugin\n</code></pre> <p>Finally we declare the <code>plugin_class</code>in the <code>__init__.py</code>file.</p> <p>You can now start Panoptic and add your plugin. You should see your clustering function on the <code>group</code> <code>ActionButton</code>.</p> <p></p> <p>As you can see our vector compute function is not visible in the UI. This is because we didn't register any <code>vector_type</code>for our plugin. Vector types serve as identifier for vectors.</p> <p></p>"},{"location":"en/plugins/dev/#creating-vectors","title":"Creating Vectors","text":"<p>To store vectors in the database we need to register a vector_type for them. For this example we will only one type for our dummy vectors.</p> <pre><code>async def _start(self):  \n    if len(self.vector_types) == 0:  \n        vec_type = self.project.create_vector_type({\"model\": \"fake_vector\"})  \n        await self.project.add_vector_type(vec_type)  \n        print('created ', vec_type)\n</code></pre> <p>We implement the <code>_start()</code> function, which is automatically called when the plugin is loaded. The variable <code>self.vector_types</code> is automatically updated with vector types created by this plugin. If the list is empty we want to create one.  Like other objects, vector types have a unique integer ID managed by the database. You can create a new vector type using the utility function: <pre><code>self.project.create_vector_type(params: dict)\n</code></pre> Then we add the vector type to the database with <pre><code>await self.project.add_vector_type(vec_type) \n</code></pre></p> <p><code>self.vec_type</code>now contains our new vector type, and it is visible in the UI.</p> <p> And our compute vector function is now callable by clicking on the <code>compute</code>button in the vector row.</p> <p>We want to place the images in a 1-dimensional vector space where the value represents the main hue (0-255) of the image. Our computation function looks like this: <pre><code>@staticmethod  \ndef compute_hue_vector(path: str):  \n    img = Image.open(path)  \n    img = img.convert('RGB')  \n    img_hsv = img.convert('HSV')  \n\n    # Get HSV data as numpy array  \n    hsv_array = np.array(img_hsv)  \n\n    # Extract hue channel (first channel in HSV)  \n    hue_channel = hsv_array[:, :, 0]  \n\n    # Flatten and calculate histogram  \n    hue_flat = hue_channel.flatten()  \n\n    # Get most common hue value  \n    counts = np.bincount(hue_flat)  \n    dominant_hue = np.argmax(counts)  \n\n    # 1-dimensional vector. Convert to float32 to match database type\n    return np.array(int(dominant_hue), dtype='float32')\n</code></pre></p> <p>and our updated <code>compute_vectors()</code> function</p> <pre><code>async def compute_vectors(self, ctx: ActionContext):  \n    # get instances from database  \n    instances = await self.project.get_instances(ids=ctx.instance_ids)  \n    # keep only on instance per sha1  \n    unique = list({i.sha1: i for i in instances}.values())  \n    # get our vector type id  \n    type_id = self.vector_types[0].id  \n\n    for instance in unique:  \n        # compute the hue vector in the executor to avoid blocking \n        # the main thread  \n        hue_vector = await self.project.run_async(\n            self.compute_hue_vector, instance.url\n        )  \n        # create the vector object to be written in the database  \n        vector = Vector(type_id=type_id, sha1=instance.sha1, data=hue_vector)  \n        # write to database  \n        await self.project.add_vector(vector)  \n\n    # send success notification  \n    notif = Notif(\n        type=NotifType.INFO, \n        name='compute_vectors', \n        message='Computed all vectors'\n    )  \n    # always return an ActionResult  \n    return ActionResult(notifs=[notif])\n</code></pre> <p>It is important to wrap computationally intensive functions with the <code>run_async</code> function. Even better, you can use the <code>Task</code> and <code>TaskQueue</code> interfaces to execute computations in the background. You can refer to the official PanopticML plugin for an example that uses a <code>Task</code> object.</p> <p>At the end, we return a notification to indicate that the computation completed successfully. This notification will appear in the UI once the action has finished.</p> <p> If your function crashes without proper error handling, Panoptic will automatically generate an error notification that includes the traceback.</p> <p></p>"},{"location":"en/plugins/dev/#clustering","title":"Clustering","text":"<p>Now that we have vectors we can start clustering. For our example we will sort the images by hue value and then create a chosen number of equally sized groups.</p> <p>The computation looks like this: <pre><code>@staticmethod  \ndef group_instances_by_hue(\n    instances: list[Instance], \n    sha1_to_hue: dict[str, int], \n    num_groups: int\n    ):  \n    \"\"\"  \n    Sort instances by hue and group them.    \n    \"\"\"   \n    # Use np for simplicity\n    id_array =  np.array([i.id for i in instances])  \n    hue_array =  np.array([sha1_to_hue[i.sha1] for i in instances])  \n\n    # Sort by hue  \n    sorted_indices = np.argsort(hue_array)  \n    sorted_ids = id_array[sorted_indices]  \n    sorted_hue = hue_array[sorted_indices]  \n\n    # Split into equal-sized groups  \n    id_groups = np.array_split(sorted_ids, num_groups)  \n    hue_groups = np.array_split(sorted_hue, num_groups) \n\n    return id_groups, hue_groups\n</code></pre></p> <p>We have to integrate this result into the <code>ActionResult</code>api. <pre><code>async def compute_clusters(self, ctx: ActionContext, nb_clusters: int):  \n    # get instances from the database  \n    instances = await self.project.get_instances(ids=ctx.instance_ids)  \n    # get our own vectors from the database  \n    vectors = await self.project.get_vectors(self.vector_types[0].id)  \n    # map sha1 to Hue with the vector data  \n    sha1_to_hue = {v.sha1: v.data.tolist()[0] for v in vectors}  \n    # compute vectors with the data  \n    id_groups, hue_groups = self.group_instances_by_hue(\n        instances, sha1_to_hue, nb_clusters\n    )  \n\n    # iterate over result and fill the Group objects  \n    groups = []  \n    for id_group, hue_group in zip(id_groups, hue_groups):  \n        # get min and max hue of each group  \n        min_hue = hue_group.min()  \n        max_hue = hue_group.max()  \n        # create Group of instance ids  \n        group = Group(\n            # extract the instance ids from the np.array\n            ids=id_group.tolist(), \n            # choose a name for the group\n            name=f\"Hue group: {min_hue}-{max_hue}\"\n        )  \n        groups.append(group)  \n\n    # return the clusters  \n    return ActionResult(groups=groups)\n</code></pre></p> <p>The implementation of the <code>compute_vectors</code>is easy to follow. First we retrieve all needed data to compute our clustering and then we use the <code>ActionResult</code>to return the groups to the UI.</p> <p></p> <p>Call the function from the Cluster <code>ActionButton</code>and the result should be visible in the UI. Be sure to have executed the compute vector action before.</p> <p>Hopefully this guide was able to make the logic behind the plugin system more understandable. The official PanopticML plugin is the best resource to have more complex examples of plugin usage.</p>"},{"location":"en/plugins/intro/","title":"Plugins","text":"<p>Due to the multiplicity of uses and possible treatments applicable to images, Panoptic does not integrate many basic functionalities, which facilitates installation but above all avoids overwhelming users with a large number of models and functionalities. Thus, as we have seen, even Panoptic's \"native\" similarity functionalities are in the form of plugins, and it is actually possible to install the tool without the latter if one simply wishes to explore a corpus and annotate it without using image models.</p>"},{"location":"en/plugins/intro/#plugin-examples","title":"Plugin Examples","text":"<ul> <li>A frequently requested feature that has been developed as a plugin is image OCRization.</li> <li>A plugin for clustering images based on the textual properties accompanying these images.</li> <li>A plugin for calculating the dominant colors of images.</li> <li>...</li> </ul>"},{"location":"en/start/annotate/","title":"Annotating Properties","text":"<p>Once a property is created and displayed, it is possible to annotate the imported images.</p> <p>When a property is displayed, an empty line is shown below each image. If two properties are displayed, two lines will be shown below each image, and so on.</p>"},{"location":"en/start/annotate/#annotating-an-image","title":"Annotating an Image","text":"<p>To annotate a single image, simply click on the empty space associated with the correct property below the image, and fill in the desired annotation.</p> <p></p> <p>Once an annotation is created, it is automatically suggested for subsequent annotations.</p> <p></p>"},{"location":"en/start/annotate/#batch-annotating","title":"Batch Annotating","text":"<p>It is possible to annotate images in batches. When you hover over an image, a clickable checkbox appears in the upper right corner of the image. By clicking, the checkbox turns blue: the image is selected. You can select several images this way. It is possible to select all images located between two images by selecting these two images while holding down the shift key.</p> <p>When several images are thus selected, a \"Tag X selected images\" option appears in the upper right corner of Panoptic. By clicking on it, you can select as many annotations as you wish for all selected images. Finally, click \"Apply\" and the images will be annotated.</p> <p>Attention</p> <p>Once images are annotated in this way, remember to deselect the selected images so as not to re-annotate them later. To deselect them, click on the cross (x) to the left of \"Tag X selected images\".</p> <p></p>"},{"location":"en/start/annotate/#annotating-a-cluster-of-similar-images","title":"Annotating a Cluster of Similar Images","text":""},{"location":"en/start/annotate/#annotating-an-entire-cluster","title":"Annotating an Entire Cluster","text":"<p>To create clusters of similar images, see the documentation on clusters.</p> <p>It is possible to annotate an entire cluster by clicking on the \"Tag group\" option above a cluster.</p> <p>In the window that opens, click next to the created property (on \"None\"), and choose an existing tag or create a new one. Finally, click \"Apply.\"</p> <p></p>"},{"location":"en/start/annotate/#annotating-part-of-a-cluster-or-several-parts-of-several-clusters","title":"Annotating Part of a Cluster, or Several Parts of Several Clusters","text":"<p>If the proposed clusters are not suitable enough for annotation, it is possible to select only a part of the images displayed to annotate them. Here, simply reproduce the batch annotation described earlier, but within a cluster.</p> <p></p> <p>Important</p> <p>It is possible to create sub-clusters (see the documentation on clusters). They function like clusters and are therefore annotatable in the same way.</p>"},{"location":"en/start/annotate/#saving-clusters","title":"Saving Clusters.","text":"<p>By default, clusters are not saved, as they are computer-generated proposals for image associations that a human must validate.</p> <p>If you wish to save a cluster, you must specify it by clicking on the floppy disk icon next to the open clusters. You can save each cluster or sub-cluster independently, or all clusters directly, by clicking on the floppy disk located at the root (at the very top, above the first images).</p> <p>When clusters are saved, they are recorded in a dedicated property, named \"clustering,\" which you can find on the left side of the screen, under the property section.</p> <p>You can then rename each element of this property to give meaning to the clustering performed, by going to the tag management window (see the documentation on managing Tag and Multi-tag properties).</p> <p></p>"},{"location":"en/start/annotate/#annotating-images-similar-to-an-image","title":"Annotating Images Similar to an Image","text":"<p>When you click on an image, a contextual window opens, showing on the left the image's properties, and on the right, images similar to this selected image.</p> <p></p> <p>You can annotate these different images directly, in batches. Several options here:</p> <p>You can choose to: select all displayed images (1), or select (or deselect) certain images (2) to refine.</p> <p>You can then click on the \"paint bucket\" icon (3) to annotate all selected images according to the chosen property. You can also click on \"Tag X selected images\" in the upper right to open a menu displaying all available properties, and tag the selected images as you wish (identically to the original image, or differently).</p> <p></p>"},{"location":"en/start/annotate/#annotating-images-similar-to-a-group-of-images","title":"Annotating Images Similar to a Group of Images","text":"<p>If you have already started annotating your image corpus, you can continue annotating by searching for images similar to an already annotated group of images. To do this, you must first group the images according to a property (see the documentation on image grouping). For each group, there is then an \"Image Proposals\" button that you can click (1).</p> <p></p> <p>If filters are active in the view you are working in, it is possible to choose whether to display similar images only present in that view, or not, by activating or deactivating the filter (2).</p> <p>Add images to the group:</p> <p>Once the image proposal window has appeared, you just need to click on the green checkmark or the red cross (3) to accept that the proposed image joins the associated group, or not (i.e., to validate or not that the image is tagged with the corresponding annotation).</p> <p></p>"},{"location":"en/start/clusters/","title":"Clusters","text":"<p>Clusters are a particularly important concept in how Panoptic works. Once vectors are calculated, images can be automatically grouped into clusters. Unlike groups created with properties, clusters are configurable, can be generated with different algorithms, and are not deterministic (the same clustering can produce slightly different results depending on the executions).</p>"},{"location":"en/start/clusters/#creating-clusters","title":"Creating Clusters","text":"<p>Once the project is launched and plugins are loaded, click on the \"Create clusters\" button:</p> <p></p> <p>This should separate your images into 10 distinct groups by similarity as shown in the image below:</p> <p></p>"},{"location":"en/start/clusters/#parameters","title":"Parameters","text":"<p>It is also possible to choose the number of clusters you want to produce by clicking on the small arrow located on the \"Create clusters\" button to open the parameters.</p> <p></p> <p>Then simply modify the value of nb_clusters to indicate the number of clusters to create.</p> <p></p> <p>Info</p> <p>There are other parameters visible in this image for more advanced uses that we will see later.</p> <p>Automatic</p> <p>It is also possible to request an automatic number of clusters to produce by entering <code>-1</code> in the nb_clusters value, but it should be noted that this will take longer to calculate and the result will be very variable from one corpus to another.</p>"},{"location":"en/start/clusters/#scores","title":"Scores","text":"<p>Each produced cluster has a score displayed in color next to its name. These scores are an indicator of the cluster's relevance, i.e., how close the images within it are to each other. The lower the score, the more coherent the cluster is considered. This score is there to give a general idea and can vary from one corpus to another. In other words, if a score of 15 can result in a cluster with almost visually identical images in some corpora, it may be more disparate in others. This depends on the diversity and number of images present in the latter.</p>"},{"location":"en/start/clusters/#nesting-clusters","title":"Nesting Clusters","text":"<p>An important feature of Panoptic is the ability to nest clusters. Indeed, the postulate followed here is that machine learning models will never produce perfect clustering and that it must/can be reworked by the person using Panoptic. In fact, it is possible to re-divide a cluster by pressing the \"Create clusters\" button again to refine the grouping of images.</p> <p>This process can also be repeated indefinitely (as long as there are images to separate).</p>"},{"location":"en/start/clusters/#saving-a-clustering","title":"Saving a Clustering","text":"<p>The clustering process is primarily an exploration tool and is not automatically saved in Panoptic. If you want to persist the work done with this tool, you must either have annotated the images in the clusters or click on the cluster save button:</p> <p></p> <p>This button creates a new property named \"Clustering\" which will assign to each image the cluster it was in as a tag. It should be noted that since clusters can be nested, the tags themselves can be hierarchical.</p>"},{"location":"en/start/clusters/#different-ways-to-cluster","title":"Different Ways to Cluster","text":"<p>The main method presented so far is the default \"PanopticML.compute_clusters,\" but there are other ways to create clusters in the similarity plugin, and other plugins may also offer other ways. Those available by default in the similarity plugin are the following:</p> <ul> <li>compute_clusters: default version that uses the KMeans algorithm and groups images based on a requested number of clusters, practical for quickly iterating and making \"large cuts\" in a corpus.</li> <li>find_duplicates: creates groups by ensuring a minimum similarity threshold between the images in these groups, which can be useful for identifying duplicates or near-duplicates in a corpus. The similarity threshold can be modified to be more or less permissive.</li> <li>cluster_by_tags: experimental, takes a tag or multi-tag property as input and tries to attach each image to the tag it is closest to.</li> </ul> <p>This method can be chosen from a dropdown field in the clustering parameters:</p> <p></p>"},{"location":"en/start/clusters/#to-go-further","title":"To Go Further","text":"<p>For concrete examples of use, see an example of methodology using clustering</p>"},{"location":"en/start/filters/","title":"Manipulating Images Based on Their Properties","text":"<p>Important</p> <p>Prerequisite for (re)arranging a corpus:</p> <p>To create FILTERS, SORTS, or GROUPS, PROPERTIES must exist and be filled. For example, initial annotations of corpus images have been made thematically: \"butterfly\", \"sport\"... Another example, data associated with images has been previously imported, which are constituted as properties during their import.</p> <p>These different functionalities are visual exploration functionalities: everything happens on the screen; the (re)arrangements are neither definitive nor destructive to the corpus. They can be constantly canceled, redone, modified... These (re)arrangements can also be multiplied to explore the corpus in different ways, thanks to the possibility of creating different tabs within Panoptic.</p> <p>(Re)arrangements can be performed at any time during exploration. They can also be planned in advance, once the properties are created, but before anything has been annotated. If annotations are made during the work, one can decide whether or not to activate automatic updating, so that the corpus rearranges itself in the window in real time, or only when desired.</p>"},{"location":"en/start/filters/#filter","title":"Filter","text":"<ul> <li>Press the \"+\" next to FILTER.</li> <li>Select the property from which you want to filter the images. Here you define the display conditions for the images.</li> </ul>"},{"location":"en/start/filters/#why-filter","title":"Why filter?","text":"<p>Filters can be useful in different cases. For example, you can choose to filter images you have already annotated, to display only those you still need to work on.</p> <p>Another example, you can also create a CHECKBOX type property, name it \"off-topic\" or \"annotation completed?\", and decide that images no longer appear in the active Panoptic tab once you have checked the box.</p>"},{"location":"en/start/filters/#group","title":"Group","text":"<p>By clicking on the \"+\" next to the GROUP function, select the property from which you want to group images. Once the property is selected, the groups are formed directly on the screen, in the central panel of Panoptic, according to the given criterion.</p>"},{"location":"en/start/filters/#reordering-groups","title":"Reordering groups:","text":"<p>When a grouping type is added, it is indicated next to the GROUP option. It is possible to change the sort type (number of elements, alphabetical) and the order (ascending or descending) by clicking on the corresponding arrows.</p>"},{"location":"en/start/filters/#groups-and-subgroups","title":"Groups and subgroups:","text":"<p>It is possible to create groups within groups, for example by grouping by a thematic property (what has been annotated to describe the image with a keyword), then by a property imported as metadata, the name of the photographer for example.</p>"},{"location":"en/start/filters/#delete-a-group","title":"Delete a group:","text":"<p>To delete a group, simply click on the name of the property you want to delete, next to the GROUP option.</p>"},{"location":"en/start/filters/#create-clusters-within-a-group","title":"Create clusters within a group:","text":"<p>It is possible to create clusters of similar images within the same group of images to rearrange it.</p>"},{"location":"en/start/filters/#sort","title":"Sort","text":"<ul> <li>Press the \"+\" next to \"SORT\".</li> <li>Select the property from which you want to sort the images.</li> </ul> <p>It is possible to arrange them in alphabetical order, or chronologically, for example.</p> <p>It is possible to combine GROUPING and SORT functions: one can then create groups based on certain properties, and sort the images arranged in these groups based on other properties. Sorting within groups can, for example, be performed using the \"average hash\" property calculated by Panoptic. This is a summary similarity calculation. This can, for example, allow sorting photos by the same photographer (group by \"author\") based on their general resemblances (sort by \"average hash\").</p> <p></p>"},{"location":"en/start/first_start/","title":"First Launch","text":"<p>Upon the first start of Panoptic, an interactive tutorial will be offered. You can follow it or continue here by following this guide.</p>"},{"location":"en/start/first_start/#similarity-plugin","title":"Similarity Plugin","text":"<p>If you haven't already, install the similarity plugin</p>"},{"location":"en/start/images/","title":"Import Images","text":"<p>Once a project is created or opened, the main Panoptic window opens.</p> <p>To import images, click on the \"+\" in the top left of Panoptic. You then need to select the folder where the images you want to import are located.</p> <p>Precision</p> <p>Importing a folder also imports all subfolders contained within it.</p> <p>You can successively import several folders containing images.</p> <p>You should not move the folder containing the images, nor rename its path afterwards.</p>"},{"location":"en/start/images/#import-tracking","title":"Import Tracking","text":"<p>Once you have selected the image folder(s) to import, the import and calculation time generally takes several minutes. This depends on your computer's power and the number of images imported.</p> <p>You can track the import progress on the left, in the \"Background Task\" section. Several pieces of information are indicated: the progress of image import, their thumbnails, and their vectorization.</p> <p>Important</p> <p>For images to be vectorized during import, you must have previously installed the \"PanopticML\" module.</p> <p>Reminder</p> <p>What is image vectorization for? Broadly speaking, image vectorization is a necessary prerequisite for searching for images similar to each other, based on their formal content (what is seen in the images).</p>"},{"location":"en/start/projets/","title":"Projects","text":"<p>Panoptic allows you to work with your corpora locally on your computer. Panoptic therefore does not offer predefined image collections; datasets must be constituted upstream.</p> <p>All actions performed within a project are automatically saved locally on your computer. If you close a project and return to it later, you will find all the actions you performed there.</p> <p>Panoptic allows you to work with as many projects as you wish.</p> <p>In a project, you can work with several image corpora if you wish, imported at once or in several steps.</p>"},{"location":"en/start/projets/#panoptic-project-management-page","title":"Panoptic Project Management Page","text":"<p>Projects are managed on a dedicated page (creation, import, deletion), which is Panoptic's home page: it opens when the software is launched and remains accessible at any time.</p> <p>On the project management page, click on \"Create\" next to \"Create a new project.\"</p> <p></p> <p>This involves defining the location on your computer \u2013 (the \"folder\") \u2013 where you want to save your project.</p> <p>Warning</p> <p>You must not move this folder/rename its path afterwards.</p> <p>Create this folder in a different folder from the one containing your image corpus.</p> <p>We recommand creating a parent folder to hold all your panoptic projects.</p> <p>Then name your project in the \"Project Name\" field.</p> <p>Finally, click \"Create\": your project is created and the Panoptic workspace opens.</p>"},{"location":"en/start/projets/#accessing-an-existing-project","title":"Accessing an Existing Project","text":"<p>When you open Panoptic, choose the project you wish to open on the left by clicking on it.</p> <p></p> <p>If you are already in an open project and wish to change projects, click on the arrow in the top left.</p>"},{"location":"en/start/properties/","title":"Properties","text":"<p>To give meaning to the images studied in the Panoptic interface, this is done by creating and defining a set of PROPERTIES. It is from the created properties that you can annotate the images. These properties are of several types (in English):</p> <ul> <li>text,</li> <li>numeric,</li> <li>tag,</li> <li>multi_tags,</li> <li>checkbox,</li> <li>url,</li> <li>date,</li> <li>color.</li> </ul> <p>Once the properties are created, you can associate annotations with each image separately, or with batches of images, in connection with a particular property, or with several properties. Properties can be created as you go, and not necessarily defined upstream.</p>"},{"location":"en/start/properties/#create-and-display-a-property","title":"Create and Display a Property","text":"<p>To annotate your images, you must first create at least one property, which will contain annotations of specific types (tag, date, text, number...).</p> <p>To create a property (for example, of type \"MultiTags\"):</p> <ul> <li>On the left, click on \"New property.\"</li> </ul> <p></p> <ul> <li>Name the property, choose its type, and choose whether it is an image or instance property. Click \"Confirm.\"</li> </ul> <p></p> <ul> <li>Display (or hide) the created property by clicking on the eye icon next to its name.</li> </ul> <p></p> <p>Important</p> <p>It is not necessary to define in advance the properties you will need during your work. These can be created as you go.</p>"},{"location":"en/start/properties/#image-properties-instance-properties","title":"Image Properties, Instance Properties","text":"<p>A point that can be complicated to decide is the choice between image properties and instance properties. To understand the difference between the notions of images and image instances, you can refer to the glossary.</p> <ul> <li>If you choose the image property option, you will annotate, for the created property, all instances of the same image.</li> <li>If you choose the instance property option, you will annotate a single instance of the image.</li> </ul> <p>For example, you are working with tweets that contain images. If 50 different tweets use the same image:</p> <ul> <li>Choosing the image property option will allow you to annotate all 50 tweets at once, which use the same image: this is relevant if you want to describe the image as such, but it is not if you want to annotate the context of the image's use.</li> <li>Choosing the instance property option will allow you to annotate the tweets one by one: this is relevant if you want to describe the context of the image's use, but it is not if you want to annotate the image as such.</li> </ul>"},{"location":"en/start/properties/#relationships-between-properties","title":"Relationships Between Properties","text":"<p>It is possible to define hierarchical (parent-child) relationships between annotations for Tag and MultiTags property types. These properties are indeed specific and can be managed in a dedicated space. This space opens from the properties pane, located on the left of the screen, by clicking on the associated symbol.</p> <p></p> <p>Important</p> <p>In this tag management space and its relationships, two views of these relationships are available depending on the needs: the \"tree\" view and the \"list\" view.</p>"},{"location":"en/start/properties/#tree-view-of-tag-and-multi-tag-properties","title":"\"Tree\" View of Tag and Multi-tag Properties","text":"<p>In the example, the \"tree\" view shows existing parent-child relationships (sport/athletics/pole vault; medical images/lungs). The parentage of the different annotations made is done by grabbing an annotation with the mouse and dragging it onto the more general level annotation.</p> <p></p> <p>In this tag management space, you can rename your different tags, to improve them if necessary, or merge them, if you find duplicates for example. To merge them, select several tags (using the shift key) and click \"Merge Tags.\"</p> <p></p>"},{"location":"en/start/properties/#list-view-of-tag-and-multi-tag-properties","title":"\"List\" View of Tag and Multi-tag Properties","text":"<p>You can also display images in \"list\" view. Here, when you select a tag, it displays its different relationships: parents, siblings (same parents), children.</p> <p></p>"},{"location":"en/start/properties/#panoptic-properties","title":"Panoptic Properties","text":"<p>\"PANOPTIC PROPERTIES\" are non-manipulable properties. They are calculated by the software during image import and provide you with some metrics: a unique identifier for each image (\"ID\"), a signature specific to each image to identify perfect duplicates (\"sha1\"), a signature specific to roughly similar images (\"average hash\"), their original folder on your computer (\"folder\"), as well as their absolute path (\"path\"), and finally their dimensions (\"width\" and \"height\")</p>"},{"location":"en/start/propsexport/","title":"Export Properties","text":"<p>Once your annotations are complete, you can decide to export them, with or without a reproduction of the images.</p> <p>You can then choose whether you want to export all properties, or only a part of them.</p> <p></p> <p>To customize your export, you can: (1) Choose a name for the export folder; if you don't specify anything, it will be named after the current date and time, in YYYY-MM-DD-HH-MM-SS format. (2) Select a subset of your images and associated data. (3) Choose between \"ID\", \"Relative Path\", and \"Absolute Path\". (4) Select the properties to export. (5) Include images in the export.</p> <p>Finally, press the \"export\" button (6) to validate your choices and start the export.</p> <p></p>"},{"location":"en/start/propsimport/","title":"Import Properties","text":"<p>Panoptic is designed for working with multi-semiotic data, making it possible to import PROPERTIES ASSOCIATED WITH IMAGES into the software interface. Properties imported into Panoptic are automatically structured like properties that can be created manually. They can therefore be modified as you wish.</p> <p>Panoptic allows the exploration of multi-semiotic corpora. To meet this methodological need, Panoptic offers a series of functionalities for manipulating images AND associated textual data. It is therefore possible to associate a properties file, in .csv format, with imported images.</p>"},{"location":"en/start/propsimport/#what-is-a-csv-file","title":"What is a .csv file?","text":"<p>A file with the .csv extension (for \"Comma-Separated Values\") is a text file format used to store tabular data, such as that found in a spreadsheet (Excel for example). In a .csv file, each row represents a line of data, and the values in each column are separated by a semicolon. This type of file is generally managed in a plain text editing application (notepad, textedit).</p>"},{"location":"en/start/propsimport/#what-types-of-data-can-be-imported","title":"What types of data can be imported?","text":"Name Explanation text Textual data: lorem ipsum... number Numerical data: 0123456789 tag text, which will be presented as tags in the Panoptic interface multi_tags several blocks of text, separated by commas (,), which will be presented as tags in the Panoptic interface checkbox a true (checked box) or false (unchecked box) value url a link to a website date a date color Colors, from the following list: red, pink, grape, violet, indigo, blue, cyan, teal, green, lime, yellow, orange"},{"location":"en/start/propsimport/#how-to-correctly-format-this-data","title":"How to correctly format this data?","text":"<p>The .csv file containing the data associated with the images must be structured as follows: - All data must be separated by semicolons (;). - The first line of the .csv must contain the headers. The part in square brackets corresponds to the property type (see previous page). The part outside the square brackets corresponds to the name you wish to give to the property.     - This first line must be written as follows: path;creation date[date];link to image[url];color code 1[color];color code 2[color];     - Important: the very first data has a different format (\"path\"): it is the path (relative or complete) to where the image is located on your computer: C:/my/personal/folder/image1.jpg. For the rest, you can order the metadata as you wish. - The following lines contain the metadata for each image, filled according to the type of properties: C:/my/personal/folder/image1.jpg;24/10/2024;https://instagram.com/image.png;blue;red</p> <p>Formatting specifics:</p> <ul> <li>Several possibilities for timestamping: 2024; 02/2024; 19/02/2024; 19/02/2024 12:45; 19/02/2024 12:45:55; 19-02-2024T12:45:55.000Z; 2024/02/19 12:45:55.</li> <li>For importing multi_tags, the different tags entered must be separated by a comma (,).</li> </ul>"},{"location":"en/start/propsimport/#example-of-a-well-formatted-csv-file-for-panoptic","title":"Example of a well-formatted .csv file for Panoptic","text":""},{"location":"en/start/propsimport/#how-to-import-well-formatted-data-into-panoptic","title":"How to import well-formatted data into Panoptic?","text":"<p>When your file to import is well structured, go to your Panoptic project and, to the right of the \"Properties\" section, click on the property import icon. In the window that opens, choose the .csv file to import. Panoptic then opens the file and indicates a summary in a five-column table. You can act on the first and last: - Check or uncheck the properties to import (by default all properties from the .csv table will be imported). - Indicates the column number in the original .csv. - Indicates the name of the properties and their type as a logo. - Indicates whether the property already exists in Panoptic or not. - Change the property mode in Panoptic: \"instance\" or \"image\".</p> <p>Specify by checking or unchecking the \"Relative Path\" box whether the image path indicated in the .csv file is relative or absolute.</p> <p>You can then validate the import by clicking on \"Import\". The data is imported into the \"properties\" section of Panoptic and is therefore now manipulable.</p> <p></p> <p></p>"},{"location":"en/start/propsimport/#precision-on-the-data-merge-mode","title":"Precision on the data merge mode","text":"<p>If one wishes to import already existing properties (typically, if two people each work on the same image corpus and annotate it before sharing their annotations to update their respective progress), there is the possibility of choosing the data merge mode. Four possibilities are offered:</p> <ul> <li>New: this mode creates a new instance of the image specified in the path column (thus does not overwrite existing data)</li> <li>First: this mode overwrites the properties of the oldest instance of an image recorded in Panoptic, and replaces them with those specified in the .csv file being imported.</li> <li>Last: this mode overwrites the properties of the most recent instance of an image recorded in Panoptic, and replaces them with those specified in the .csv file being imported.</li> <li>All: this mode overwrites all properties corresponding to the different instances of an image to replace them with the properties specified in the imported .csv file.</li> </ul>"},{"location":"en/start/reco/","title":"Recommendations","text":"<p>A third similarity tool is recommendations to complete an existing group.</p> <p>You must first have grouped your images by a tag or multi-tag property and click on the \"Image Proposal\" button:</p> <p></p> <p>This then opens a list of image proposals similar to all images in the source group. You can then either validate or refuse each image. By validating an image, it will be added to the group by assigning the group's tag to it.</p>"},{"location":"en/start/similar/","title":"Find Similar Images","text":"<p>Another similarity tool provided by Panoptic is the search for images similar to a given image. To do this, simply click on an image to open a window containing that image, all its properties, as well as all images similar to it:</p> <p></p> <p>At the bottom right of each image, its similarity score with the \"source\" image is displayed. Panoptic's basic similarity plugin displays a score ranging from 0 to 1, with 1 being the closest. A filter allows selecting minimum and maximum similarity rates.</p> <p>It is then possible to annotate these images either by selecting them and proceeding with a group annotation, or by clicking on the paint bucket icon next to the source image's properties, which will assign the same value to all similar images.</p> <p></p>"},{"location":"en/start/text/","title":"Textual Similarity","text":"<p>The last similarity tool provided by default in Panoptic is the one allowing for textual similarity. That is, to be able to search within the corpus for images that best match a textual query.</p> <p></p> <p>This will then return all images sorted by decreasing similarity. A parameter can be chosen to return only images exceeding a certain similarity threshold.</p>"}]}